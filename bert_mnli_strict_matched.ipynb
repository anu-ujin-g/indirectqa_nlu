{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bert_mnli_strict_matched",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHPrujng28-7",
        "outputId": "601ebe6a-086d-4841-8eb1-8195d1ab9d87"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HkugCqiD-e9",
        "outputId": "dfc03ffa-c14c-407a-ffe9-feef6067f6fa"
      },
      "source": [
        "!pip install transformers==2.5.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==2.5.1 in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (1.19.5)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (0.1.95)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (1.17.54)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2019.12.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2020.12.5)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1) (0.4.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.54 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1) (1.20.54)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.54->boto3->transformers==2.5.1) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3IdDlBz3ZaK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "# from transformers import AutoTokenizer, BertTokenizer, EvalPrediction, BertPreTrainedModel, BertConfig, BertModel, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV5G9TxitK8X"
      },
      "source": [
        "    import torch\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6PGzfGHq4kZ",
        "outputId": "f17fa5e8-6ea5-40af-9b46-ccb9128ff54e"
      },
      "source": [
        "cd '/content/drive/MyDrive/'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9_N6KwgmcXL"
      },
      "source": [
        "## Data pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzL4OXr_ZCZD"
      },
      "source": [
        "Strict-matched"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPj_AqIO4eeI"
      },
      "source": [
        "# circa_og = pd.read_csv('NLU_Project/circa-data.tsv', sep='\\t', index_col='id')\n",
        "circa_og = pd.read_csv('/content/drive/MyDrive/AMBER_TENG_NYU_DRIVE_TO_BROWN/NYU_SPRING2021/NLU/NLU_Project/circa-data.tsv', sep='\\t', index_col='id')\n",
        "circa_r = circa_og.drop(circa_og.loc[circa_og['goldstandard2']=='Other'].index)\n",
        "circa_r = circa_r.drop(circa_r.loc[circa_r['goldstandard2'].isnull()].index)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3zGnD5Vj_GD"
      },
      "source": [
        "# circa_og = pd.read_csv('circa-data.tsv', sep='\\t', index_col='id')\n",
        "circa_og = pd.read_csv('/content/drive/MyDrive/AMBER_TENG_NYU_DRIVE_TO_BROWN/NYU_SPRING2021/NLU/NLU_Project/circa-data.tsv', sep='\\t', index_col='id')\n",
        "circa_s = circa_og.drop(circa_og.loc[circa_og['goldstandard1']=='Other'].index)\n",
        "circa_s = circa_s.drop(circa_s.loc[circa_s['goldstandard1'].isnull()].index)\n",
        "circa_s = circa_s.drop(circa_s.loc[circa_s['goldstandard1']=='I am not sure how X will interpret Y’s answer'].index)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW9QqMAjf7p-"
      },
      "source": [
        "# YN_r = (circa_r['question-X'].map(str)+' '+circa_r['answer-Y']).apply(lambda row: row.strip())\n",
        "# relaxed_labels = circa_r['goldstandard2'].unique()\n",
        "# relaxed_label = circa_r['goldstandard2']\n",
        "# relaxed_dict = {}\n",
        "# for idx, label in enumerate(relaxed_labels):\n",
        "#     relaxed_dict[label] = idx\n",
        "# circa_r['relaxed'] = circa_r.goldstandard2.replace(relaxed_dict)\n",
        "# relaxed = circa_r['relaxed']\n",
        "YN_s = (circa_s['question-X'].map(str)+' '+circa_s['answer-Y']).apply(lambda row: row.strip())\n",
        "strict_labels = circa_s['goldstandard1'].unique()\n",
        "strict_label = circa_s['goldstandard1']\n",
        "strict_dict = {}\n",
        "for idx, label in enumerate(strict_labels):\n",
        "    strict_dict[label] = idx\n",
        "circa_s['strict'] = circa_s.goldstandard1.replace(strict_dict)\n",
        "strict = circa_s['strict']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn0h950hmUU5"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSmxC4gJ4ZE9",
        "outputId": "8195569d-84a4-4f7d-ec9e-3cb8f53b6c48"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeoL9QXBmXR9"
      },
      "source": [
        "### Strict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b6Hm6JElryP"
      },
      "source": [
        "from transformers import PreTrainedModel\n",
        "from transformers import BertConfig, BertModel\n",
        "from transformers.modeling_tf_bert import TFBertForSequenceClassification\n",
        "from transformers import BertForSequenceClassification"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZfGsNNdVfyE"
      },
      "source": [
        "## Model Specs\n",
        "- BERT-MNLI-YN Relaxed learning rate: 5e-5\n",
        "- MNLI learning rate: 2e-5 ; 3 epochs; batch size 16 vs 32 \n",
        "  - https://huggingface.co/ishan/bert-base-uncased-mnli \n",
        "  - The training parameters were kept the same as Devlin et al., 2019 (learning rate = 2e-5, training epochs = 3, max_sequence_len = 128 and batch_size = 32).\n",
        "- BERT-MNLI-YN Strict learning rate: 2e-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jinT4bf1Zyc5"
      },
      "source": [
        "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\") \n",
        "tokenizer = AutoTokenizer.from_pretrained('ishan/bert-base-uncased-mnli') \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "# device = torch.device(\"cpu\")\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "# model.cuda()\n",
        "model.to(device)\n",
        "\n",
        "learning_rate = 2e-5\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "TUedR74Kt4_I",
        "outputId": "2ccf48e1-bbf1-49f1-eeb7-2c880618b221"
      },
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |  428780 KB |  428780 KB |  428780 KB |       0 B  |\\n|       from large pool |  428288 KB |  428288 KB |  428288 KB |       0 B  |\\n|       from small pool |     492 KB |     492 KB |     492 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |  428780 KB |  428780 KB |  428780 KB |       0 B  |\\n|       from large pool |  428288 KB |  428288 KB |  428288 KB |       0 B  |\\n|       from small pool |     492 KB |     492 KB |     492 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |  483328 KB |  483328 KB |  483328 KB |       0 B  |\\n|       from large pool |  481280 KB |  481280 KB |  481280 KB |       0 B  |\\n|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   54547 KB |   54560 KB |  265210 KB |  210662 KB |\\n|       from large pool |   52992 KB |   52992 KB |  263168 KB |  210176 KB |\\n|       from small pool |    1555 KB |    2042 KB |    2042 KB |     486 KB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     201    |     201    |     201    |       0    |\\n|       from large pool |      75    |      75    |      75    |       0    |\\n|       from small pool |     126    |     126    |     126    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     201    |     201    |     201    |       0    |\\n|       from large pool |      75    |      75    |      75    |       0    |\\n|       from small pool |     126    |     126    |     126    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      21    |      21    |      21    |       0    |\\n|       from large pool |      20    |      20    |      20    |       0    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      19    |      19    |      20    |       1    |\\n|       from large pool |      18    |      18    |      19    |       1    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|===========================================================================|\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BjmZLHa7Nne",
        "outputId": "0ee212e5-ae4c-42c1-a516-260af8081d3d"
      },
      "source": [
        "# max_len = 0\n",
        "# for entry in YN_r.values:\n",
        "#     input_ids = tokenizer.encode(entry,  add_special_tokens=True)\n",
        "#     max_len = max(max_len, len(input_ids))\n",
        "# print(max_len)\n",
        "\n",
        "max_len = 0\n",
        "for entry in YN_s.values:\n",
        "    input_ids = tokenizer.encode(entry,  add_special_tokens=True)\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "print(max_len)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYTos6aPksfw"
      },
      "source": [
        "strict_labels = circa_s['goldstandard1'].unique()\n",
        "strict_label = circa_s['goldstandard1']\n",
        "strict_dict = {}\n",
        "for idx, label in enumerate(strict_labels):\n",
        "    strict_dict[label] = idx\n",
        "circa_s['strict'] = circa_s.goldstandard1.replace(strict_dict)\n",
        "strict = circa_s['strict']\n",
        "\n",
        "YN_s = (circa_s['question-X'].map(str)+' '+circa_s['answer-Y']).apply(lambda row: row.strip())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "Fv5cc_qyWPFS",
        "outputId": "9088fa0a-5afe-483c-8ba5-52f3550215bd"
      },
      "source": [
        "# df = pd.concat([YN_r, relaxed_label, relaxed], axis=1).rename(columns={0:'YN_r'})\n",
        "# df\n",
        "df = pd.concat([YN_s, strict_label, strict], axis=1).rename(columns={0:'YN_s'})\n",
        "df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YN_s</th>\n",
              "      <th>goldstandard1</th>\n",
              "      <th>strict</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Are you employed? I'm a veterinary technician.</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are you a fan of Korean food? I wouldn't say so</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Are you bringing any pets into the flat? I do ...</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Would you like to get some fresh air in your f...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Is your family still living in the neighborhoo...</td>\n",
              "      <td>In the middle, neither yes nor no</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34263</th>\n",
              "      <td>Do you like to drink? I am in AA.</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34264</th>\n",
              "      <td>Do you like pie? My favorite pie is pecan.</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34265</th>\n",
              "      <td>Want to go to a concert with me? I'd rather do...</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34266</th>\n",
              "      <td>Do you like hip/hop music? I can't dance to hi...</td>\n",
              "      <td>Probably no</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34267</th>\n",
              "      <td>Do you see yourself raising a family in New Yo...</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30958 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    YN_s  ... strict\n",
              "id                                                        ...       \n",
              "0         Are you employed? I'm a veterinary technician.  ...      0\n",
              "1        Are you a fan of Korean food? I wouldn't say so  ...      1\n",
              "2      Are you bringing any pets into the flat? I do ...  ...      1\n",
              "3      Would you like to get some fresh air in your f...  ...      0\n",
              "4      Is your family still living in the neighborhoo...  ...      2\n",
              "...                                                  ...  ...    ...\n",
              "34263                  Do you like to drink? I am in AA.  ...      1\n",
              "34264         Do you like pie? My favorite pie is pecan.  ...      0\n",
              "34265  Want to go to a concert with me? I'd rather do...  ...      1\n",
              "34266  Do you like hip/hop music? I can't dance to hi...  ...      4\n",
              "34267  Do you see yourself raising a family in New Yo...  ...      1\n",
              "\n",
              "[30958 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulXaXpJiVrcT"
      },
      "source": [
        "# train_relaxed, val_relaxed, trainy_relaxed, valy_relaxed = train_test_split(df.index.values, df.relaxed.values, test_size=.4, stratify=df.relaxed.values)\n",
        "# test_relaxed, dev_relaxed, testy_relaxed, devy_relaxed = train_test_split(val_relaxed, valy_relaxed, test_size=.5, stratify=valy_relaxed)\n",
        "\n",
        "train_strict, val_strict, trainy_strict, valy_strict = train_test_split(df.index.values, df.strict.values, test_size=.4, stratify=df.strict.values)\n",
        "test_strict, dev_strict, testy_strict, devy_strict = train_test_split(val_strict, valy_strict, test_size=.5, stratify=valy_strict)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O06VmOd-VrWL"
      },
      "source": [
        "# df['data_type'] = ['not_set']*df.shape[0]\n",
        "# df.loc[train_relaxed,'data_type'] = 'train'\n",
        "# df.loc[dev_relaxed,'data_type'] = 'dev'\n",
        "# df.loc[test_relaxed,'data_type'] = 'test'\n",
        "\n",
        "df['data_type'] = ['not_set']*df.shape[0]\n",
        "df.loc[train_strict,'data_type'] = 'train'\n",
        "df.loc[dev_strict,'data_type'] = 'dev'\n",
        "df.loc[test_strict,'data_type'] = 'test'"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "roLxfOJAVdt_",
        "outputId": "cbf8c24e-971e-46f9-b0b4-9576d9e60985"
      },
      "source": [
        "# df.groupby(['goldstandard2','relaxed','data_type']).count()\n",
        "\n",
        "df.groupby(['goldstandard1','strict','data_type']).count()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>YN_s</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goldstandard1</th>\n",
              "      <th>strict</th>\n",
              "      <th>data_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">In the middle, neither yes nor no</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
              "      <th>dev</th>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">No</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
              "      <th>dev</th>\n",
              "      <td>2166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>2166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>6497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">Probably no</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">4</th>\n",
              "      <th>dev</th>\n",
              "      <td>232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">Probably yes / sometimes yes</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
              "      <th>dev</th>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">Yes</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
              "      <th>dev</th>\n",
              "      <td>2901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>2901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>8702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">Yes, subject to some conditions</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
              "      <th>dev</th>\n",
              "      <td>516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>1550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    YN_s\n",
              "goldstandard1                     strict data_type      \n",
              "In the middle, neither yes nor no 2      dev         128\n",
              "                                         test        127\n",
              "                                         train       383\n",
              "No                                1      dev        2166\n",
              "                                         test       2166\n",
              "                                         train      6497\n",
              "Probably no                       4      dev         232\n",
              "                                         test        232\n",
              "                                         train       696\n",
              "Probably yes / sometimes yes      3      dev         249\n",
              "                                         test        249\n",
              "                                         train       746\n",
              "Yes                               0      dev        2901\n",
              "                                         test       2901\n",
              "                                         train      8702\n",
              "Yes, subject to some conditions   5      dev         516\n",
              "                                         test        517\n",
              "                                         train      1550"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCQzgsZpYb7k"
      },
      "source": [
        "# encoded_data_train = tokenizer.batch_encode_plus(\n",
        "#     df[df.data_type=='train'].YN_r.values, \n",
        "#     add_special_tokens=True, \n",
        "#     return_attention_mask=True, \n",
        "#     pad_to_max_length=True, \n",
        "#     max_length=256, \n",
        "#     return_tensors='pt'\n",
        "# )\n",
        "\n",
        "# encoded_data_dev = tokenizer.batch_encode_plus(\n",
        "#     df[df.data_type=='dev'].YN_r.values, \n",
        "#     add_special_tokens=True, \n",
        "#     return_attention_mask=True, \n",
        "#     pad_to_max_length=True, \n",
        "#     max_length=256, \n",
        "#     return_tensors='pt'\n",
        "# )\n",
        "\n",
        "\n",
        "# input_ids_train = encoded_data_train['input_ids']\n",
        "# attention_masks_train = encoded_data_train['attention_mask']\n",
        "# labels_train = torch.tensor(df[df.data_type=='train'].relaxed.values)\n",
        "\n",
        "# input_ids_dev = encoded_data_dev['input_ids']\n",
        "# attention_masks_dev = encoded_data_dev['attention_mask']\n",
        "# labels_dev = torch.tensor(df[df.data_type=='dev'].relaxed.values)\n",
        "\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='train'].YN_s.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=256, \n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_dev = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='dev'].YN_s.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=256, \n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df[df.data_type=='train'].strict.values)\n",
        "\n",
        "input_ids_dev = encoded_data_dev['input_ids']\n",
        "attention_masks_dev = encoded_data_dev['attention_mask']\n",
        "labels_dev = torch.tensor(df[df.data_type=='dev'].strict.values)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlIrCldCnh-E"
      },
      "source": [
        "# encoded_data_train\n",
        "# input_ids_train\n",
        "# attention_masks_dev\n",
        "# labels_dev  "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITsWnPAoYb1B"
      },
      "source": [
        "# dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "# dataset_dev = TensorDataset(input_ids_dev, attention_masks_dev, labels_dev)\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_dev = TensorDataset(input_ids_dev, attention_masks_dev, labels_dev)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxXgN_qkYboP",
        "outputId": "6acc5e00-bb82-4c24-8b2f-cff24be58af5"
      },
      "source": [
        "len(dataset_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18574"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9wyJZKyoSvl",
        "outputId": "34dad34b-bccd-4af5-a7a2-e4fdfe93cce5"
      },
      "source": [
        "# model\n",
        "# relaxed_dict\n",
        "len(strict_dict)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Awf4-kru0Rb0",
        "outputId": "73b41293-3d4c-4fa4-e0c0-2fcafcd50aa0"
      },
      "source": [
        "model.classifier"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=768, out_features=3, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH9pv41v0b-I"
      },
      "source": [
        "# model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBGmxeLQYbh2",
        "outputId": "addd79aa-9bee-4304-a79a-01162c64cb53"
      },
      "source": [
        "# model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "#                                                       num_labels=len(relaxed_dict),\n",
        "#                                                       output_attentions=False,\n",
        "#                                                       output_hidden_states=False)\n",
        "\n",
        "# model = BertForSequenceClassification.from_pretrained('ishan/bert-base-uncased-mnli',\n",
        "#                                                       num_labels=4,\n",
        "#                                                       # num_labels=len(relaxed_dict),\n",
        "#                                                       output_attentions=False,\n",
        "#                                                       output_hidden_states=False)\n",
        "model.classifier = torch.nn.Linear(model.classifier.in_features, 6)\n",
        "model.num_labels = 6\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
        "model.to(device)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f4D3pbiYbd9"
      },
      "source": [
        "# batch_size = 32\n",
        "batch_size = 16\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, \n",
        "                              sampler=RandomSampler(dataset_train), \n",
        "                              batch_size=batch_size)\n",
        "\n",
        "dataloader_validation = DataLoader(dataset_dev, \n",
        "                                   sampler=SequentialSampler(dataset_dev), \n",
        "                                   batch_size=batch_size)\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9mezaQuZtMn"
      },
      "source": [
        "# epochs = 3\n",
        "epochs = 2\n",
        "total_steps = len(dataloader_train) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3mrMRzuZtF5"
      },
      "source": [
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in strict_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98gXVUdIZs_F"
      },
      "source": [
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8O6SdezZs7E",
        "outputId": "2fad3f82-f8d4-4f24-84d6-64d93788aa59"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaOGmI3KZszz"
      },
      "source": [
        "\n",
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in dataloader_val:\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IquyMsgoZstF",
        "outputId": "143f7120-14a8-4dfc-9a9f-f87f9afce91f"
      },
      "source": [
        "\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    loss_train_total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        model.zero_grad()\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }       \n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "         \n",
        "        \n",
        "    torch.save(model.state_dict(), f'finetuned_BERT_epoch_{epoch}.model')\n",
        "        \n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    dev_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
        "    dev_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {dev_loss}')\n",
        "    tqdm.write(f'F1 Score (Weighted): {dev_f1}')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 0/1161 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Epoch 1:   0%|          | 0/1161 [00:00<?, ?it/s, training_loss=0.630]\u001b[A\n",
            "Epoch 1:   0%|          | 1/1161 [00:00<14:20,  1.35it/s, training_loss=0.630]\u001b[A\n",
            "Epoch 1:   0%|          | 1/1161 [00:01<14:20,  1.35it/s, training_loss=0.556]\u001b[A\n",
            "Epoch 1:   0%|          | 2/1161 [00:01<14:00,  1.38it/s, training_loss=0.556]\u001b[A\n",
            "Epoch 1:   0%|          | 2/1161 [00:02<14:00,  1.38it/s, training_loss=0.574]\u001b[A\n",
            "Epoch 1:   0%|          | 3/1161 [00:02<13:49,  1.40it/s, training_loss=0.574]\u001b[A\n",
            "Epoch 1:   0%|          | 3/1161 [00:02<13:49,  1.40it/s, training_loss=0.518]\u001b[A\n",
            "Epoch 1:   0%|          | 4/1161 [00:02<13:38,  1.41it/s, training_loss=0.518]\u001b[A\n",
            "Epoch 1:   0%|          | 4/1161 [00:03<13:38,  1.41it/s, training_loss=0.499]\u001b[A\n",
            "Epoch 1:   0%|          | 5/1161 [00:03<13:34,  1.42it/s, training_loss=0.499]\u001b[A\n",
            "Epoch 1:   0%|          | 5/1161 [00:04<13:34,  1.42it/s, training_loss=0.515]\u001b[A\n",
            "Epoch 1:   1%|          | 6/1161 [00:04<13:31,  1.42it/s, training_loss=0.515]\u001b[A\n",
            "Epoch 1:   1%|          | 6/1161 [00:04<13:31,  1.42it/s, training_loss=0.567]\u001b[A\n",
            "Epoch 1:   1%|          | 7/1161 [00:04<13:32,  1.42it/s, training_loss=0.567]\u001b[A\n",
            "Epoch 1:   1%|          | 7/1161 [00:05<13:32,  1.42it/s, training_loss=0.503]\u001b[A\n",
            "Epoch 1:   1%|          | 8/1161 [00:05<13:32,  1.42it/s, training_loss=0.503]\u001b[A\n",
            "Epoch 1:   1%|          | 8/1161 [00:06<13:32,  1.42it/s, training_loss=0.480]\u001b[A\n",
            "Epoch 1:   1%|          | 9/1161 [00:06<13:32,  1.42it/s, training_loss=0.480]\u001b[A\n",
            "Epoch 1:   1%|          | 9/1161 [00:07<13:32,  1.42it/s, training_loss=0.406]\u001b[A\n",
            "Epoch 1:   1%|          | 10/1161 [00:07<13:33,  1.41it/s, training_loss=0.406]\u001b[A\n",
            "Epoch 1:   1%|          | 10/1161 [00:07<13:33,  1.41it/s, training_loss=0.529]\u001b[A\n",
            "Epoch 1:   1%|          | 11/1161 [00:07<13:31,  1.42it/s, training_loss=0.529]\u001b[A\n",
            "Epoch 1:   1%|          | 11/1161 [00:08<13:31,  1.42it/s, training_loss=0.575]\u001b[A\n",
            "Epoch 1:   1%|          | 12/1161 [00:08<13:29,  1.42it/s, training_loss=0.575]\u001b[A\n",
            "Epoch 1:   1%|          | 12/1161 [00:09<13:29,  1.42it/s, training_loss=0.613]\u001b[A\n",
            "Epoch 1:   1%|          | 13/1161 [00:09<13:31,  1.41it/s, training_loss=0.613]\u001b[A\n",
            "Epoch 1:   1%|          | 13/1161 [00:09<13:31,  1.41it/s, training_loss=0.418]\u001b[A\n",
            "Epoch 1:   1%|          | 14/1161 [00:09<13:33,  1.41it/s, training_loss=0.418]\u001b[A\n",
            "Epoch 1:   1%|          | 14/1161 [00:10<13:33,  1.41it/s, training_loss=0.453]\u001b[A\n",
            "Epoch 1:   1%|▏         | 15/1161 [00:10<13:32,  1.41it/s, training_loss=0.453]\u001b[A\n",
            "Epoch 1:   1%|▏         | 15/1161 [00:11<13:32,  1.41it/s, training_loss=0.363]\u001b[A\n",
            "Epoch 1:   1%|▏         | 16/1161 [00:11<13:33,  1.41it/s, training_loss=0.363]\u001b[A\n",
            "Epoch 1:   1%|▏         | 16/1161 [00:11<13:33,  1.41it/s, training_loss=0.479]\u001b[A\n",
            "Epoch 1:   1%|▏         | 17/1161 [00:11<13:27,  1.42it/s, training_loss=0.479]\u001b[A\n",
            "Epoch 1:   1%|▏         | 17/1161 [00:12<13:27,  1.42it/s, training_loss=0.408]\u001b[A\n",
            "Epoch 1:   2%|▏         | 18/1161 [00:12<13:27,  1.42it/s, training_loss=0.408]\u001b[A\n",
            "Epoch 1:   2%|▏         | 18/1161 [00:13<13:27,  1.42it/s, training_loss=0.413]\u001b[A\n",
            "Epoch 1:   2%|▏         | 19/1161 [00:13<13:24,  1.42it/s, training_loss=0.413]\u001b[A\n",
            "Epoch 1:   2%|▏         | 19/1161 [00:14<13:24,  1.42it/s, training_loss=0.444]\u001b[A\n",
            "Epoch 1:   2%|▏         | 20/1161 [00:14<13:28,  1.41it/s, training_loss=0.444]\u001b[A\n",
            "Epoch 1:   2%|▏         | 20/1161 [00:14<13:28,  1.41it/s, training_loss=0.488]\u001b[A\n",
            "Epoch 1:   2%|▏         | 21/1161 [00:14<13:26,  1.41it/s, training_loss=0.488]\u001b[A\n",
            "Epoch 1:   2%|▏         | 21/1161 [00:15<13:26,  1.41it/s, training_loss=0.455]\u001b[A\n",
            "Epoch 1:   2%|▏         | 22/1161 [00:15<13:27,  1.41it/s, training_loss=0.455]\u001b[A\n",
            "Epoch 1:   2%|▏         | 22/1161 [00:16<13:27,  1.41it/s, training_loss=0.379]\u001b[A\n",
            "Epoch 1:   2%|▏         | 23/1161 [00:16<13:29,  1.41it/s, training_loss=0.379]\u001b[A\n",
            "Epoch 1:   2%|▏         | 23/1161 [00:16<13:29,  1.41it/s, training_loss=0.528]\u001b[A\n",
            "Epoch 1:   2%|▏         | 24/1161 [00:16<13:29,  1.40it/s, training_loss=0.528]\u001b[A\n",
            "Epoch 1:   2%|▏         | 24/1161 [00:17<13:29,  1.40it/s, training_loss=0.503]\u001b[A\n",
            "Epoch 1:   2%|▏         | 25/1161 [00:17<13:29,  1.40it/s, training_loss=0.503]\u001b[A\n",
            "Epoch 1:   2%|▏         | 25/1161 [00:18<13:29,  1.40it/s, training_loss=0.412]\u001b[A\n",
            "Epoch 1:   2%|▏         | 26/1161 [00:18<13:30,  1.40it/s, training_loss=0.412]\u001b[A\n",
            "Epoch 1:   2%|▏         | 26/1161 [00:19<13:30,  1.40it/s, training_loss=0.344]\u001b[A\n",
            "Epoch 1:   2%|▏         | 27/1161 [00:19<13:31,  1.40it/s, training_loss=0.344]\u001b[A\n",
            "Epoch 1:   2%|▏         | 27/1161 [00:19<13:31,  1.40it/s, training_loss=0.412]\u001b[A\n",
            "Epoch 1:   2%|▏         | 28/1161 [00:19<13:31,  1.40it/s, training_loss=0.412]\u001b[A\n",
            "Epoch 1:   2%|▏         | 28/1161 [00:20<13:31,  1.40it/s, training_loss=0.357]\u001b[A\n",
            "Epoch 1:   2%|▏         | 29/1161 [00:20<13:33,  1.39it/s, training_loss=0.357]\u001b[A\n",
            "Epoch 1:   2%|▏         | 29/1161 [00:21<13:33,  1.39it/s, training_loss=0.588]\u001b[A\n",
            "Epoch 1:   3%|▎         | 30/1161 [00:21<13:35,  1.39it/s, training_loss=0.588]\u001b[A\n",
            "Epoch 1:   3%|▎         | 30/1161 [00:21<13:35,  1.39it/s, training_loss=0.387]\u001b[A\n",
            "Epoch 1:   3%|▎         | 31/1161 [00:22<13:35,  1.39it/s, training_loss=0.387]\u001b[A\n",
            "Epoch 1:   3%|▎         | 31/1161 [00:22<13:35,  1.39it/s, training_loss=0.315]\u001b[A\n",
            "Epoch 1:   3%|▎         | 32/1161 [00:22<13:34,  1.39it/s, training_loss=0.315]\u001b[A\n",
            "Epoch 1:   3%|▎         | 32/1161 [00:23<13:34,  1.39it/s, training_loss=0.501]\u001b[A\n",
            "Epoch 1:   3%|▎         | 33/1161 [00:23<13:34,  1.39it/s, training_loss=0.501]\u001b[A\n",
            "Epoch 1:   3%|▎         | 33/1161 [00:24<13:34,  1.39it/s, training_loss=0.386]\u001b[A\n",
            "Epoch 1:   3%|▎         | 34/1161 [00:24<13:35,  1.38it/s, training_loss=0.386]\u001b[A\n",
            "Epoch 1:   3%|▎         | 34/1161 [00:24<13:35,  1.38it/s, training_loss=0.332]\u001b[A\n",
            "Epoch 1:   3%|▎         | 35/1161 [00:24<13:33,  1.38it/s, training_loss=0.332]\u001b[A\n",
            "Epoch 1:   3%|▎         | 35/1161 [00:25<13:33,  1.38it/s, training_loss=0.400]\u001b[A\n",
            "Epoch 1:   3%|▎         | 36/1161 [00:25<13:34,  1.38it/s, training_loss=0.400]\u001b[A\n",
            "Epoch 1:   3%|▎         | 36/1161 [00:26<13:34,  1.38it/s, training_loss=0.415]\u001b[A\n",
            "Epoch 1:   3%|▎         | 37/1161 [00:26<13:36,  1.38it/s, training_loss=0.415]\u001b[A\n",
            "Epoch 1:   3%|▎         | 37/1161 [00:27<13:36,  1.38it/s, training_loss=0.436]\u001b[A\n",
            "Epoch 1:   3%|▎         | 38/1161 [00:27<13:36,  1.38it/s, training_loss=0.436]\u001b[A\n",
            "Epoch 1:   3%|▎         | 38/1161 [00:27<13:36,  1.38it/s, training_loss=0.441]\u001b[A\n",
            "Epoch 1:   3%|▎         | 39/1161 [00:27<13:36,  1.37it/s, training_loss=0.441]\u001b[A\n",
            "Epoch 1:   3%|▎         | 39/1161 [00:28<13:36,  1.37it/s, training_loss=0.469]\u001b[A\n",
            "Epoch 1:   3%|▎         | 40/1161 [00:28<13:37,  1.37it/s, training_loss=0.469]\u001b[A\n",
            "Epoch 1:   3%|▎         | 40/1161 [00:29<13:37,  1.37it/s, training_loss=0.522]\u001b[A\n",
            "Epoch 1:   4%|▎         | 41/1161 [00:29<13:40,  1.36it/s, training_loss=0.522]\u001b[A\n",
            "Epoch 1:   4%|▎         | 41/1161 [00:30<13:40,  1.36it/s, training_loss=0.268]\u001b[A\n",
            "Epoch 1:   4%|▎         | 42/1161 [00:30<13:39,  1.37it/s, training_loss=0.268]\u001b[A\n",
            "Epoch 1:   4%|▎         | 42/1161 [00:30<13:39,  1.37it/s, training_loss=0.380]\u001b[A\n",
            "Epoch 1:   4%|▎         | 43/1161 [00:30<13:44,  1.36it/s, training_loss=0.380]\u001b[A\n",
            "Epoch 1:   4%|▎         | 43/1161 [00:31<13:44,  1.36it/s, training_loss=0.371]\u001b[A\n",
            "Epoch 1:   4%|▍         | 44/1161 [00:31<13:46,  1.35it/s, training_loss=0.371]\u001b[A\n",
            "Epoch 1:   4%|▍         | 44/1161 [00:32<13:46,  1.35it/s, training_loss=0.432]\u001b[A\n",
            "Epoch 1:   4%|▍         | 45/1161 [00:32<13:45,  1.35it/s, training_loss=0.432]\u001b[A\n",
            "Epoch 1:   4%|▍         | 45/1161 [00:32<13:45,  1.35it/s, training_loss=0.419]\u001b[A\n",
            "Epoch 1:   4%|▍         | 46/1161 [00:32<13:46,  1.35it/s, training_loss=0.419]\u001b[A\n",
            "Epoch 1:   4%|▍         | 46/1161 [00:33<13:46,  1.35it/s, training_loss=0.345]\u001b[A\n",
            "Epoch 1:   4%|▍         | 47/1161 [00:33<13:44,  1.35it/s, training_loss=0.345]\u001b[A\n",
            "Epoch 1:   4%|▍         | 47/1161 [00:34<13:44,  1.35it/s, training_loss=0.389]\u001b[A\n",
            "Epoch 1:   4%|▍         | 48/1161 [00:34<13:48,  1.34it/s, training_loss=0.389]\u001b[A\n",
            "Epoch 1:   4%|▍         | 48/1161 [00:35<13:48,  1.34it/s, training_loss=0.372]\u001b[A\n",
            "Epoch 1:   4%|▍         | 49/1161 [00:35<13:48,  1.34it/s, training_loss=0.372]\u001b[A\n",
            "Epoch 1:   4%|▍         | 49/1161 [00:35<13:48,  1.34it/s, training_loss=0.344]\u001b[A\n",
            "Epoch 1:   4%|▍         | 50/1161 [00:35<13:46,  1.34it/s, training_loss=0.344]\u001b[A\n",
            "Epoch 1:   4%|▍         | 50/1161 [00:36<13:46,  1.34it/s, training_loss=0.393]\u001b[A\n",
            "Epoch 1:   4%|▍         | 51/1161 [00:36<13:47,  1.34it/s, training_loss=0.393]\u001b[A\n",
            "Epoch 1:   4%|▍         | 51/1161 [00:37<13:47,  1.34it/s, training_loss=0.333]\u001b[A\n",
            "Epoch 1:   4%|▍         | 52/1161 [00:37<13:47,  1.34it/s, training_loss=0.333]\u001b[A\n",
            "Epoch 1:   4%|▍         | 52/1161 [00:38<13:47,  1.34it/s, training_loss=0.346]\u001b[A\n",
            "Epoch 1:   5%|▍         | 53/1161 [00:38<13:46,  1.34it/s, training_loss=0.346]\u001b[A\n",
            "Epoch 1:   5%|▍         | 53/1161 [00:38<13:46,  1.34it/s, training_loss=0.344]\u001b[A\n",
            "Epoch 1:   5%|▍         | 54/1161 [00:38<13:46,  1.34it/s, training_loss=0.344]\u001b[A\n",
            "Epoch 1:   5%|▍         | 54/1161 [00:39<13:46,  1.34it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:   5%|▍         | 55/1161 [00:39<13:45,  1.34it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:   5%|▍         | 55/1161 [00:40<13:45,  1.34it/s, training_loss=0.336]\u001b[A\n",
            "Epoch 1:   5%|▍         | 56/1161 [00:40<13:47,  1.34it/s, training_loss=0.336]\u001b[A\n",
            "Epoch 1:   5%|▍         | 56/1161 [00:41<13:47,  1.34it/s, training_loss=0.368]\u001b[A\n",
            "Epoch 1:   5%|▍         | 57/1161 [00:41<13:48,  1.33it/s, training_loss=0.368]\u001b[A\n",
            "Epoch 1:   5%|▍         | 57/1161 [00:41<13:48,  1.33it/s, training_loss=0.387]\u001b[A\n",
            "Epoch 1:   5%|▍         | 58/1161 [00:41<13:48,  1.33it/s, training_loss=0.387]\u001b[A\n",
            "Epoch 1:   5%|▍         | 58/1161 [00:42<13:48,  1.33it/s, training_loss=0.307]\u001b[A\n",
            "Epoch 1:   5%|▌         | 59/1161 [00:42<13:49,  1.33it/s, training_loss=0.307]\u001b[A\n",
            "Epoch 1:   5%|▌         | 59/1161 [00:43<13:49,  1.33it/s, training_loss=0.433]\u001b[A\n",
            "Epoch 1:   5%|▌         | 60/1161 [00:43<13:48,  1.33it/s, training_loss=0.433]\u001b[A\n",
            "Epoch 1:   5%|▌         | 60/1161 [00:44<13:48,  1.33it/s, training_loss=0.498]\u001b[A\n",
            "Epoch 1:   5%|▌         | 61/1161 [00:44<13:47,  1.33it/s, training_loss=0.498]\u001b[A\n",
            "Epoch 1:   5%|▌         | 61/1161 [00:44<13:47,  1.33it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 1:   5%|▌         | 62/1161 [00:44<13:46,  1.33it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 1:   5%|▌         | 62/1161 [00:45<13:46,  1.33it/s, training_loss=0.392]\u001b[A\n",
            "Epoch 1:   5%|▌         | 63/1161 [00:45<13:45,  1.33it/s, training_loss=0.392]\u001b[A\n",
            "Epoch 1:   5%|▌         | 63/1161 [00:46<13:45,  1.33it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:   6%|▌         | 64/1161 [00:46<13:48,  1.32it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:   6%|▌         | 64/1161 [00:47<13:48,  1.32it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 1:   6%|▌         | 65/1161 [00:47<13:49,  1.32it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 1:   6%|▌         | 65/1161 [00:48<13:49,  1.32it/s, training_loss=0.351]\u001b[A\n",
            "Epoch 1:   6%|▌         | 66/1161 [00:48<13:48,  1.32it/s, training_loss=0.351]\u001b[A\n",
            "Epoch 1:   6%|▌         | 66/1161 [00:48<13:48,  1.32it/s, training_loss=0.341]\u001b[A\n",
            "Epoch 1:   6%|▌         | 67/1161 [00:48<13:49,  1.32it/s, training_loss=0.341]\u001b[A\n",
            "Epoch 1:   6%|▌         | 67/1161 [00:49<13:49,  1.32it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 1:   6%|▌         | 68/1161 [00:49<13:47,  1.32it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 1:   6%|▌         | 68/1161 [00:50<13:47,  1.32it/s, training_loss=0.367]\u001b[A\n",
            "Epoch 1:   6%|▌         | 69/1161 [00:50<13:48,  1.32it/s, training_loss=0.367]\u001b[A\n",
            "Epoch 1:   6%|▌         | 69/1161 [00:51<13:48,  1.32it/s, training_loss=0.420]\u001b[A\n",
            "Epoch 1:   6%|▌         | 70/1161 [00:51<13:50,  1.31it/s, training_loss=0.420]\u001b[A\n",
            "Epoch 1:   6%|▌         | 70/1161 [00:51<13:50,  1.31it/s, training_loss=0.249]\u001b[A\n",
            "Epoch 1:   6%|▌         | 71/1161 [00:51<13:49,  1.31it/s, training_loss=0.249]\u001b[A\n",
            "Epoch 1:   6%|▌         | 71/1161 [00:52<13:49,  1.31it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:   6%|▌         | 72/1161 [00:52<13:48,  1.31it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:   6%|▌         | 72/1161 [00:53<13:48,  1.31it/s, training_loss=0.338]\u001b[A\n",
            "Epoch 1:   6%|▋         | 73/1161 [00:53<13:48,  1.31it/s, training_loss=0.338]\u001b[A\n",
            "Epoch 1:   6%|▋         | 73/1161 [00:54<13:48,  1.31it/s, training_loss=0.276]\u001b[A\n",
            "Epoch 1:   6%|▋         | 74/1161 [00:54<13:49,  1.31it/s, training_loss=0.276]\u001b[A\n",
            "Epoch 1:   6%|▋         | 74/1161 [00:54<13:49,  1.31it/s, training_loss=0.544]\u001b[A\n",
            "Epoch 1:   6%|▋         | 75/1161 [00:54<13:46,  1.31it/s, training_loss=0.544]\u001b[A\n",
            "Epoch 1:   6%|▋         | 75/1161 [00:55<13:46,  1.31it/s, training_loss=0.341]\u001b[A\n",
            "Epoch 1:   7%|▋         | 76/1161 [00:55<13:43,  1.32it/s, training_loss=0.341]\u001b[A\n",
            "Epoch 1:   7%|▋         | 76/1161 [00:56<13:43,  1.32it/s, training_loss=0.343]\u001b[A\n",
            "Epoch 1:   7%|▋         | 77/1161 [00:56<13:41,  1.32it/s, training_loss=0.343]\u001b[A\n",
            "Epoch 1:   7%|▋         | 77/1161 [00:57<13:41,  1.32it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 1:   7%|▋         | 78/1161 [00:57<13:40,  1.32it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 1:   7%|▋         | 78/1161 [00:57<13:40,  1.32it/s, training_loss=0.441]\u001b[A\n",
            "Epoch 1:   7%|▋         | 79/1161 [00:57<13:38,  1.32it/s, training_loss=0.441]\u001b[A\n",
            "Epoch 1:   7%|▋         | 79/1161 [00:58<13:38,  1.32it/s, training_loss=0.304]\u001b[A\n",
            "Epoch 1:   7%|▋         | 80/1161 [00:58<13:36,  1.32it/s, training_loss=0.304]\u001b[A\n",
            "Epoch 1:   7%|▋         | 80/1161 [00:59<13:36,  1.32it/s, training_loss=0.316]\u001b[A\n",
            "Epoch 1:   7%|▋         | 81/1161 [00:59<13:36,  1.32it/s, training_loss=0.316]\u001b[A\n",
            "Epoch 1:   7%|▋         | 81/1161 [01:00<13:36,  1.32it/s, training_loss=0.325]\u001b[A\n",
            "Epoch 1:   7%|▋         | 82/1161 [01:00<13:34,  1.32it/s, training_loss=0.325]\u001b[A\n",
            "Epoch 1:   7%|▋         | 82/1161 [01:00<13:34,  1.32it/s, training_loss=0.320]\u001b[A\n",
            "Epoch 1:   7%|▋         | 83/1161 [01:00<13:30,  1.33it/s, training_loss=0.320]\u001b[A\n",
            "Epoch 1:   7%|▋         | 83/1161 [01:01<13:30,  1.33it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:   7%|▋         | 84/1161 [01:01<13:28,  1.33it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:   7%|▋         | 84/1161 [01:02<13:28,  1.33it/s, training_loss=0.421]\u001b[A\n",
            "Epoch 1:   7%|▋         | 85/1161 [01:02<13:24,  1.34it/s, training_loss=0.421]\u001b[A\n",
            "Epoch 1:   7%|▋         | 85/1161 [01:03<13:24,  1.34it/s, training_loss=0.601]\u001b[A\n",
            "Epoch 1:   7%|▋         | 86/1161 [01:03<13:21,  1.34it/s, training_loss=0.601]\u001b[A\n",
            "Epoch 1:   7%|▋         | 86/1161 [01:03<13:21,  1.34it/s, training_loss=0.306]\u001b[A\n",
            "Epoch 1:   7%|▋         | 87/1161 [01:03<13:20,  1.34it/s, training_loss=0.306]\u001b[A\n",
            "Epoch 1:   7%|▋         | 87/1161 [01:04<13:20,  1.34it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 1:   8%|▊         | 88/1161 [01:04<13:16,  1.35it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 1:   8%|▊         | 88/1161 [01:05<13:16,  1.35it/s, training_loss=0.417]\u001b[A\n",
            "Epoch 1:   8%|▊         | 89/1161 [01:05<13:13,  1.35it/s, training_loss=0.417]\u001b[A\n",
            "Epoch 1:   8%|▊         | 89/1161 [01:06<13:13,  1.35it/s, training_loss=0.288]\u001b[A\n",
            "Epoch 1:   8%|▊         | 90/1161 [01:06<13:09,  1.36it/s, training_loss=0.288]\u001b[A\n",
            "Epoch 1:   8%|▊         | 90/1161 [01:06<13:09,  1.36it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 1:   8%|▊         | 91/1161 [01:06<13:10,  1.35it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 1:   8%|▊         | 91/1161 [01:07<13:10,  1.35it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:   8%|▊         | 92/1161 [01:07<13:10,  1.35it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:   8%|▊         | 92/1161 [01:08<13:10,  1.35it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 1:   8%|▊         | 93/1161 [01:08<13:10,  1.35it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 1:   8%|▊         | 93/1161 [01:09<13:10,  1.35it/s, training_loss=0.376]\u001b[A\n",
            "Epoch 1:   8%|▊         | 94/1161 [01:09<13:08,  1.35it/s, training_loss=0.376]\u001b[A\n",
            "Epoch 1:   8%|▊         | 94/1161 [01:09<13:08,  1.35it/s, training_loss=0.319]\u001b[A\n",
            "Epoch 1:   8%|▊         | 95/1161 [01:09<13:09,  1.35it/s, training_loss=0.319]\u001b[A\n",
            "Epoch 1:   8%|▊         | 95/1161 [01:10<13:09,  1.35it/s, training_loss=0.327]\u001b[A\n",
            "Epoch 1:   8%|▊         | 96/1161 [01:10<13:06,  1.35it/s, training_loss=0.327]\u001b[A\n",
            "Epoch 1:   8%|▊         | 96/1161 [01:11<13:06,  1.35it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:   8%|▊         | 97/1161 [01:11<13:07,  1.35it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:   8%|▊         | 97/1161 [01:11<13:07,  1.35it/s, training_loss=0.325]\u001b[A\n",
            "Epoch 1:   8%|▊         | 98/1161 [01:12<13:07,  1.35it/s, training_loss=0.325]\u001b[A\n",
            "Epoch 1:   8%|▊         | 98/1161 [01:12<13:07,  1.35it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:   9%|▊         | 99/1161 [01:12<13:00,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:   9%|▊         | 99/1161 [01:13<13:00,  1.36it/s, training_loss=0.437]\u001b[A\n",
            "Epoch 1:   9%|▊         | 100/1161 [01:13<13:01,  1.36it/s, training_loss=0.437]\u001b[A\n",
            "Epoch 1:   9%|▊         | 100/1161 [01:14<13:01,  1.36it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:   9%|▊         | 101/1161 [01:14<12:57,  1.36it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:   9%|▊         | 101/1161 [01:14<12:57,  1.36it/s, training_loss=0.433]\u001b[A\n",
            "Epoch 1:   9%|▉         | 102/1161 [01:14<12:53,  1.37it/s, training_loss=0.433]\u001b[A\n",
            "Epoch 1:   9%|▉         | 102/1161 [01:15<12:53,  1.37it/s, training_loss=0.438]\u001b[A\n",
            "Epoch 1:   9%|▉         | 103/1161 [01:15<12:54,  1.37it/s, training_loss=0.438]\u001b[A\n",
            "Epoch 1:   9%|▉         | 103/1161 [01:16<12:54,  1.37it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 1:   9%|▉         | 104/1161 [01:16<12:53,  1.37it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 1:   9%|▉         | 104/1161 [01:17<12:53,  1.37it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:   9%|▉         | 105/1161 [01:17<12:54,  1.36it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:   9%|▉         | 105/1161 [01:17<12:54,  1.36it/s, training_loss=0.410]\u001b[A\n",
            "Epoch 1:   9%|▉         | 106/1161 [01:17<12:53,  1.36it/s, training_loss=0.410]\u001b[A\n",
            "Epoch 1:   9%|▉         | 106/1161 [01:18<12:53,  1.36it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:   9%|▉         | 107/1161 [01:18<12:53,  1.36it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:   9%|▉         | 107/1161 [01:19<12:53,  1.36it/s, training_loss=0.358]\u001b[A\n",
            "Epoch 1:   9%|▉         | 108/1161 [01:19<12:55,  1.36it/s, training_loss=0.358]\u001b[A\n",
            "Epoch 1:   9%|▉         | 108/1161 [01:20<12:55,  1.36it/s, training_loss=0.301]\u001b[A\n",
            "Epoch 1:   9%|▉         | 109/1161 [01:20<12:52,  1.36it/s, training_loss=0.301]\u001b[A\n",
            "Epoch 1:   9%|▉         | 109/1161 [01:20<12:52,  1.36it/s, training_loss=0.365]\u001b[A\n",
            "Epoch 1:   9%|▉         | 110/1161 [01:20<12:52,  1.36it/s, training_loss=0.365]\u001b[A\n",
            "Epoch 1:   9%|▉         | 110/1161 [01:21<12:52,  1.36it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  10%|▉         | 111/1161 [01:21<12:51,  1.36it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  10%|▉         | 111/1161 [01:22<12:51,  1.36it/s, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  10%|▉         | 112/1161 [01:22<12:48,  1.36it/s, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  10%|▉         | 112/1161 [01:22<12:48,  1.36it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  10%|▉         | 113/1161 [01:22<12:47,  1.36it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  10%|▉         | 113/1161 [01:23<12:47,  1.36it/s, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  10%|▉         | 114/1161 [01:23<12:46,  1.37it/s, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  10%|▉         | 114/1161 [01:24<12:46,  1.37it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  10%|▉         | 115/1161 [01:24<12:43,  1.37it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  10%|▉         | 115/1161 [01:25<12:43,  1.37it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  10%|▉         | 116/1161 [01:25<12:41,  1.37it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  10%|▉         | 116/1161 [01:25<12:41,  1.37it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  10%|█         | 117/1161 [01:25<12:42,  1.37it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  10%|█         | 117/1161 [01:26<12:42,  1.37it/s, training_loss=0.427]\u001b[A\n",
            "Epoch 1:  10%|█         | 118/1161 [01:26<12:39,  1.37it/s, training_loss=0.427]\u001b[A\n",
            "Epoch 1:  10%|█         | 118/1161 [01:27<12:39,  1.37it/s, training_loss=0.455]\u001b[A\n",
            "Epoch 1:  10%|█         | 119/1161 [01:27<12:35,  1.38it/s, training_loss=0.455]\u001b[A\n",
            "Epoch 1:  10%|█         | 119/1161 [01:28<12:35,  1.38it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 1:  10%|█         | 120/1161 [01:28<12:37,  1.37it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 1:  10%|█         | 120/1161 [01:28<12:37,  1.37it/s, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  10%|█         | 121/1161 [01:28<12:37,  1.37it/s, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  10%|█         | 121/1161 [01:29<12:37,  1.37it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  11%|█         | 122/1161 [01:29<12:35,  1.37it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  11%|█         | 122/1161 [01:30<12:35,  1.37it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  11%|█         | 123/1161 [01:30<12:35,  1.37it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  11%|█         | 123/1161 [01:30<12:35,  1.37it/s, training_loss=0.382]\u001b[A\n",
            "Epoch 1:  11%|█         | 124/1161 [01:30<12:32,  1.38it/s, training_loss=0.382]\u001b[A\n",
            "Epoch 1:  11%|█         | 124/1161 [01:31<12:32,  1.38it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  11%|█         | 125/1161 [01:31<12:29,  1.38it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  11%|█         | 125/1161 [01:32<12:29,  1.38it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  11%|█         | 126/1161 [01:32<12:28,  1.38it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  11%|█         | 126/1161 [01:33<12:28,  1.38it/s, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  11%|█         | 127/1161 [01:33<12:29,  1.38it/s, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  11%|█         | 127/1161 [01:33<12:29,  1.38it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  11%|█         | 128/1161 [01:33<12:27,  1.38it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  11%|█         | 128/1161 [01:34<12:27,  1.38it/s, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  11%|█         | 129/1161 [01:34<12:31,  1.37it/s, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  11%|█         | 129/1161 [01:35<12:31,  1.37it/s, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  11%|█         | 130/1161 [01:35<12:29,  1.37it/s, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  11%|█         | 130/1161 [01:36<12:29,  1.37it/s, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 131/1161 [01:36<12:31,  1.37it/s, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 131/1161 [01:36<12:31,  1.37it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 132/1161 [01:36<12:26,  1.38it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 132/1161 [01:37<12:26,  1.38it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 133/1161 [01:37<12:26,  1.38it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 133/1161 [01:38<12:26,  1.38it/s, training_loss=0.429]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 134/1161 [01:38<12:27,  1.37it/s, training_loss=0.429]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 134/1161 [01:38<12:27,  1.37it/s, training_loss=0.367]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 135/1161 [01:38<12:27,  1.37it/s, training_loss=0.367]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 135/1161 [01:39<12:27,  1.37it/s, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 136/1161 [01:39<12:28,  1.37it/s, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 136/1161 [01:40<12:28,  1.37it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 137/1161 [01:40<12:26,  1.37it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 137/1161 [01:41<12:26,  1.37it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 138/1161 [01:41<12:28,  1.37it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 138/1161 [01:41<12:28,  1.37it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 139/1161 [01:41<12:25,  1.37it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 139/1161 [01:42<12:25,  1.37it/s, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 140/1161 [01:42<12:26,  1.37it/s, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 140/1161 [01:43<12:26,  1.37it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 141/1161 [01:43<12:27,  1.36it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 141/1161 [01:44<12:27,  1.36it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 142/1161 [01:44<12:24,  1.37it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 142/1161 [01:44<12:24,  1.37it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 143/1161 [01:44<12:23,  1.37it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 143/1161 [01:45<12:23,  1.37it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 144/1161 [01:45<12:22,  1.37it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 144/1161 [01:46<12:22,  1.37it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 145/1161 [01:46<12:21,  1.37it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 145/1161 [01:47<12:21,  1.37it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 146/1161 [01:47<12:20,  1.37it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 146/1161 [01:47<12:20,  1.37it/s, training_loss=0.450]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 147/1161 [01:47<12:17,  1.37it/s, training_loss=0.450]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 147/1161 [01:48<12:17,  1.37it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 148/1161 [01:48<12:16,  1.38it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 148/1161 [01:49<12:16,  1.38it/s, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 149/1161 [01:49<12:17,  1.37it/s, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 149/1161 [01:49<12:17,  1.37it/s, training_loss=0.450]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 150/1161 [01:49<12:16,  1.37it/s, training_loss=0.450]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 150/1161 [01:50<12:16,  1.37it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 151/1161 [01:50<12:17,  1.37it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 151/1161 [01:51<12:17,  1.37it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 152/1161 [01:51<12:15,  1.37it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 152/1161 [01:52<12:15,  1.37it/s, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 153/1161 [01:52<12:18,  1.36it/s, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 153/1161 [01:52<12:18,  1.36it/s, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 154/1161 [01:52<12:17,  1.37it/s, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 154/1161 [01:53<12:17,  1.37it/s, training_loss=0.346]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 155/1161 [01:53<12:15,  1.37it/s, training_loss=0.346]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 155/1161 [01:54<12:15,  1.37it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 156/1161 [01:54<12:14,  1.37it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 156/1161 [01:55<12:14,  1.37it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 157/1161 [01:55<12:15,  1.36it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 157/1161 [01:55<12:15,  1.36it/s, training_loss=0.417]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 158/1161 [01:55<12:17,  1.36it/s, training_loss=0.417]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 158/1161 [01:56<12:17,  1.36it/s, training_loss=0.482]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 159/1161 [01:56<12:16,  1.36it/s, training_loss=0.482]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 159/1161 [01:57<12:16,  1.36it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 160/1161 [01:57<12:15,  1.36it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 160/1161 [01:57<12:15,  1.36it/s, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 161/1161 [01:58<12:15,  1.36it/s, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 161/1161 [01:58<12:15,  1.36it/s, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 162/1161 [01:58<12:14,  1.36it/s, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 162/1161 [01:59<12:14,  1.36it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 163/1161 [01:59<12:16,  1.36it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 163/1161 [02:00<12:16,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 164/1161 [02:00<12:16,  1.35it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 164/1161 [02:00<12:16,  1.35it/s, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 165/1161 [02:00<12:14,  1.36it/s, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 165/1161 [02:01<12:14,  1.36it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 166/1161 [02:01<12:11,  1.36it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 166/1161 [02:02<12:11,  1.36it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 167/1161 [02:02<12:12,  1.36it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 167/1161 [02:03<12:12,  1.36it/s, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 168/1161 [02:03<12:11,  1.36it/s, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 168/1161 [02:03<12:11,  1.36it/s, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 169/1161 [02:03<12:13,  1.35it/s, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 169/1161 [02:04<12:13,  1.35it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 170/1161 [02:04<12:12,  1.35it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 170/1161 [02:05<12:12,  1.35it/s, training_loss=0.406]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 171/1161 [02:05<12:11,  1.35it/s, training_loss=0.406]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 171/1161 [02:06<12:11,  1.35it/s, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 172/1161 [02:06<12:13,  1.35it/s, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 172/1161 [02:06<12:13,  1.35it/s, training_loss=0.525]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 173/1161 [02:06<12:12,  1.35it/s, training_loss=0.525]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 173/1161 [02:07<12:12,  1.35it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 174/1161 [02:07<12:11,  1.35it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 174/1161 [02:08<12:11,  1.35it/s, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 175/1161 [02:08<12:12,  1.35it/s, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 175/1161 [02:09<12:12,  1.35it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 176/1161 [02:09<12:11,  1.35it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 176/1161 [02:09<12:11,  1.35it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 177/1161 [02:09<12:08,  1.35it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 177/1161 [02:10<12:08,  1.35it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 178/1161 [02:10<12:09,  1.35it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 178/1161 [02:11<12:09,  1.35it/s, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 179/1161 [02:11<12:08,  1.35it/s, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 179/1161 [02:12<12:08,  1.35it/s, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 180/1161 [02:12<12:08,  1.35it/s, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 180/1161 [02:12<12:08,  1.35it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 181/1161 [02:12<12:05,  1.35it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 181/1161 [02:13<12:05,  1.35it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 182/1161 [02:13<12:03,  1.35it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 182/1161 [02:14<12:03,  1.35it/s, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 183/1161 [02:14<12:02,  1.35it/s, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 183/1161 [02:15<12:02,  1.35it/s, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 184/1161 [02:15<12:00,  1.36it/s, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 184/1161 [02:15<12:00,  1.36it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 185/1161 [02:15<12:02,  1.35it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 185/1161 [02:16<12:02,  1.35it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 186/1161 [02:16<12:03,  1.35it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 186/1161 [02:17<12:03,  1.35it/s, training_loss=0.365]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 187/1161 [02:17<12:06,  1.34it/s, training_loss=0.365]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 187/1161 [02:17<12:06,  1.34it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 188/1161 [02:18<12:03,  1.34it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 188/1161 [02:18<12:03,  1.34it/s, training_loss=0.476]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 189/1161 [02:18<12:03,  1.34it/s, training_loss=0.476]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 189/1161 [02:19<12:03,  1.34it/s, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 190/1161 [02:19<12:01,  1.35it/s, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 190/1161 [02:20<12:01,  1.35it/s, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 191/1161 [02:20<12:01,  1.34it/s, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 191/1161 [02:20<12:01,  1.34it/s, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 192/1161 [02:20<11:58,  1.35it/s, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 192/1161 [02:21<11:58,  1.35it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 193/1161 [02:21<11:58,  1.35it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 193/1161 [02:22<11:58,  1.35it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 194/1161 [02:22<11:56,  1.35it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 194/1161 [02:23<11:56,  1.35it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 195/1161 [02:23<11:54,  1.35it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 195/1161 [02:23<11:54,  1.35it/s, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 196/1161 [02:23<11:54,  1.35it/s, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 196/1161 [02:24<11:54,  1.35it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 197/1161 [02:24<11:51,  1.35it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 197/1161 [02:25<11:51,  1.35it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 198/1161 [02:25<11:51,  1.35it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 198/1161 [02:26<11:51,  1.35it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 199/1161 [02:26<11:51,  1.35it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 199/1161 [02:26<11:51,  1.35it/s, training_loss=0.588]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 200/1161 [02:26<11:52,  1.35it/s, training_loss=0.588]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 200/1161 [02:27<11:52,  1.35it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 201/1161 [02:27<11:51,  1.35it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 201/1161 [02:28<11:51,  1.35it/s, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 202/1161 [02:28<11:50,  1.35it/s, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 202/1161 [02:29<11:50,  1.35it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 203/1161 [02:29<11:49,  1.35it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 203/1161 [02:29<11:49,  1.35it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 204/1161 [02:29<11:47,  1.35it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 204/1161 [02:30<11:47,  1.35it/s, training_loss=0.377]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 205/1161 [02:30<11:46,  1.35it/s, training_loss=0.377]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 205/1161 [02:31<11:46,  1.35it/s, training_loss=0.426]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 206/1161 [02:31<11:47,  1.35it/s, training_loss=0.426]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 206/1161 [02:32<11:47,  1.35it/s, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 207/1161 [02:32<11:45,  1.35it/s, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 207/1161 [02:32<11:45,  1.35it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 208/1161 [02:32<11:46,  1.35it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 208/1161 [02:33<11:46,  1.35it/s, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 209/1161 [02:33<11:44,  1.35it/s, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 209/1161 [02:34<11:44,  1.35it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 210/1161 [02:34<11:41,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 210/1161 [02:35<11:41,  1.36it/s, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 211/1161 [02:35<11:41,  1.35it/s, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 211/1161 [02:35<11:41,  1.35it/s, training_loss=0.435]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 212/1161 [02:35<11:40,  1.36it/s, training_loss=0.435]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 212/1161 [02:36<11:40,  1.36it/s, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 213/1161 [02:36<11:39,  1.36it/s, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 213/1161 [02:37<11:39,  1.36it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 214/1161 [02:37<11:38,  1.36it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 214/1161 [02:37<11:38,  1.36it/s, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 215/1161 [02:37<11:38,  1.35it/s, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 215/1161 [02:38<11:38,  1.35it/s, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 216/1161 [02:38<11:36,  1.36it/s, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 216/1161 [02:39<11:36,  1.36it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 217/1161 [02:39<11:37,  1.35it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 217/1161 [02:40<11:37,  1.35it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 218/1161 [02:40<11:37,  1.35it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 218/1161 [02:40<11:37,  1.35it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 219/1161 [02:40<11:38,  1.35it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 219/1161 [02:41<11:38,  1.35it/s, training_loss=0.472]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 220/1161 [02:41<11:35,  1.35it/s, training_loss=0.472]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 220/1161 [02:42<11:35,  1.35it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 221/1161 [02:42<11:34,  1.35it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 221/1161 [02:43<11:34,  1.35it/s, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 222/1161 [02:43<11:35,  1.35it/s, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 222/1161 [02:43<11:35,  1.35it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 223/1161 [02:43<11:33,  1.35it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 223/1161 [02:44<11:33,  1.35it/s, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 224/1161 [02:44<11:33,  1.35it/s, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 224/1161 [02:45<11:33,  1.35it/s, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 225/1161 [02:45<11:29,  1.36it/s, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 225/1161 [02:46<11:29,  1.36it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 226/1161 [02:46<11:27,  1.36it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 226/1161 [02:46<11:27,  1.36it/s, training_loss=0.318]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 227/1161 [02:46<11:23,  1.37it/s, training_loss=0.318]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 227/1161 [02:47<11:23,  1.37it/s, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 228/1161 [02:47<11:25,  1.36it/s, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 228/1161 [02:48<11:25,  1.36it/s, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 229/1161 [02:48<11:22,  1.37it/s, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 229/1161 [02:49<11:22,  1.37it/s, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 230/1161 [02:49<11:25,  1.36it/s, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 230/1161 [02:49<11:25,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 231/1161 [02:49<11:23,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 231/1161 [02:50<11:23,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 232/1161 [02:50<11:23,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 232/1161 [02:51<11:23,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  20%|██        | 233/1161 [02:51<11:23,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  20%|██        | 233/1161 [02:51<11:23,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  20%|██        | 234/1161 [02:51<11:20,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  20%|██        | 234/1161 [02:52<11:20,  1.36it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  20%|██        | 235/1161 [02:52<11:20,  1.36it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  20%|██        | 235/1161 [02:53<11:20,  1.36it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  20%|██        | 236/1161 [02:53<11:19,  1.36it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  20%|██        | 236/1161 [02:54<11:19,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  20%|██        | 237/1161 [02:54<11:18,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  20%|██        | 237/1161 [02:54<11:18,  1.36it/s, training_loss=0.500]\u001b[A\n",
            "Epoch 1:  20%|██        | 238/1161 [02:54<11:16,  1.36it/s, training_loss=0.500]\u001b[A\n",
            "Epoch 1:  20%|██        | 238/1161 [02:55<11:16,  1.36it/s, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  21%|██        | 239/1161 [02:55<11:17,  1.36it/s, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  21%|██        | 239/1161 [02:56<11:17,  1.36it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  21%|██        | 240/1161 [02:56<11:15,  1.36it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  21%|██        | 240/1161 [02:57<11:15,  1.36it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  21%|██        | 241/1161 [02:57<11:14,  1.36it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  21%|██        | 241/1161 [02:57<11:14,  1.36it/s, training_loss=0.395]\u001b[A\n",
            "Epoch 1:  21%|██        | 242/1161 [02:57<11:13,  1.36it/s, training_loss=0.395]\u001b[A\n",
            "Epoch 1:  21%|██        | 242/1161 [02:58<11:13,  1.36it/s, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  21%|██        | 243/1161 [02:58<11:11,  1.37it/s, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  21%|██        | 243/1161 [02:59<11:11,  1.37it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  21%|██        | 244/1161 [02:59<11:16,  1.36it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  21%|██        | 244/1161 [03:00<11:16,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  21%|██        | 245/1161 [03:00<11:11,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  21%|██        | 245/1161 [03:00<11:11,  1.36it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  21%|██        | 246/1161 [03:00<11:14,  1.36it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  21%|██        | 246/1161 [03:01<11:14,  1.36it/s, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 247/1161 [03:01<11:13,  1.36it/s, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 247/1161 [03:02<11:13,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 248/1161 [03:02<11:12,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 248/1161 [03:02<11:12,  1.36it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 249/1161 [03:02<11:11,  1.36it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 249/1161 [03:03<11:11,  1.36it/s, training_loss=0.318]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 250/1161 [03:03<11:07,  1.36it/s, training_loss=0.318]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 250/1161 [03:04<11:07,  1.36it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 251/1161 [03:04<11:06,  1.37it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 251/1161 [03:05<11:06,  1.37it/s, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 252/1161 [03:05<11:09,  1.36it/s, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 252/1161 [03:05<11:09,  1.36it/s, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 253/1161 [03:05<11:05,  1.36it/s, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 253/1161 [03:06<11:05,  1.36it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 254/1161 [03:06<11:06,  1.36it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 254/1161 [03:07<11:06,  1.36it/s, training_loss=0.465]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 255/1161 [03:07<11:02,  1.37it/s, training_loss=0.465]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 255/1161 [03:08<11:02,  1.37it/s, training_loss=0.509]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 256/1161 [03:08<11:02,  1.37it/s, training_loss=0.509]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 256/1161 [03:08<11:02,  1.37it/s, training_loss=0.385]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 257/1161 [03:08<11:00,  1.37it/s, training_loss=0.385]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 257/1161 [03:09<11:00,  1.37it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 258/1161 [03:09<11:00,  1.37it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 258/1161 [03:10<11:00,  1.37it/s, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 259/1161 [03:10<11:03,  1.36it/s, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 259/1161 [03:11<11:03,  1.36it/s, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 260/1161 [03:11<11:01,  1.36it/s, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 260/1161 [03:11<11:01,  1.36it/s, training_loss=0.413]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 261/1161 [03:11<11:02,  1.36it/s, training_loss=0.413]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 261/1161 [03:12<11:02,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 262/1161 [03:12<11:02,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 262/1161 [03:13<11:02,  1.36it/s, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 263/1161 [03:13<11:00,  1.36it/s, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 263/1161 [03:14<11:00,  1.36it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 264/1161 [03:14<10:59,  1.36it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 264/1161 [03:14<10:59,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 265/1161 [03:14<10:57,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 265/1161 [03:15<10:57,  1.36it/s, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 266/1161 [03:15<10:56,  1.36it/s, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 266/1161 [03:16<10:56,  1.36it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 267/1161 [03:16<10:55,  1.36it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 267/1161 [03:16<10:55,  1.36it/s, training_loss=0.393]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 268/1161 [03:16<10:55,  1.36it/s, training_loss=0.393]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 268/1161 [03:17<10:55,  1.36it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 269/1161 [03:17<10:54,  1.36it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 269/1161 [03:18<10:54,  1.36it/s, training_loss=0.490]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 270/1161 [03:18<10:55,  1.36it/s, training_loss=0.490]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 270/1161 [03:19<10:55,  1.36it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 271/1161 [03:19<10:55,  1.36it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 271/1161 [03:19<10:55,  1.36it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 272/1161 [03:19<10:52,  1.36it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 272/1161 [03:20<10:52,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 273/1161 [03:20<10:51,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 273/1161 [03:21<10:51,  1.36it/s, training_loss=0.338]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 274/1161 [03:21<10:49,  1.37it/s, training_loss=0.338]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 274/1161 [03:22<10:49,  1.37it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 275/1161 [03:22<10:49,  1.36it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 275/1161 [03:22<10:49,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 276/1161 [03:22<10:50,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 276/1161 [03:23<10:50,  1.36it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 277/1161 [03:23<10:49,  1.36it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 277/1161 [03:24<10:49,  1.36it/s, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 278/1161 [03:24<10:48,  1.36it/s, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 278/1161 [03:25<10:48,  1.36it/s, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 279/1161 [03:25<10:47,  1.36it/s, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 279/1161 [03:25<10:47,  1.36it/s, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 280/1161 [03:25<10:47,  1.36it/s, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 280/1161 [03:26<10:47,  1.36it/s, training_loss=0.344]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 281/1161 [03:26<10:44,  1.37it/s, training_loss=0.344]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 281/1161 [03:27<10:44,  1.37it/s, training_loss=0.398]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 282/1161 [03:27<10:44,  1.36it/s, training_loss=0.398]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 282/1161 [03:27<10:44,  1.36it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 283/1161 [03:27<10:42,  1.37it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 283/1161 [03:28<10:42,  1.37it/s, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 284/1161 [03:28<10:43,  1.36it/s, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 284/1161 [03:29<10:43,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 285/1161 [03:29<10:42,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 285/1161 [03:30<10:42,  1.36it/s, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 286/1161 [03:30<10:42,  1.36it/s, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 286/1161 [03:30<10:42,  1.36it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 287/1161 [03:30<10:41,  1.36it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 287/1161 [03:31<10:41,  1.36it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 288/1161 [03:31<10:42,  1.36it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 288/1161 [03:32<10:42,  1.36it/s, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 289/1161 [03:32<10:42,  1.36it/s, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 289/1161 [03:33<10:42,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 290/1161 [03:33<10:39,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 290/1161 [03:33<10:39,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 291/1161 [03:33<10:37,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 291/1161 [03:34<10:37,  1.36it/s, training_loss=0.391]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 292/1161 [03:34<10:35,  1.37it/s, training_loss=0.391]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 292/1161 [03:35<10:35,  1.37it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 293/1161 [03:35<10:35,  1.37it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 293/1161 [03:36<10:35,  1.37it/s, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 294/1161 [03:36<10:34,  1.37it/s, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 294/1161 [03:36<10:34,  1.37it/s, training_loss=0.415]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 295/1161 [03:36<10:33,  1.37it/s, training_loss=0.415]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 295/1161 [03:37<10:33,  1.37it/s, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 296/1161 [03:37<10:33,  1.36it/s, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 296/1161 [03:38<10:33,  1.36it/s, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 297/1161 [03:38<10:32,  1.37it/s, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 297/1161 [03:38<10:32,  1.37it/s, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 298/1161 [03:38<10:29,  1.37it/s, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 298/1161 [03:39<10:29,  1.37it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 299/1161 [03:39<10:30,  1.37it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 299/1161 [03:40<10:30,  1.37it/s, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 300/1161 [03:40<10:31,  1.36it/s, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 300/1161 [03:41<10:31,  1.36it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 301/1161 [03:41<10:30,  1.36it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 301/1161 [03:41<10:30,  1.36it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 302/1161 [03:41<10:31,  1.36it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 302/1161 [03:42<10:31,  1.36it/s, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 303/1161 [03:42<10:29,  1.36it/s, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 303/1161 [03:43<10:29,  1.36it/s, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 304/1161 [03:43<10:31,  1.36it/s, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 304/1161 [03:44<10:31,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 305/1161 [03:44<10:31,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 305/1161 [03:44<10:31,  1.36it/s, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 306/1161 [03:44<10:32,  1.35it/s, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 306/1161 [03:45<10:32,  1.35it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 307/1161 [03:45<10:30,  1.35it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 307/1161 [03:46<10:30,  1.35it/s, training_loss=0.344]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 308/1161 [03:46<10:30,  1.35it/s, training_loss=0.344]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 308/1161 [03:47<10:30,  1.35it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 309/1161 [03:47<10:31,  1.35it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 309/1161 [03:47<10:31,  1.35it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 310/1161 [03:47<10:30,  1.35it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 310/1161 [03:48<10:30,  1.35it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 311/1161 [03:48<10:29,  1.35it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 311/1161 [03:49<10:29,  1.35it/s, training_loss=0.332]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 312/1161 [03:49<10:30,  1.35it/s, training_loss=0.332]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 312/1161 [03:50<10:30,  1.35it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 313/1161 [03:50<10:26,  1.35it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 313/1161 [03:50<10:26,  1.35it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 314/1161 [03:50<10:26,  1.35it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 314/1161 [03:51<10:26,  1.35it/s, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 315/1161 [03:51<10:24,  1.36it/s, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 315/1161 [03:52<10:24,  1.36it/s, training_loss=0.410]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 316/1161 [03:52<10:22,  1.36it/s, training_loss=0.410]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 316/1161 [03:52<10:22,  1.36it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 317/1161 [03:52<10:22,  1.36it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 317/1161 [03:53<10:22,  1.36it/s, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 318/1161 [03:53<10:20,  1.36it/s, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 318/1161 [03:54<10:20,  1.36it/s, training_loss=0.418]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 319/1161 [03:54<10:19,  1.36it/s, training_loss=0.418]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 319/1161 [03:55<10:19,  1.36it/s, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 320/1161 [03:55<10:18,  1.36it/s, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 320/1161 [03:55<10:18,  1.36it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 321/1161 [03:55<10:17,  1.36it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 321/1161 [03:56<10:17,  1.36it/s, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 322/1161 [03:56<10:16,  1.36it/s, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 322/1161 [03:57<10:16,  1.36it/s, training_loss=0.391]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 323/1161 [03:57<10:16,  1.36it/s, training_loss=0.391]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 323/1161 [03:58<10:16,  1.36it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 324/1161 [03:58<10:14,  1.36it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 324/1161 [03:58<10:14,  1.36it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 325/1161 [03:58<10:15,  1.36it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 325/1161 [03:59<10:15,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 326/1161 [03:59<10:13,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 326/1161 [04:00<10:13,  1.36it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 327/1161 [04:00<10:14,  1.36it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 327/1161 [04:01<10:14,  1.36it/s, training_loss=0.363]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 328/1161 [04:01<10:13,  1.36it/s, training_loss=0.363]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 328/1161 [04:01<10:13,  1.36it/s, training_loss=0.354]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 329/1161 [04:01<10:13,  1.36it/s, training_loss=0.354]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 329/1161 [04:02<10:13,  1.36it/s, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 330/1161 [04:02<10:11,  1.36it/s, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 330/1161 [04:03<10:11,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 331/1161 [04:03<10:09,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 331/1161 [04:03<10:09,  1.36it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 332/1161 [04:03<10:09,  1.36it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 332/1161 [04:04<10:09,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 333/1161 [04:04<10:09,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 333/1161 [04:05<10:09,  1.36it/s, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 334/1161 [04:05<10:06,  1.36it/s, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 334/1161 [04:06<10:06,  1.36it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 335/1161 [04:06<10:10,  1.35it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 335/1161 [04:06<10:10,  1.35it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 336/1161 [04:06<10:07,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 336/1161 [04:07<10:07,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 337/1161 [04:07<10:06,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 337/1161 [04:08<10:06,  1.36it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 338/1161 [04:08<10:08,  1.35it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 338/1161 [04:09<10:08,  1.35it/s, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 339/1161 [04:09<10:08,  1.35it/s, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 339/1161 [04:09<10:08,  1.35it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 340/1161 [04:09<10:09,  1.35it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 340/1161 [04:10<10:09,  1.35it/s, training_loss=0.390]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 341/1161 [04:10<10:06,  1.35it/s, training_loss=0.390]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 341/1161 [04:11<10:06,  1.35it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 342/1161 [04:11<10:08,  1.35it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 342/1161 [04:12<10:08,  1.35it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 343/1161 [04:12<10:07,  1.35it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 343/1161 [04:12<10:07,  1.35it/s, training_loss=0.350]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 344/1161 [04:12<10:05,  1.35it/s, training_loss=0.350]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 344/1161 [04:13<10:05,  1.35it/s, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 345/1161 [04:13<10:04,  1.35it/s, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 345/1161 [04:14<10:04,  1.35it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 346/1161 [04:14<10:04,  1.35it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 346/1161 [04:15<10:04,  1.35it/s, training_loss=0.376]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 347/1161 [04:15<10:00,  1.35it/s, training_loss=0.376]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 347/1161 [04:15<10:00,  1.35it/s, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 348/1161 [04:15<10:00,  1.35it/s, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 348/1161 [04:16<10:00,  1.35it/s, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  30%|███       | 349/1161 [04:16<09:58,  1.36it/s, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  30%|███       | 349/1161 [04:17<09:58,  1.36it/s, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  30%|███       | 350/1161 [04:17<09:57,  1.36it/s, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  30%|███       | 350/1161 [04:18<09:57,  1.36it/s, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  30%|███       | 351/1161 [04:18<09:55,  1.36it/s, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  30%|███       | 351/1161 [04:18<09:55,  1.36it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  30%|███       | 352/1161 [04:18<09:54,  1.36it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  30%|███       | 352/1161 [04:19<09:54,  1.36it/s, training_loss=0.328]\u001b[A\n",
            "Epoch 1:  30%|███       | 353/1161 [04:19<09:54,  1.36it/s, training_loss=0.328]\u001b[A\n",
            "Epoch 1:  30%|███       | 353/1161 [04:20<09:54,  1.36it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  30%|███       | 354/1161 [04:20<09:53,  1.36it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  30%|███       | 354/1161 [04:20<09:53,  1.36it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  31%|███       | 355/1161 [04:20<09:52,  1.36it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  31%|███       | 355/1161 [04:21<09:52,  1.36it/s, training_loss=0.318]\u001b[A\n",
            "Epoch 1:  31%|███       | 356/1161 [04:21<09:51,  1.36it/s, training_loss=0.318]\u001b[A\n",
            "Epoch 1:  31%|███       | 356/1161 [04:22<09:51,  1.36it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  31%|███       | 357/1161 [04:22<09:49,  1.36it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  31%|███       | 357/1161 [04:23<09:49,  1.36it/s, training_loss=0.412]\u001b[A\n",
            "Epoch 1:  31%|███       | 358/1161 [04:23<09:47,  1.37it/s, training_loss=0.412]\u001b[A\n",
            "Epoch 1:  31%|███       | 358/1161 [04:23<09:47,  1.37it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  31%|███       | 359/1161 [04:23<09:47,  1.37it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  31%|███       | 359/1161 [04:24<09:47,  1.37it/s, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  31%|███       | 360/1161 [04:24<09:47,  1.36it/s, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  31%|███       | 360/1161 [04:25<09:47,  1.36it/s, training_loss=0.403]\u001b[A\n",
            "Epoch 1:  31%|███       | 361/1161 [04:25<09:49,  1.36it/s, training_loss=0.403]\u001b[A\n",
            "Epoch 1:  31%|███       | 361/1161 [04:26<09:49,  1.36it/s, training_loss=0.393]\u001b[A\n",
            "Epoch 1:  31%|███       | 362/1161 [04:26<09:46,  1.36it/s, training_loss=0.393]\u001b[A\n",
            "Epoch 1:  31%|███       | 362/1161 [04:26<09:46,  1.36it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 363/1161 [04:26<09:46,  1.36it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 363/1161 [04:27<09:46,  1.36it/s, training_loss=0.328]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 364/1161 [04:27<09:43,  1.36it/s, training_loss=0.328]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 364/1161 [04:28<09:43,  1.36it/s, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 365/1161 [04:28<09:43,  1.37it/s, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 365/1161 [04:29<09:43,  1.37it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 366/1161 [04:29<09:41,  1.37it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 366/1161 [04:29<09:41,  1.37it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 367/1161 [04:29<09:42,  1.36it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 367/1161 [04:30<09:42,  1.36it/s, training_loss=0.318]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 368/1161 [04:30<09:41,  1.36it/s, training_loss=0.318]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 368/1161 [04:31<09:41,  1.36it/s, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 369/1161 [04:31<09:39,  1.37it/s, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 369/1161 [04:31<09:39,  1.37it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 370/1161 [04:31<09:39,  1.37it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 370/1161 [04:32<09:39,  1.37it/s, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 371/1161 [04:32<09:39,  1.36it/s, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 371/1161 [04:33<09:39,  1.36it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 372/1161 [04:33<09:38,  1.36it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 372/1161 [04:34<09:38,  1.36it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 373/1161 [04:34<09:40,  1.36it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 373/1161 [04:34<09:40,  1.36it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 374/1161 [04:34<09:43,  1.35it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 374/1161 [04:35<09:43,  1.35it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 375/1161 [04:35<09:42,  1.35it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 375/1161 [04:36<09:42,  1.35it/s, training_loss=0.431]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 376/1161 [04:36<09:39,  1.36it/s, training_loss=0.431]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 376/1161 [04:37<09:39,  1.36it/s, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 377/1161 [04:37<09:35,  1.36it/s, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 377/1161 [04:37<09:35,  1.36it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 378/1161 [04:37<09:34,  1.36it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 378/1161 [04:38<09:34,  1.36it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 379/1161 [04:38<09:33,  1.36it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 379/1161 [04:39<09:33,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 380/1161 [04:39<09:32,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 380/1161 [04:40<09:32,  1.36it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 381/1161 [04:40<09:32,  1.36it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 381/1161 [04:40<09:32,  1.36it/s, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 382/1161 [04:40<09:32,  1.36it/s, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 382/1161 [04:41<09:32,  1.36it/s, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 383/1161 [04:41<09:35,  1.35it/s, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 383/1161 [04:42<09:35,  1.35it/s, training_loss=0.426]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 384/1161 [04:42<09:32,  1.36it/s, training_loss=0.426]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 384/1161 [04:43<09:32,  1.36it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 385/1161 [04:43<09:34,  1.35it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 385/1161 [04:43<09:34,  1.35it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 386/1161 [04:43<09:31,  1.36it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 386/1161 [04:44<09:31,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 387/1161 [04:44<09:31,  1.35it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 387/1161 [04:45<09:31,  1.35it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 388/1161 [04:45<09:30,  1.36it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 388/1161 [04:45<09:30,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 389/1161 [04:45<09:29,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 389/1161 [04:46<09:29,  1.36it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 390/1161 [04:46<09:28,  1.36it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 390/1161 [04:47<09:28,  1.36it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 391/1161 [04:47<09:27,  1.36it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 391/1161 [04:48<09:27,  1.36it/s, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 392/1161 [04:48<09:27,  1.36it/s, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 392/1161 [04:48<09:27,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 393/1161 [04:48<09:25,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 393/1161 [04:49<09:25,  1.36it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 394/1161 [04:49<09:23,  1.36it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 394/1161 [04:50<09:23,  1.36it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 395/1161 [04:50<09:21,  1.37it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 395/1161 [04:51<09:21,  1.37it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 396/1161 [04:51<09:21,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 396/1161 [04:51<09:21,  1.36it/s, training_loss=0.420]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 397/1161 [04:51<09:18,  1.37it/s, training_loss=0.420]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 397/1161 [04:52<09:18,  1.37it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 398/1161 [04:52<09:22,  1.36it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 398/1161 [04:53<09:22,  1.36it/s, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 399/1161 [04:53<09:20,  1.36it/s, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 399/1161 [04:54<09:20,  1.36it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 400/1161 [04:54<09:20,  1.36it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 400/1161 [04:54<09:20,  1.36it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 401/1161 [04:54<09:19,  1.36it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 401/1161 [04:55<09:19,  1.36it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 402/1161 [04:55<09:18,  1.36it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 402/1161 [04:56<09:18,  1.36it/s, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 403/1161 [04:56<09:17,  1.36it/s, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 403/1161 [04:56<09:17,  1.36it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 404/1161 [04:56<09:16,  1.36it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 404/1161 [04:57<09:16,  1.36it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 405/1161 [04:57<09:15,  1.36it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 405/1161 [04:58<09:15,  1.36it/s, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 406/1161 [04:58<09:17,  1.35it/s, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 406/1161 [04:59<09:17,  1.35it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 407/1161 [04:59<09:18,  1.35it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 407/1161 [04:59<09:18,  1.35it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 408/1161 [04:59<09:20,  1.34it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 408/1161 [05:00<09:20,  1.34it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 409/1161 [05:00<09:17,  1.35it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 409/1161 [05:01<09:17,  1.35it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 410/1161 [05:01<09:17,  1.35it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 410/1161 [05:02<09:17,  1.35it/s, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 411/1161 [05:02<09:16,  1.35it/s, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 411/1161 [05:02<09:16,  1.35it/s, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 412/1161 [05:02<09:11,  1.36it/s, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 412/1161 [05:03<09:11,  1.36it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 413/1161 [05:03<09:12,  1.35it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 413/1161 [05:04<09:12,  1.35it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 414/1161 [05:04<09:10,  1.36it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 414/1161 [05:05<09:10,  1.36it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 415/1161 [05:05<09:10,  1.36it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 415/1161 [05:05<09:10,  1.36it/s, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 416/1161 [05:05<09:08,  1.36it/s, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 416/1161 [05:06<09:08,  1.36it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 417/1161 [05:06<09:07,  1.36it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 417/1161 [05:07<09:07,  1.36it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 418/1161 [05:07<09:06,  1.36it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 418/1161 [05:08<09:06,  1.36it/s, training_loss=0.392]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 419/1161 [05:08<09:07,  1.35it/s, training_loss=0.392]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 419/1161 [05:08<09:07,  1.35it/s, training_loss=0.427]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 420/1161 [05:08<09:06,  1.36it/s, training_loss=0.427]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 420/1161 [05:09<09:06,  1.36it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 421/1161 [05:09<09:07,  1.35it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 421/1161 [05:10<09:07,  1.35it/s, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 422/1161 [05:10<09:05,  1.35it/s, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 422/1161 [05:11<09:05,  1.35it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 423/1161 [05:11<09:04,  1.36it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 423/1161 [05:11<09:04,  1.36it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 424/1161 [05:11<09:04,  1.35it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 424/1161 [05:12<09:04,  1.35it/s, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 425/1161 [05:12<09:03,  1.35it/s, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 425/1161 [05:13<09:03,  1.35it/s, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 426/1161 [05:13<09:04,  1.35it/s, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 426/1161 [05:13<09:04,  1.35it/s, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 427/1161 [05:13<09:02,  1.35it/s, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 427/1161 [05:14<09:02,  1.35it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 428/1161 [05:14<08:59,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 428/1161 [05:15<08:59,  1.36it/s, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 429/1161 [05:15<08:57,  1.36it/s, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 429/1161 [05:16<08:57,  1.36it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 430/1161 [05:16<08:58,  1.36it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 430/1161 [05:16<08:58,  1.36it/s, training_loss=0.349]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 431/1161 [05:16<08:58,  1.36it/s, training_loss=0.349]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 431/1161 [05:17<08:58,  1.36it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 432/1161 [05:17<08:57,  1.36it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 432/1161 [05:18<08:57,  1.36it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 433/1161 [05:18<08:55,  1.36it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 433/1161 [05:19<08:55,  1.36it/s, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 434/1161 [05:19<08:55,  1.36it/s, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 434/1161 [05:19<08:55,  1.36it/s, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 435/1161 [05:19<08:54,  1.36it/s, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 435/1161 [05:20<08:54,  1.36it/s, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 436/1161 [05:20<08:53,  1.36it/s, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 436/1161 [05:21<08:53,  1.36it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 437/1161 [05:21<08:50,  1.36it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 437/1161 [05:22<08:50,  1.36it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 438/1161 [05:22<08:51,  1.36it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 438/1161 [05:22<08:51,  1.36it/s, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 439/1161 [05:22<08:51,  1.36it/s, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 439/1161 [05:23<08:51,  1.36it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 440/1161 [05:23<08:53,  1.35it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 440/1161 [05:24<08:53,  1.35it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 441/1161 [05:24<08:52,  1.35it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 441/1161 [05:25<08:52,  1.35it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 442/1161 [05:25<08:49,  1.36it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 442/1161 [05:25<08:49,  1.36it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 443/1161 [05:25<08:49,  1.36it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 443/1161 [05:26<08:49,  1.36it/s, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 444/1161 [05:26<08:48,  1.36it/s, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 444/1161 [05:27<08:48,  1.36it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 445/1161 [05:27<08:47,  1.36it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 445/1161 [05:27<08:47,  1.36it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 446/1161 [05:27<08:46,  1.36it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 446/1161 [05:28<08:46,  1.36it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 447/1161 [05:28<08:44,  1.36it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 447/1161 [05:29<08:44,  1.36it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 448/1161 [05:29<08:43,  1.36it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 448/1161 [05:30<08:43,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 449/1161 [05:30<08:43,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 449/1161 [05:30<08:43,  1.36it/s, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 450/1161 [05:30<08:41,  1.36it/s, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 450/1161 [05:31<08:41,  1.36it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 451/1161 [05:31<08:40,  1.36it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 451/1161 [05:32<08:40,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 452/1161 [05:32<08:37,  1.37it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 452/1161 [05:33<08:37,  1.37it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 453/1161 [05:33<08:37,  1.37it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 453/1161 [05:33<08:37,  1.37it/s, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 454/1161 [05:33<08:35,  1.37it/s, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 454/1161 [05:34<08:35,  1.37it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 455/1161 [05:34<08:36,  1.37it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 455/1161 [05:35<08:36,  1.37it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 456/1161 [05:35<08:36,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 456/1161 [05:36<08:36,  1.36it/s, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 457/1161 [05:36<08:37,  1.36it/s, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 457/1161 [05:36<08:37,  1.36it/s, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 458/1161 [05:36<08:36,  1.36it/s, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 458/1161 [05:37<08:36,  1.36it/s, training_loss=0.383]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 459/1161 [05:37<08:35,  1.36it/s, training_loss=0.383]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 459/1161 [05:38<08:35,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 460/1161 [05:38<08:34,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 460/1161 [05:38<08:34,  1.36it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 461/1161 [05:38<08:33,  1.36it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 461/1161 [05:39<08:33,  1.36it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 462/1161 [05:39<08:33,  1.36it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 462/1161 [05:40<08:33,  1.36it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 463/1161 [05:40<08:32,  1.36it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 463/1161 [05:41<08:32,  1.36it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 464/1161 [05:41<08:31,  1.36it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 464/1161 [05:41<08:31,  1.36it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  40%|████      | 465/1161 [05:41<08:33,  1.36it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  40%|████      | 465/1161 [05:42<08:33,  1.36it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  40%|████      | 466/1161 [05:42<08:32,  1.36it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  40%|████      | 466/1161 [05:43<08:32,  1.36it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  40%|████      | 467/1161 [05:43<08:32,  1.35it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  40%|████      | 467/1161 [05:44<08:32,  1.35it/s, training_loss=0.429]\u001b[A\n",
            "Epoch 1:  40%|████      | 468/1161 [05:44<08:30,  1.36it/s, training_loss=0.429]\u001b[A\n",
            "Epoch 1:  40%|████      | 468/1161 [05:44<08:30,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  40%|████      | 469/1161 [05:44<08:29,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  40%|████      | 469/1161 [05:45<08:29,  1.36it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  40%|████      | 470/1161 [05:45<08:27,  1.36it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  40%|████      | 470/1161 [05:46<08:27,  1.36it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:  41%|████      | 471/1161 [05:46<08:25,  1.37it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:  41%|████      | 471/1161 [05:47<08:25,  1.37it/s, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  41%|████      | 472/1161 [05:47<08:24,  1.37it/s, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  41%|████      | 472/1161 [05:47<08:24,  1.37it/s, training_loss=0.367]\u001b[A\n",
            "Epoch 1:  41%|████      | 473/1161 [05:47<08:23,  1.37it/s, training_loss=0.367]\u001b[A\n",
            "Epoch 1:  41%|████      | 473/1161 [05:48<08:23,  1.37it/s, training_loss=0.423]\u001b[A\n",
            "Epoch 1:  41%|████      | 474/1161 [05:48<08:21,  1.37it/s, training_loss=0.423]\u001b[A\n",
            "Epoch 1:  41%|████      | 474/1161 [05:49<08:21,  1.37it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  41%|████      | 475/1161 [05:49<08:22,  1.37it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  41%|████      | 475/1161 [05:49<08:22,  1.37it/s, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  41%|████      | 476/1161 [05:49<08:20,  1.37it/s, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  41%|████      | 476/1161 [05:50<08:20,  1.37it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  41%|████      | 477/1161 [05:50<08:23,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  41%|████      | 477/1161 [05:51<08:23,  1.36it/s, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  41%|████      | 478/1161 [05:51<08:23,  1.36it/s, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  41%|████      | 478/1161 [05:52<08:23,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 479/1161 [05:52<08:21,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 479/1161 [05:52<08:21,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 480/1161 [05:52<08:22,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 480/1161 [05:53<08:22,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 481/1161 [05:53<08:18,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 481/1161 [05:54<08:18,  1.36it/s, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 482/1161 [05:54<08:19,  1.36it/s, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 482/1161 [05:55<08:19,  1.36it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 483/1161 [05:55<08:17,  1.36it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 483/1161 [05:55<08:17,  1.36it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 484/1161 [05:55<08:15,  1.37it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 484/1161 [05:56<08:15,  1.37it/s, training_loss=0.467]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 485/1161 [05:56<08:15,  1.37it/s, training_loss=0.467]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 485/1161 [05:57<08:15,  1.37it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 486/1161 [05:57<08:15,  1.36it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 486/1161 [05:58<08:15,  1.36it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 487/1161 [05:58<08:16,  1.36it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 487/1161 [05:58<08:16,  1.36it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 488/1161 [05:58<08:14,  1.36it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 488/1161 [05:59<08:14,  1.36it/s, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 489/1161 [05:59<08:13,  1.36it/s, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 489/1161 [06:00<08:13,  1.36it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 490/1161 [06:00<08:13,  1.36it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 490/1161 [06:01<08:13,  1.36it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 491/1161 [06:01<08:13,  1.36it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 491/1161 [06:01<08:13,  1.36it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 492/1161 [06:01<08:10,  1.36it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 492/1161 [06:02<08:10,  1.36it/s, training_loss=0.419]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 493/1161 [06:02<08:08,  1.37it/s, training_loss=0.419]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 493/1161 [06:03<08:08,  1.37it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 494/1161 [06:03<08:08,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 494/1161 [06:03<08:08,  1.36it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 495/1161 [06:03<08:07,  1.37it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 495/1161 [06:04<08:07,  1.37it/s, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 496/1161 [06:04<08:10,  1.35it/s, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 496/1161 [06:05<08:10,  1.35it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 497/1161 [06:05<08:08,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 497/1161 [06:06<08:08,  1.36it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 498/1161 [06:06<08:07,  1.36it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 498/1161 [06:06<08:07,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 499/1161 [06:06<08:06,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 499/1161 [06:07<08:06,  1.36it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 500/1161 [06:07<08:06,  1.36it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 500/1161 [06:08<08:06,  1.36it/s, training_loss=0.350]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 501/1161 [06:08<08:06,  1.36it/s, training_loss=0.350]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 501/1161 [06:09<08:06,  1.36it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 502/1161 [06:09<08:04,  1.36it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 502/1161 [06:09<08:04,  1.36it/s, training_loss=0.390]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 503/1161 [06:09<08:03,  1.36it/s, training_loss=0.390]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 503/1161 [06:10<08:03,  1.36it/s, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 504/1161 [06:10<08:03,  1.36it/s, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 504/1161 [06:11<08:03,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 505/1161 [06:11<08:03,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 505/1161 [06:12<08:03,  1.36it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 506/1161 [06:12<08:02,  1.36it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 506/1161 [06:12<08:02,  1.36it/s, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 507/1161 [06:12<08:02,  1.36it/s, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 507/1161 [06:13<08:02,  1.36it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 508/1161 [06:13<08:02,  1.35it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 508/1161 [06:14<08:02,  1.35it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 509/1161 [06:14<07:59,  1.36it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 509/1161 [06:14<07:59,  1.36it/s, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 510/1161 [06:14<07:57,  1.36it/s, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 510/1161 [06:15<07:57,  1.36it/s, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 511/1161 [06:15<07:56,  1.36it/s, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 511/1161 [06:16<07:56,  1.36it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 512/1161 [06:16<07:59,  1.35it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 512/1161 [06:17<07:59,  1.35it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 513/1161 [06:17<07:57,  1.36it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 513/1161 [06:17<07:57,  1.36it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 514/1161 [06:17<07:55,  1.36it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 514/1161 [06:18<07:55,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 515/1161 [06:18<07:54,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 515/1161 [06:19<07:54,  1.36it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 516/1161 [06:19<07:54,  1.36it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 516/1161 [06:20<07:54,  1.36it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 517/1161 [06:20<07:54,  1.36it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 517/1161 [06:20<07:54,  1.36it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 518/1161 [06:20<07:54,  1.36it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 518/1161 [06:21<07:54,  1.36it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 519/1161 [06:21<07:53,  1.36it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 519/1161 [06:22<07:53,  1.36it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 520/1161 [06:22<07:54,  1.35it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 520/1161 [06:23<07:54,  1.35it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 521/1161 [06:23<07:53,  1.35it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 521/1161 [06:23<07:53,  1.35it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 522/1161 [06:23<07:52,  1.35it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 522/1161 [06:24<07:52,  1.35it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 523/1161 [06:24<07:49,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 523/1161 [06:25<07:49,  1.36it/s, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 524/1161 [06:25<07:47,  1.36it/s, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 524/1161 [06:26<07:47,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 525/1161 [06:26<07:48,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 525/1161 [06:26<07:48,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 526/1161 [06:26<07:47,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 526/1161 [06:27<07:47,  1.36it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 527/1161 [06:27<07:47,  1.36it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 527/1161 [06:28<07:47,  1.36it/s, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 528/1161 [06:28<07:44,  1.36it/s, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 528/1161 [06:28<07:44,  1.36it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 529/1161 [06:28<07:43,  1.36it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 529/1161 [06:29<07:43,  1.36it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 530/1161 [06:29<07:43,  1.36it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 530/1161 [06:30<07:43,  1.36it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 531/1161 [06:30<07:43,  1.36it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 531/1161 [06:31<07:43,  1.36it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 532/1161 [06:31<07:41,  1.36it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 532/1161 [06:31<07:41,  1.36it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 533/1161 [06:31<07:39,  1.37it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 533/1161 [06:32<07:39,  1.37it/s, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 534/1161 [06:32<07:38,  1.37it/s, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 534/1161 [06:33<07:38,  1.37it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 535/1161 [06:33<07:38,  1.36it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 535/1161 [06:34<07:38,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 536/1161 [06:34<07:36,  1.37it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 536/1161 [06:34<07:36,  1.37it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 537/1161 [06:34<07:38,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 537/1161 [06:35<07:38,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 538/1161 [06:35<07:39,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 538/1161 [06:36<07:39,  1.36it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 539/1161 [06:36<07:36,  1.36it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 539/1161 [06:37<07:36,  1.36it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 540/1161 [06:37<07:36,  1.36it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 540/1161 [06:37<07:36,  1.36it/s, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 541/1161 [06:37<07:35,  1.36it/s, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 541/1161 [06:38<07:35,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 542/1161 [06:38<07:33,  1.37it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 542/1161 [06:39<07:33,  1.37it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 543/1161 [06:39<07:34,  1.36it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 543/1161 [06:39<07:34,  1.36it/s, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 544/1161 [06:39<07:33,  1.36it/s, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 544/1161 [06:40<07:33,  1.36it/s, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 545/1161 [06:40<07:33,  1.36it/s, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 545/1161 [06:41<07:33,  1.36it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 546/1161 [06:41<07:34,  1.35it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 546/1161 [06:42<07:34,  1.35it/s, training_loss=0.417]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 547/1161 [06:42<07:31,  1.36it/s, training_loss=0.417]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 547/1161 [06:42<07:31,  1.36it/s, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 548/1161 [06:42<07:31,  1.36it/s, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 548/1161 [06:43<07:31,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 549/1161 [06:43<07:32,  1.35it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 549/1161 [06:44<07:32,  1.35it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 550/1161 [06:44<07:29,  1.36it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 550/1161 [06:45<07:29,  1.36it/s, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 551/1161 [06:45<07:27,  1.36it/s, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 551/1161 [06:45<07:27,  1.36it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 552/1161 [06:45<07:26,  1.36it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 552/1161 [06:46<07:26,  1.36it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 553/1161 [06:46<07:26,  1.36it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 553/1161 [06:47<07:26,  1.36it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 554/1161 [06:47<07:24,  1.36it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 554/1161 [06:48<07:24,  1.36it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 555/1161 [06:48<07:24,  1.36it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 555/1161 [06:48<07:24,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 556/1161 [06:48<07:22,  1.37it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 556/1161 [06:49<07:22,  1.37it/s, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 557/1161 [06:49<07:21,  1.37it/s, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 557/1161 [06:50<07:21,  1.37it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 558/1161 [06:50<07:19,  1.37it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 558/1161 [06:50<07:19,  1.37it/s, training_loss=0.403]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 559/1161 [06:51<07:20,  1.37it/s, training_loss=0.403]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 559/1161 [06:51<07:20,  1.37it/s, training_loss=0.345]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 560/1161 [06:51<07:19,  1.37it/s, training_loss=0.345]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 560/1161 [06:52<07:19,  1.37it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 561/1161 [06:52<07:20,  1.36it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 561/1161 [06:53<07:20,  1.36it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 562/1161 [06:53<07:20,  1.36it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 562/1161 [06:53<07:20,  1.36it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 563/1161 [06:53<07:21,  1.36it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 563/1161 [06:54<07:21,  1.36it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 564/1161 [06:54<07:19,  1.36it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 564/1161 [06:55<07:19,  1.36it/s, training_loss=0.397]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 565/1161 [06:55<07:19,  1.35it/s, training_loss=0.397]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 565/1161 [06:56<07:19,  1.35it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 566/1161 [06:56<07:18,  1.36it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 566/1161 [06:56<07:18,  1.36it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 567/1161 [06:56<07:18,  1.36it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 567/1161 [06:57<07:18,  1.36it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 568/1161 [06:57<07:15,  1.36it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 568/1161 [06:58<07:15,  1.36it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 569/1161 [06:58<07:14,  1.36it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 569/1161 [06:59<07:14,  1.36it/s, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 570/1161 [06:59<07:11,  1.37it/s, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 570/1161 [06:59<07:11,  1.37it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 571/1161 [06:59<07:10,  1.37it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 571/1161 [07:00<07:10,  1.37it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 572/1161 [07:00<07:10,  1.37it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 572/1161 [07:01<07:10,  1.37it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 573/1161 [07:01<07:09,  1.37it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 573/1161 [07:01<07:09,  1.37it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 574/1161 [07:02<07:08,  1.37it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 574/1161 [07:02<07:08,  1.37it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 575/1161 [07:02<07:07,  1.37it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 575/1161 [07:03<07:07,  1.37it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 576/1161 [07:03<07:08,  1.37it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 576/1161 [07:04<07:08,  1.37it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 577/1161 [07:04<07:06,  1.37it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 577/1161 [07:04<07:06,  1.37it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 578/1161 [07:04<07:07,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 578/1161 [07:05<07:07,  1.36it/s, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 579/1161 [07:05<07:07,  1.36it/s, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 579/1161 [07:06<07:07,  1.36it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 580/1161 [07:06<07:06,  1.36it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 580/1161 [07:07<07:06,  1.36it/s, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  50%|█████     | 581/1161 [07:07<07:04,  1.37it/s, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  50%|█████     | 581/1161 [07:07<07:04,  1.37it/s, training_loss=0.389]\u001b[A\n",
            "Epoch 1:  50%|█████     | 582/1161 [07:07<07:03,  1.37it/s, training_loss=0.389]\u001b[A\n",
            "Epoch 1:  50%|█████     | 582/1161 [07:08<07:03,  1.37it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  50%|█████     | 583/1161 [07:08<07:04,  1.36it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  50%|█████     | 583/1161 [07:09<07:04,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  50%|█████     | 584/1161 [07:09<07:04,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  50%|█████     | 584/1161 [07:10<07:04,  1.36it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  50%|█████     | 585/1161 [07:10<07:03,  1.36it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  50%|█████     | 585/1161 [07:10<07:03,  1.36it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  50%|█████     | 586/1161 [07:10<07:03,  1.36it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  50%|█████     | 586/1161 [07:11<07:03,  1.36it/s, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  51%|█████     | 587/1161 [07:11<07:01,  1.36it/s, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  51%|█████     | 587/1161 [07:12<07:01,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  51%|█████     | 588/1161 [07:12<07:00,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  51%|█████     | 588/1161 [07:12<07:00,  1.36it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  51%|█████     | 589/1161 [07:13<06:59,  1.37it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  51%|█████     | 589/1161 [07:13<06:59,  1.37it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  51%|█████     | 590/1161 [07:13<06:57,  1.37it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  51%|█████     | 590/1161 [07:14<06:57,  1.37it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  51%|█████     | 591/1161 [07:14<06:58,  1.36it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  51%|█████     | 591/1161 [07:15<06:58,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  51%|█████     | 592/1161 [07:15<06:58,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  51%|█████     | 592/1161 [07:15<06:58,  1.36it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  51%|█████     | 593/1161 [07:15<06:57,  1.36it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  51%|█████     | 593/1161 [07:16<06:57,  1.36it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  51%|█████     | 594/1161 [07:16<06:56,  1.36it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  51%|█████     | 594/1161 [07:17<06:56,  1.36it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  51%|█████     | 595/1161 [07:17<06:55,  1.36it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  51%|█████     | 595/1161 [07:18<06:55,  1.36it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 596/1161 [07:18<06:54,  1.36it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 596/1161 [07:18<06:54,  1.36it/s, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 597/1161 [07:18<06:53,  1.36it/s, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 597/1161 [07:19<06:53,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 598/1161 [07:19<06:54,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 598/1161 [07:20<06:54,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 599/1161 [07:20<06:54,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 599/1161 [07:21<06:54,  1.36it/s, training_loss=0.359]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 600/1161 [07:21<06:53,  1.36it/s, training_loss=0.359]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 600/1161 [07:21<06:53,  1.36it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 601/1161 [07:21<06:51,  1.36it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 601/1161 [07:22<06:51,  1.36it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 602/1161 [07:22<06:49,  1.36it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 602/1161 [07:23<06:49,  1.36it/s, training_loss=0.477]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 603/1161 [07:23<06:48,  1.36it/s, training_loss=0.477]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 603/1161 [07:24<06:48,  1.36it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 604/1161 [07:24<06:47,  1.37it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 604/1161 [07:24<06:47,  1.37it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 605/1161 [07:24<06:46,  1.37it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 605/1161 [07:25<06:46,  1.37it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 606/1161 [07:25<06:46,  1.37it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 606/1161 [07:26<06:46,  1.37it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 607/1161 [07:26<06:46,  1.36it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 607/1161 [07:26<06:46,  1.36it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 608/1161 [07:26<06:46,  1.36it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 608/1161 [07:27<06:46,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 609/1161 [07:27<06:47,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 609/1161 [07:28<06:47,  1.36it/s, training_loss=0.406]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 610/1161 [07:28<06:45,  1.36it/s, training_loss=0.406]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 610/1161 [07:29<06:45,  1.36it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 611/1161 [07:29<06:45,  1.36it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 611/1161 [07:29<06:45,  1.36it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 612/1161 [07:29<06:44,  1.36it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 612/1161 [07:30<06:44,  1.36it/s, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 613/1161 [07:30<06:44,  1.36it/s, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 613/1161 [07:31<06:44,  1.36it/s, training_loss=0.332]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 614/1161 [07:31<06:43,  1.36it/s, training_loss=0.332]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 614/1161 [07:32<06:43,  1.36it/s, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 615/1161 [07:32<06:42,  1.36it/s, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 615/1161 [07:32<06:42,  1.36it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 616/1161 [07:32<06:39,  1.36it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 616/1161 [07:33<06:39,  1.36it/s, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 617/1161 [07:33<06:38,  1.37it/s, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 617/1161 [07:34<06:38,  1.37it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 618/1161 [07:34<06:38,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 618/1161 [07:35<06:38,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 619/1161 [07:35<06:36,  1.37it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 619/1161 [07:35<06:36,  1.37it/s, training_loss=0.315]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 620/1161 [07:35<06:37,  1.36it/s, training_loss=0.315]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 620/1161 [07:36<06:37,  1.36it/s, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 621/1161 [07:36<06:36,  1.36it/s, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 621/1161 [07:37<06:36,  1.36it/s, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 622/1161 [07:37<06:36,  1.36it/s, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 622/1161 [07:37<06:36,  1.36it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 623/1161 [07:38<06:36,  1.36it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 623/1161 [07:38<06:36,  1.36it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 624/1161 [07:38<06:36,  1.36it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 624/1161 [07:39<06:36,  1.36it/s, training_loss=0.525]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 625/1161 [07:39<06:35,  1.35it/s, training_loss=0.525]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 625/1161 [07:40<06:35,  1.35it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 626/1161 [07:40<06:34,  1.36it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 626/1161 [07:40<06:34,  1.36it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 627/1161 [07:40<06:34,  1.35it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 627/1161 [07:41<06:34,  1.35it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 628/1161 [07:41<06:34,  1.35it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 628/1161 [07:42<06:34,  1.35it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 629/1161 [07:42<06:32,  1.35it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 629/1161 [07:43<06:32,  1.35it/s, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 630/1161 [07:43<06:30,  1.36it/s, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 630/1161 [07:43<06:30,  1.36it/s, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 631/1161 [07:43<06:28,  1.37it/s, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 631/1161 [07:44<06:28,  1.37it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 632/1161 [07:44<06:28,  1.36it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 632/1161 [07:45<06:28,  1.36it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 633/1161 [07:45<06:26,  1.37it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 633/1161 [07:46<06:26,  1.37it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 634/1161 [07:46<06:25,  1.37it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 634/1161 [07:46<06:25,  1.37it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 635/1161 [07:46<06:26,  1.36it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 635/1161 [07:47<06:26,  1.36it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 636/1161 [07:47<06:26,  1.36it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 636/1161 [07:48<06:26,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 637/1161 [07:48<06:26,  1.35it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 637/1161 [07:49<06:26,  1.35it/s, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 638/1161 [07:49<06:26,  1.35it/s, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 638/1161 [07:49<06:26,  1.35it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 639/1161 [07:49<06:25,  1.35it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 639/1161 [07:50<06:25,  1.35it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 640/1161 [07:50<06:24,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 640/1161 [07:51<06:24,  1.36it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 641/1161 [07:51<06:21,  1.36it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 641/1161 [07:51<06:21,  1.36it/s, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 642/1161 [07:51<06:20,  1.36it/s, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 642/1161 [07:52<06:20,  1.36it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 643/1161 [07:52<06:19,  1.36it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 643/1161 [07:53<06:19,  1.36it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 644/1161 [07:53<06:18,  1.36it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 644/1161 [07:54<06:18,  1.36it/s, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 645/1161 [07:54<06:16,  1.37it/s, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 645/1161 [07:54<06:16,  1.37it/s, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 646/1161 [07:54<06:15,  1.37it/s, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 646/1161 [07:55<06:15,  1.37it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 647/1161 [07:55<06:15,  1.37it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 647/1161 [07:56<06:15,  1.37it/s, training_loss=0.373]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 648/1161 [07:56<06:15,  1.36it/s, training_loss=0.373]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 648/1161 [07:57<06:15,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 649/1161 [07:57<06:17,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 649/1161 [07:57<06:17,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 650/1161 [07:57<06:16,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 650/1161 [07:58<06:16,  1.36it/s, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 651/1161 [07:58<06:15,  1.36it/s, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 651/1161 [07:59<06:15,  1.36it/s, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 652/1161 [07:59<06:13,  1.36it/s, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 652/1161 [08:00<06:13,  1.36it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 653/1161 [08:00<06:13,  1.36it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 653/1161 [08:00<06:13,  1.36it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 654/1161 [08:00<06:13,  1.36it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 654/1161 [08:01<06:13,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 655/1161 [08:01<06:12,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 655/1161 [08:02<06:12,  1.36it/s, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 656/1161 [08:02<06:12,  1.35it/s, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 656/1161 [08:02<06:12,  1.35it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 657/1161 [08:03<06:12,  1.35it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 657/1161 [08:03<06:12,  1.35it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 658/1161 [08:03<06:11,  1.35it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 658/1161 [08:04<06:11,  1.35it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 659/1161 [08:04<06:09,  1.36it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 659/1161 [08:05<06:09,  1.36it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 660/1161 [08:05<06:08,  1.36it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 660/1161 [08:05<06:08,  1.36it/s, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 661/1161 [08:05<06:06,  1.36it/s, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 661/1161 [08:06<06:06,  1.36it/s, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 662/1161 [08:06<06:06,  1.36it/s, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 662/1161 [08:07<06:06,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 663/1161 [08:07<06:05,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 663/1161 [08:08<06:05,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 664/1161 [08:08<06:05,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 664/1161 [08:08<06:05,  1.36it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 665/1161 [08:08<06:07,  1.35it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 665/1161 [08:09<06:07,  1.35it/s, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 666/1161 [08:09<06:05,  1.36it/s, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 666/1161 [08:10<06:05,  1.36it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 667/1161 [08:10<06:03,  1.36it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 667/1161 [08:11<06:03,  1.36it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 668/1161 [08:11<06:03,  1.36it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 668/1161 [08:11<06:03,  1.36it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 669/1161 [08:11<06:02,  1.36it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 669/1161 [08:12<06:02,  1.36it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 670/1161 [08:12<06:00,  1.36it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 670/1161 [08:13<06:00,  1.36it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 671/1161 [08:13<05:59,  1.36it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 671/1161 [08:14<05:59,  1.36it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 672/1161 [08:14<05:58,  1.36it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 672/1161 [08:14<05:58,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 673/1161 [08:14<05:58,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 673/1161 [08:15<05:58,  1.36it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 674/1161 [08:15<05:56,  1.37it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 674/1161 [08:16<05:56,  1.37it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 675/1161 [08:16<05:56,  1.36it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 675/1161 [08:16<05:56,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 676/1161 [08:16<05:56,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 676/1161 [08:17<05:56,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 677/1161 [08:17<05:56,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 677/1161 [08:18<05:56,  1.36it/s, training_loss=0.386]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 678/1161 [08:18<05:57,  1.35it/s, training_loss=0.386]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 678/1161 [08:19<05:57,  1.35it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 679/1161 [08:19<05:55,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 679/1161 [08:19<05:55,  1.36it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 680/1161 [08:19<05:55,  1.35it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 680/1161 [08:20<05:55,  1.35it/s, training_loss=0.249]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 681/1161 [08:20<05:53,  1.36it/s, training_loss=0.249]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 681/1161 [08:21<05:53,  1.36it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 682/1161 [08:21<05:52,  1.36it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 682/1161 [08:22<05:52,  1.36it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 683/1161 [08:22<05:51,  1.36it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 683/1161 [08:22<05:51,  1.36it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 684/1161 [08:22<05:49,  1.36it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 684/1161 [08:23<05:49,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 685/1161 [08:23<05:49,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 685/1161 [08:24<05:49,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 686/1161 [08:24<05:47,  1.37it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 686/1161 [08:25<05:47,  1.37it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 687/1161 [08:25<05:47,  1.37it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 687/1161 [08:25<05:47,  1.37it/s, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 688/1161 [08:25<05:47,  1.36it/s, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 688/1161 [08:26<05:47,  1.36it/s, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 689/1161 [08:26<05:45,  1.37it/s, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 689/1161 [08:27<05:45,  1.37it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 690/1161 [08:27<05:45,  1.36it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 690/1161 [08:27<05:45,  1.36it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 691/1161 [08:28<05:45,  1.36it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 691/1161 [08:28<05:45,  1.36it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 692/1161 [08:28<05:44,  1.36it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 692/1161 [08:29<05:44,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 693/1161 [08:29<05:43,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 693/1161 [08:30<05:43,  1.36it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 694/1161 [08:30<05:42,  1.36it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 694/1161 [08:30<05:42,  1.36it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 695/1161 [08:30<05:42,  1.36it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 695/1161 [08:31<05:42,  1.36it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 696/1161 [08:31<05:42,  1.36it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 696/1161 [08:32<05:42,  1.36it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  60%|██████    | 697/1161 [08:32<05:42,  1.35it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  60%|██████    | 697/1161 [08:33<05:42,  1.35it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  60%|██████    | 698/1161 [08:33<05:41,  1.36it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  60%|██████    | 698/1161 [08:33<05:41,  1.36it/s, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  60%|██████    | 699/1161 [08:33<05:40,  1.36it/s, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  60%|██████    | 699/1161 [08:34<05:40,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  60%|██████    | 700/1161 [08:34<05:40,  1.35it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  60%|██████    | 700/1161 [08:35<05:40,  1.35it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  60%|██████    | 701/1161 [08:35<05:38,  1.36it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  60%|██████    | 701/1161 [08:36<05:38,  1.36it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 1:  60%|██████    | 702/1161 [08:36<05:39,  1.35it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 1:  60%|██████    | 702/1161 [08:36<05:39,  1.35it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  61%|██████    | 703/1161 [08:36<05:37,  1.36it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  61%|██████    | 703/1161 [08:37<05:37,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  61%|██████    | 704/1161 [08:37<05:36,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  61%|██████    | 704/1161 [08:38<05:36,  1.36it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  61%|██████    | 705/1161 [08:38<05:37,  1.35it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  61%|██████    | 705/1161 [08:39<05:37,  1.35it/s, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  61%|██████    | 706/1161 [08:39<05:37,  1.35it/s, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  61%|██████    | 706/1161 [08:39<05:37,  1.35it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  61%|██████    | 707/1161 [08:39<05:35,  1.35it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  61%|██████    | 707/1161 [08:40<05:35,  1.35it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  61%|██████    | 708/1161 [08:40<05:33,  1.36it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  61%|██████    | 708/1161 [08:41<05:33,  1.36it/s, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  61%|██████    | 709/1161 [08:41<05:32,  1.36it/s, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  61%|██████    | 709/1161 [08:41<05:32,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  61%|██████    | 710/1161 [08:42<05:32,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  61%|██████    | 710/1161 [08:42<05:32,  1.36it/s, training_loss=0.328]\u001b[A\n",
            "Epoch 1:  61%|██████    | 711/1161 [08:42<05:31,  1.36it/s, training_loss=0.328]\u001b[A\n",
            "Epoch 1:  61%|██████    | 711/1161 [08:43<05:31,  1.36it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 712/1161 [08:43<05:30,  1.36it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 712/1161 [08:44<05:30,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 713/1161 [08:44<05:29,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 713/1161 [08:44<05:29,  1.36it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 714/1161 [08:44<05:29,  1.36it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 714/1161 [08:45<05:29,  1.36it/s, training_loss=0.406]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 715/1161 [08:45<05:27,  1.36it/s, training_loss=0.406]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 715/1161 [08:46<05:27,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 716/1161 [08:46<05:27,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 716/1161 [08:47<05:27,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 717/1161 [08:47<05:25,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 717/1161 [08:47<05:25,  1.36it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 718/1161 [08:47<05:25,  1.36it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 718/1161 [08:48<05:25,  1.36it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 719/1161 [08:48<05:24,  1.36it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 719/1161 [08:49<05:24,  1.36it/s, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 720/1161 [08:49<05:22,  1.37it/s, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 720/1161 [08:50<05:22,  1.37it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 721/1161 [08:50<05:23,  1.36it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 721/1161 [08:50<05:23,  1.36it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 722/1161 [08:50<05:23,  1.36it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 722/1161 [08:51<05:23,  1.36it/s, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 723/1161 [08:51<05:23,  1.36it/s, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 723/1161 [08:52<05:23,  1.36it/s, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 724/1161 [08:52<05:21,  1.36it/s, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 724/1161 [08:53<05:21,  1.36it/s, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 725/1161 [08:53<05:20,  1.36it/s, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 725/1161 [08:53<05:20,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 726/1161 [08:53<05:19,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 726/1161 [08:54<05:19,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 727/1161 [08:54<05:18,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 727/1161 [08:55<05:18,  1.36it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 728/1161 [08:55<05:17,  1.37it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 728/1161 [08:55<05:17,  1.37it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 729/1161 [08:55<05:17,  1.36it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 729/1161 [08:56<05:17,  1.36it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 730/1161 [08:56<05:16,  1.36it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 730/1161 [08:57<05:16,  1.36it/s, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 731/1161 [08:57<05:15,  1.36it/s, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 731/1161 [08:58<05:15,  1.36it/s, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 732/1161 [08:58<05:14,  1.37it/s, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 732/1161 [08:58<05:14,  1.37it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 733/1161 [08:58<05:14,  1.36it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 733/1161 [08:59<05:14,  1.36it/s, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 734/1161 [08:59<05:13,  1.36it/s, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 734/1161 [09:00<05:13,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 735/1161 [09:00<05:14,  1.35it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 735/1161 [09:01<05:14,  1.35it/s, training_loss=0.328]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 736/1161 [09:01<05:12,  1.36it/s, training_loss=0.328]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 736/1161 [09:01<05:12,  1.36it/s, training_loss=0.368]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 737/1161 [09:01<05:13,  1.35it/s, training_loss=0.368]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 737/1161 [09:02<05:13,  1.35it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 738/1161 [09:02<05:13,  1.35it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 738/1161 [09:03<05:13,  1.35it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 739/1161 [09:03<05:11,  1.36it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 739/1161 [09:04<05:11,  1.36it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 740/1161 [09:04<05:10,  1.36it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 740/1161 [09:04<05:10,  1.36it/s, training_loss=0.463]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 741/1161 [09:04<05:10,  1.35it/s, training_loss=0.463]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 741/1161 [09:05<05:10,  1.35it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 742/1161 [09:05<05:09,  1.35it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 742/1161 [09:06<05:09,  1.35it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 743/1161 [09:06<05:08,  1.35it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 743/1161 [09:07<05:08,  1.35it/s, training_loss=0.365]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 744/1161 [09:07<05:07,  1.36it/s, training_loss=0.365]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 744/1161 [09:07<05:07,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 745/1161 [09:07<05:06,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 745/1161 [09:08<05:06,  1.36it/s, training_loss=0.249]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 746/1161 [09:08<05:05,  1.36it/s, training_loss=0.249]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 746/1161 [09:09<05:05,  1.36it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 747/1161 [09:09<05:03,  1.36it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 747/1161 [09:09<05:03,  1.36it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 748/1161 [09:09<05:05,  1.35it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 748/1161 [09:10<05:05,  1.35it/s, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 749/1161 [09:10<05:04,  1.35it/s, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 749/1161 [09:11<05:04,  1.35it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 750/1161 [09:11<05:03,  1.35it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 750/1161 [09:12<05:03,  1.35it/s, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 751/1161 [09:12<05:02,  1.36it/s, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 751/1161 [09:12<05:02,  1.36it/s, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 752/1161 [09:12<05:01,  1.36it/s, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 752/1161 [09:13<05:01,  1.36it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 753/1161 [09:13<04:59,  1.36it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 753/1161 [09:14<04:59,  1.36it/s, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 754/1161 [09:14<04:58,  1.36it/s, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 754/1161 [09:15<04:58,  1.36it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 755/1161 [09:15<04:58,  1.36it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 755/1161 [09:15<04:58,  1.36it/s, training_loss=0.321]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 756/1161 [09:15<04:57,  1.36it/s, training_loss=0.321]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 756/1161 [09:16<04:57,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 757/1161 [09:16<04:57,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 757/1161 [09:17<04:57,  1.36it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 758/1161 [09:17<04:55,  1.36it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 758/1161 [09:18<04:55,  1.36it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 759/1161 [09:18<04:55,  1.36it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 759/1161 [09:18<04:55,  1.36it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 760/1161 [09:18<04:55,  1.36it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 760/1161 [09:19<04:55,  1.36it/s, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 761/1161 [09:19<04:54,  1.36it/s, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 761/1161 [09:20<04:54,  1.36it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 762/1161 [09:20<04:53,  1.36it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 762/1161 [09:21<04:53,  1.36it/s, training_loss=0.450]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 763/1161 [09:21<04:52,  1.36it/s, training_loss=0.450]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 763/1161 [09:21<04:52,  1.36it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 764/1161 [09:21<04:54,  1.35it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 764/1161 [09:22<04:54,  1.35it/s, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 765/1161 [09:22<04:54,  1.34it/s, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 765/1161 [09:23<04:54,  1.34it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 766/1161 [09:23<04:52,  1.35it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 766/1161 [09:23<04:52,  1.35it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 767/1161 [09:23<04:51,  1.35it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 767/1161 [09:24<04:51,  1.35it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 768/1161 [09:24<04:50,  1.35it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 768/1161 [09:25<04:50,  1.35it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 769/1161 [09:25<04:48,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 769/1161 [09:26<04:48,  1.36it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 770/1161 [09:26<04:47,  1.36it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 770/1161 [09:26<04:47,  1.36it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 771/1161 [09:26<04:46,  1.36it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 771/1161 [09:27<04:46,  1.36it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 772/1161 [09:27<04:45,  1.36it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 772/1161 [09:28<04:45,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 773/1161 [09:28<04:44,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 773/1161 [09:29<04:44,  1.36it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 774/1161 [09:29<04:44,  1.36it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 774/1161 [09:29<04:44,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 775/1161 [09:29<04:43,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 775/1161 [09:30<04:43,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 776/1161 [09:30<04:42,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 776/1161 [09:31<04:42,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 777/1161 [09:31<04:43,  1.35it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 777/1161 [09:32<04:43,  1.35it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 778/1161 [09:32<04:43,  1.35it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 778/1161 [09:32<04:43,  1.35it/s, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 779/1161 [09:32<04:42,  1.35it/s, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 779/1161 [09:33<04:42,  1.35it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 780/1161 [09:33<04:41,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 780/1161 [09:34<04:41,  1.36it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 781/1161 [09:34<04:40,  1.35it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 781/1161 [09:35<04:40,  1.35it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 782/1161 [09:35<04:38,  1.36it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 782/1161 [09:35<04:38,  1.36it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 783/1161 [09:35<04:38,  1.36it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 783/1161 [09:36<04:38,  1.36it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 784/1161 [09:36<04:36,  1.36it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 784/1161 [09:37<04:36,  1.36it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 785/1161 [09:37<04:35,  1.36it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 785/1161 [09:37<04:35,  1.36it/s, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 786/1161 [09:37<04:35,  1.36it/s, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 786/1161 [09:38<04:35,  1.36it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 787/1161 [09:38<04:33,  1.37it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 787/1161 [09:39<04:33,  1.37it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 788/1161 [09:39<04:32,  1.37it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 788/1161 [09:40<04:32,  1.37it/s, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 789/1161 [09:40<04:32,  1.37it/s, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 789/1161 [09:40<04:32,  1.37it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 790/1161 [09:40<04:31,  1.36it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 790/1161 [09:41<04:31,  1.36it/s, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 791/1161 [09:41<04:30,  1.37it/s, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 791/1161 [09:42<04:30,  1.37it/s, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 792/1161 [09:42<04:30,  1.36it/s, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 792/1161 [09:43<04:30,  1.36it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 793/1161 [09:43<04:29,  1.36it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 793/1161 [09:43<04:29,  1.36it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 794/1161 [09:43<04:28,  1.37it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 794/1161 [09:44<04:28,  1.37it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 795/1161 [09:44<04:29,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 795/1161 [09:45<04:29,  1.36it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 796/1161 [09:45<04:28,  1.36it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 796/1161 [09:46<04:28,  1.36it/s, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 797/1161 [09:46<04:28,  1.35it/s, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 797/1161 [09:46<04:28,  1.35it/s, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 798/1161 [09:46<04:27,  1.36it/s, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 798/1161 [09:47<04:27,  1.36it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 799/1161 [09:47<04:28,  1.35it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 799/1161 [09:48<04:28,  1.35it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 800/1161 [09:48<04:26,  1.36it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 800/1161 [09:48<04:26,  1.36it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 801/1161 [09:48<04:25,  1.35it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 801/1161 [09:49<04:25,  1.35it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 802/1161 [09:49<04:25,  1.35it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 802/1161 [09:50<04:25,  1.35it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 803/1161 [09:50<04:24,  1.36it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 803/1161 [09:51<04:24,  1.36it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 804/1161 [09:51<04:22,  1.36it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 804/1161 [09:51<04:22,  1.36it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 805/1161 [09:51<04:21,  1.36it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 805/1161 [09:52<04:21,  1.36it/s, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 806/1161 [09:52<04:21,  1.36it/s, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 806/1161 [09:53<04:21,  1.36it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 807/1161 [09:53<04:20,  1.36it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 807/1161 [09:54<04:20,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 808/1161 [09:54<04:19,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 808/1161 [09:54<04:19,  1.36it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 809/1161 [09:54<04:18,  1.36it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 809/1161 [09:55<04:18,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 810/1161 [09:55<04:18,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 810/1161 [09:56<04:18,  1.36it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 811/1161 [09:56<04:16,  1.36it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 811/1161 [09:57<04:16,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 812/1161 [09:57<04:15,  1.37it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 812/1161 [09:57<04:15,  1.37it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  70%|███████   | 813/1161 [09:57<04:15,  1.36it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  70%|███████   | 813/1161 [09:58<04:15,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  70%|███████   | 814/1161 [09:58<04:14,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  70%|███████   | 814/1161 [09:59<04:14,  1.36it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 1:  70%|███████   | 815/1161 [09:59<04:13,  1.36it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 1:  70%|███████   | 815/1161 [09:59<04:13,  1.36it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  70%|███████   | 816/1161 [10:00<04:14,  1.36it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  70%|███████   | 816/1161 [10:00<04:14,  1.36it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  70%|███████   | 817/1161 [10:00<04:11,  1.37it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  70%|███████   | 817/1161 [10:01<04:11,  1.37it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  70%|███████   | 818/1161 [10:01<04:12,  1.36it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  70%|███████   | 818/1161 [10:02<04:12,  1.36it/s, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  71%|███████   | 819/1161 [10:02<04:11,  1.36it/s, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  71%|███████   | 819/1161 [10:02<04:11,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  71%|███████   | 820/1161 [10:02<04:11,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  71%|███████   | 820/1161 [10:03<04:11,  1.36it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  71%|███████   | 821/1161 [10:03<04:09,  1.36it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  71%|███████   | 821/1161 [10:04<04:09,  1.36it/s, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  71%|███████   | 822/1161 [10:04<04:08,  1.36it/s, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  71%|███████   | 822/1161 [10:05<04:08,  1.36it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  71%|███████   | 823/1161 [10:05<04:08,  1.36it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  71%|███████   | 823/1161 [10:05<04:08,  1.36it/s, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  71%|███████   | 824/1161 [10:05<04:06,  1.36it/s, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  71%|███████   | 824/1161 [10:06<04:06,  1.36it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  71%|███████   | 825/1161 [10:06<04:07,  1.36it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  71%|███████   | 825/1161 [10:07<04:07,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  71%|███████   | 826/1161 [10:07<04:06,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  71%|███████   | 826/1161 [10:08<04:06,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  71%|███████   | 827/1161 [10:08<04:07,  1.35it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  71%|███████   | 827/1161 [10:08<04:07,  1.35it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 828/1161 [10:08<04:06,  1.35it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 828/1161 [10:09<04:06,  1.35it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 829/1161 [10:09<04:04,  1.36it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 829/1161 [10:10<04:04,  1.36it/s, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 830/1161 [10:10<04:05,  1.35it/s, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 830/1161 [10:11<04:05,  1.35it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 831/1161 [10:11<04:03,  1.36it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 831/1161 [10:11<04:03,  1.36it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 832/1161 [10:11<04:03,  1.35it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 832/1161 [10:12<04:03,  1.35it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 833/1161 [10:12<04:01,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 833/1161 [10:13<04:01,  1.36it/s, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 834/1161 [10:13<04:00,  1.36it/s, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 834/1161 [10:13<04:00,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 835/1161 [10:14<03:59,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 835/1161 [10:14<03:59,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 836/1161 [10:14<03:59,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 836/1161 [10:15<03:59,  1.36it/s, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 837/1161 [10:15<03:57,  1.36it/s, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 837/1161 [10:16<03:57,  1.36it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 838/1161 [10:16<03:56,  1.36it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 838/1161 [10:16<03:56,  1.36it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 839/1161 [10:16<03:55,  1.37it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 839/1161 [10:17<03:55,  1.37it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 840/1161 [10:17<03:54,  1.37it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 840/1161 [10:18<03:54,  1.37it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 841/1161 [10:18<03:54,  1.36it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 841/1161 [10:19<03:54,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 842/1161 [10:19<03:54,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 842/1161 [10:19<03:54,  1.36it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 843/1161 [10:19<03:53,  1.36it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 843/1161 [10:20<03:53,  1.36it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 844/1161 [10:20<03:53,  1.36it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 844/1161 [10:21<03:53,  1.36it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 845/1161 [10:21<03:52,  1.36it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 845/1161 [10:22<03:52,  1.36it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 846/1161 [10:22<03:51,  1.36it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 846/1161 [10:22<03:51,  1.36it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 847/1161 [10:22<03:50,  1.36it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 847/1161 [10:23<03:50,  1.36it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 848/1161 [10:23<03:49,  1.36it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 848/1161 [10:24<03:49,  1.36it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 849/1161 [10:24<03:48,  1.36it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 849/1161 [10:24<03:48,  1.36it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 850/1161 [10:24<03:47,  1.37it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 850/1161 [10:25<03:47,  1.37it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 851/1161 [10:25<03:46,  1.37it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 851/1161 [10:26<03:46,  1.37it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 852/1161 [10:26<03:46,  1.36it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 852/1161 [10:27<03:46,  1.36it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 853/1161 [10:27<03:46,  1.36it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 853/1161 [10:27<03:46,  1.36it/s, training_loss=0.369]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 854/1161 [10:27<03:45,  1.36it/s, training_loss=0.369]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 854/1161 [10:28<03:45,  1.36it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 855/1161 [10:28<03:45,  1.36it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 855/1161 [10:29<03:45,  1.36it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 856/1161 [10:29<03:44,  1.36it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 856/1161 [10:30<03:44,  1.36it/s, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 857/1161 [10:30<03:43,  1.36it/s, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 857/1161 [10:30<03:43,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 858/1161 [10:30<03:44,  1.35it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 858/1161 [10:31<03:44,  1.35it/s, training_loss=0.369]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 859/1161 [10:31<03:43,  1.35it/s, training_loss=0.369]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 859/1161 [10:32<03:43,  1.35it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 860/1161 [10:32<03:44,  1.34it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 860/1161 [10:33<03:44,  1.34it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 861/1161 [10:33<03:42,  1.35it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 861/1161 [10:33<03:42,  1.35it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 862/1161 [10:33<03:42,  1.35it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 862/1161 [10:34<03:42,  1.35it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 863/1161 [10:34<03:40,  1.35it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 863/1161 [10:35<03:40,  1.35it/s, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 864/1161 [10:35<03:40,  1.35it/s, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 864/1161 [10:36<03:40,  1.35it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 865/1161 [10:36<03:38,  1.36it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 865/1161 [10:36<03:38,  1.36it/s, training_loss=0.418]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 866/1161 [10:36<03:37,  1.35it/s, training_loss=0.418]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 866/1161 [10:37<03:37,  1.35it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 867/1161 [10:37<03:36,  1.36it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 867/1161 [10:38<03:36,  1.36it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 868/1161 [10:38<03:35,  1.36it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 868/1161 [10:39<03:35,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 869/1161 [10:39<03:35,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 869/1161 [10:39<03:35,  1.36it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 870/1161 [10:39<03:33,  1.36it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 870/1161 [10:40<03:33,  1.36it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 871/1161 [10:40<03:35,  1.35it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 871/1161 [10:41<03:35,  1.35it/s, training_loss=0.383]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 872/1161 [10:41<03:33,  1.36it/s, training_loss=0.383]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 872/1161 [10:41<03:33,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 873/1161 [10:41<03:33,  1.35it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 873/1161 [10:42<03:33,  1.35it/s, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 874/1161 [10:42<03:31,  1.36it/s, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 874/1161 [10:43<03:31,  1.36it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 875/1161 [10:43<03:31,  1.35it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 875/1161 [10:44<03:31,  1.35it/s, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 876/1161 [10:44<03:30,  1.35it/s, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 876/1161 [10:44<03:30,  1.35it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 877/1161 [10:44<03:30,  1.35it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 877/1161 [10:45<03:30,  1.35it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 878/1161 [10:45<03:29,  1.35it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 878/1161 [10:46<03:29,  1.35it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 879/1161 [10:46<03:27,  1.36it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 879/1161 [10:47<03:27,  1.36it/s, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 880/1161 [10:47<03:26,  1.36it/s, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 880/1161 [10:47<03:26,  1.36it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 881/1161 [10:47<03:26,  1.36it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 881/1161 [10:48<03:26,  1.36it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 882/1161 [10:48<03:25,  1.36it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 882/1161 [10:49<03:25,  1.36it/s, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 883/1161 [10:49<03:25,  1.35it/s, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 883/1161 [10:50<03:25,  1.35it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 884/1161 [10:50<03:24,  1.36it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 884/1161 [10:50<03:24,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 885/1161 [10:50<03:23,  1.35it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 885/1161 [10:51<03:23,  1.35it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 886/1161 [10:51<03:23,  1.35it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 886/1161 [10:52<03:23,  1.35it/s, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 887/1161 [10:52<03:23,  1.35it/s, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 887/1161 [10:53<03:23,  1.35it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 888/1161 [10:53<03:21,  1.35it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 888/1161 [10:53<03:21,  1.35it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 889/1161 [10:53<03:21,  1.35it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 889/1161 [10:54<03:21,  1.35it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 890/1161 [10:54<03:20,  1.35it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 890/1161 [10:55<03:20,  1.35it/s, training_loss=0.389]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 891/1161 [10:55<03:19,  1.36it/s, training_loss=0.389]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 891/1161 [10:56<03:19,  1.36it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 892/1161 [10:56<03:18,  1.35it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 892/1161 [10:56<03:18,  1.35it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 893/1161 [10:56<03:17,  1.36it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 893/1161 [10:57<03:17,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 894/1161 [10:57<03:16,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 894/1161 [10:58<03:16,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 895/1161 [10:58<03:16,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 895/1161 [10:58<03:16,  1.36it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 896/1161 [10:58<03:15,  1.36it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 896/1161 [10:59<03:15,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 897/1161 [10:59<03:14,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 897/1161 [11:00<03:14,  1.36it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 898/1161 [11:00<03:13,  1.36it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 898/1161 [11:01<03:13,  1.36it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 899/1161 [11:01<03:13,  1.36it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 899/1161 [11:01<03:13,  1.36it/s, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 900/1161 [11:01<03:12,  1.36it/s, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 900/1161 [11:02<03:12,  1.36it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 901/1161 [11:02<03:11,  1.36it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 901/1161 [11:03<03:11,  1.36it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 902/1161 [11:03<03:10,  1.36it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 902/1161 [11:04<03:10,  1.36it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 903/1161 [11:04<03:09,  1.36it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 903/1161 [11:04<03:09,  1.36it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 904/1161 [11:04<03:09,  1.36it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 904/1161 [11:05<03:09,  1.36it/s, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 905/1161 [11:05<03:08,  1.36it/s, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 905/1161 [11:06<03:08,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 906/1161 [11:06<03:08,  1.35it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 906/1161 [11:07<03:08,  1.35it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 907/1161 [11:07<03:07,  1.36it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 907/1161 [11:07<03:07,  1.36it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 908/1161 [11:07<03:06,  1.35it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 908/1161 [11:08<03:06,  1.35it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 909/1161 [11:08<03:06,  1.35it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 909/1161 [11:09<03:06,  1.35it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 910/1161 [11:09<03:05,  1.35it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 910/1161 [11:10<03:05,  1.35it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 911/1161 [11:10<03:05,  1.35it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 911/1161 [11:10<03:05,  1.35it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 912/1161 [11:10<03:05,  1.34it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 912/1161 [11:11<03:05,  1.34it/s, training_loss=0.332]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 913/1161 [11:11<03:03,  1.35it/s, training_loss=0.332]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 913/1161 [11:12<03:03,  1.35it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 914/1161 [11:12<03:02,  1.35it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 914/1161 [11:12<03:02,  1.35it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 915/1161 [11:12<03:01,  1.36it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 915/1161 [11:13<03:01,  1.36it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 916/1161 [11:13<03:00,  1.36it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 916/1161 [11:14<03:00,  1.36it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 917/1161 [11:14<02:59,  1.36it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 917/1161 [11:15<02:59,  1.36it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 918/1161 [11:15<02:58,  1.36it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 918/1161 [11:15<02:58,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 919/1161 [11:15<02:58,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 919/1161 [11:16<02:58,  1.36it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 920/1161 [11:16<02:57,  1.36it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 920/1161 [11:17<02:57,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 921/1161 [11:17<02:57,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 921/1161 [11:18<02:57,  1.36it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 922/1161 [11:18<02:55,  1.36it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 922/1161 [11:18<02:55,  1.36it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 923/1161 [11:18<02:55,  1.36it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 923/1161 [11:19<02:55,  1.36it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 924/1161 [11:19<02:54,  1.36it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 924/1161 [11:20<02:54,  1.36it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 925/1161 [11:20<02:54,  1.36it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 925/1161 [11:21<02:54,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 926/1161 [11:21<02:52,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 926/1161 [11:21<02:52,  1.36it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 927/1161 [11:21<02:52,  1.36it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 927/1161 [11:22<02:52,  1.36it/s, training_loss=0.461]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 928/1161 [11:22<02:51,  1.36it/s, training_loss=0.461]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 928/1161 [11:23<02:51,  1.36it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  80%|████████  | 929/1161 [11:23<02:51,  1.36it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  80%|████████  | 929/1161 [11:24<02:51,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  80%|████████  | 930/1161 [11:24<02:50,  1.35it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  80%|████████  | 930/1161 [11:24<02:50,  1.35it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  80%|████████  | 931/1161 [11:24<02:49,  1.35it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  80%|████████  | 931/1161 [11:25<02:49,  1.35it/s, training_loss=0.479]\u001b[A\n",
            "Epoch 1:  80%|████████  | 932/1161 [11:25<02:50,  1.34it/s, training_loss=0.479]\u001b[A\n",
            "Epoch 1:  80%|████████  | 932/1161 [11:26<02:50,  1.34it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  80%|████████  | 933/1161 [11:26<02:48,  1.35it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  80%|████████  | 933/1161 [11:27<02:48,  1.35it/s, training_loss=0.447]\u001b[A\n",
            "Epoch 1:  80%|████████  | 934/1161 [11:27<02:47,  1.35it/s, training_loss=0.447]\u001b[A\n",
            "Epoch 1:  80%|████████  | 934/1161 [11:27<02:47,  1.35it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  81%|████████  | 935/1161 [11:27<02:47,  1.35it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  81%|████████  | 935/1161 [11:28<02:47,  1.35it/s, training_loss=0.042]\u001b[A\n",
            "Epoch 1:  81%|████████  | 936/1161 [11:28<02:45,  1.36it/s, training_loss=0.042]\u001b[A\n",
            "Epoch 1:  81%|████████  | 936/1161 [11:29<02:45,  1.36it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  81%|████████  | 937/1161 [11:29<02:44,  1.36it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  81%|████████  | 937/1161 [11:29<02:44,  1.36it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 1:  81%|████████  | 938/1161 [11:29<02:43,  1.36it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 1:  81%|████████  | 938/1161 [11:30<02:43,  1.36it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  81%|████████  | 939/1161 [11:30<02:42,  1.37it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  81%|████████  | 939/1161 [11:31<02:42,  1.37it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  81%|████████  | 940/1161 [11:31<02:42,  1.36it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  81%|████████  | 940/1161 [11:32<02:42,  1.36it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  81%|████████  | 941/1161 [11:32<02:41,  1.36it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  81%|████████  | 941/1161 [11:32<02:41,  1.36it/s, training_loss=0.348]\u001b[A\n",
            "Epoch 1:  81%|████████  | 942/1161 [11:32<02:41,  1.36it/s, training_loss=0.348]\u001b[A\n",
            "Epoch 1:  81%|████████  | 942/1161 [11:33<02:41,  1.36it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  81%|████████  | 943/1161 [11:33<02:39,  1.36it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  81%|████████  | 943/1161 [11:34<02:39,  1.36it/s, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 944/1161 [11:34<02:39,  1.36it/s, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 944/1161 [11:35<02:39,  1.36it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 945/1161 [11:35<02:38,  1.36it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 945/1161 [11:35<02:38,  1.36it/s, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 946/1161 [11:35<02:38,  1.36it/s, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 946/1161 [11:36<02:38,  1.36it/s, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 947/1161 [11:36<02:37,  1.36it/s, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 947/1161 [11:37<02:37,  1.36it/s, training_loss=0.449]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 948/1161 [11:37<02:37,  1.35it/s, training_loss=0.449]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 948/1161 [11:38<02:37,  1.35it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 949/1161 [11:38<02:37,  1.35it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 949/1161 [11:38<02:37,  1.35it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 950/1161 [11:38<02:36,  1.35it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 950/1161 [11:39<02:36,  1.35it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 951/1161 [11:39<02:35,  1.35it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 951/1161 [11:40<02:35,  1.35it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 952/1161 [11:40<02:34,  1.36it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 952/1161 [11:40<02:34,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 953/1161 [11:40<02:33,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 953/1161 [11:41<02:33,  1.36it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 954/1161 [11:41<02:32,  1.36it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 954/1161 [11:42<02:32,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 955/1161 [11:42<02:31,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 955/1161 [11:43<02:31,  1.36it/s, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 956/1161 [11:43<02:31,  1.36it/s, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 956/1161 [11:43<02:31,  1.36it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 957/1161 [11:43<02:30,  1.36it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 957/1161 [11:44<02:30,  1.36it/s, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 958/1161 [11:44<02:28,  1.36it/s, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 958/1161 [11:45<02:28,  1.36it/s, training_loss=0.403]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 959/1161 [11:45<02:28,  1.36it/s, training_loss=0.403]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 959/1161 [11:46<02:28,  1.36it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 960/1161 [11:46<02:27,  1.36it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 960/1161 [11:46<02:27,  1.36it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 961/1161 [11:46<02:27,  1.36it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 961/1161 [11:47<02:27,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 962/1161 [11:47<02:26,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 962/1161 [11:48<02:26,  1.36it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 963/1161 [11:48<02:26,  1.35it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 963/1161 [11:49<02:26,  1.35it/s, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 964/1161 [11:49<02:25,  1.35it/s, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 964/1161 [11:49<02:25,  1.35it/s, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 965/1161 [11:49<02:24,  1.35it/s, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 965/1161 [11:50<02:24,  1.35it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 966/1161 [11:50<02:23,  1.36it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 966/1161 [11:51<02:23,  1.36it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 967/1161 [11:51<02:22,  1.36it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 967/1161 [11:52<02:22,  1.36it/s, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 968/1161 [11:52<02:22,  1.36it/s, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 968/1161 [11:52<02:22,  1.36it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 969/1161 [11:52<02:21,  1.35it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 969/1161 [11:53<02:21,  1.35it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 970/1161 [11:53<02:20,  1.36it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 970/1161 [11:54<02:20,  1.36it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 971/1161 [11:54<02:19,  1.36it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 971/1161 [11:54<02:19,  1.36it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 972/1161 [11:54<02:18,  1.36it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 972/1161 [11:55<02:18,  1.36it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 973/1161 [11:55<02:18,  1.36it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 973/1161 [11:56<02:18,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 974/1161 [11:56<02:17,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 974/1161 [11:57<02:17,  1.36it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 975/1161 [11:57<02:16,  1.36it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 975/1161 [11:57<02:16,  1.36it/s, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 976/1161 [11:57<02:16,  1.35it/s, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 976/1161 [11:58<02:16,  1.35it/s, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 977/1161 [11:58<02:15,  1.35it/s, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 977/1161 [11:59<02:15,  1.35it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 978/1161 [11:59<02:14,  1.36it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 978/1161 [12:00<02:14,  1.36it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 979/1161 [12:00<02:14,  1.36it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 979/1161 [12:00<02:14,  1.36it/s, training_loss=0.362]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 980/1161 [12:00<02:13,  1.36it/s, training_loss=0.362]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 980/1161 [12:01<02:13,  1.36it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 981/1161 [12:01<02:12,  1.36it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 981/1161 [12:02<02:12,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 982/1161 [12:02<02:11,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 982/1161 [12:03<02:11,  1.36it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 983/1161 [12:03<02:10,  1.36it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 983/1161 [12:03<02:10,  1.36it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 984/1161 [12:03<02:10,  1.36it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 984/1161 [12:04<02:10,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 985/1161 [12:04<02:10,  1.35it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 985/1161 [12:05<02:10,  1.35it/s, training_loss=0.368]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 986/1161 [12:05<02:09,  1.35it/s, training_loss=0.368]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 986/1161 [12:06<02:09,  1.35it/s, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 987/1161 [12:06<02:08,  1.36it/s, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 987/1161 [12:06<02:08,  1.36it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 988/1161 [12:06<02:07,  1.36it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 988/1161 [12:07<02:07,  1.36it/s, training_loss=0.338]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 989/1161 [12:07<02:06,  1.36it/s, training_loss=0.338]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 989/1161 [12:08<02:06,  1.36it/s, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 990/1161 [12:08<02:05,  1.36it/s, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 990/1161 [12:08<02:05,  1.36it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 991/1161 [12:08<02:05,  1.36it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 991/1161 [12:09<02:05,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 992/1161 [12:09<02:04,  1.35it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 992/1161 [12:10<02:04,  1.35it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 993/1161 [12:10<02:03,  1.36it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 993/1161 [12:11<02:03,  1.36it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 994/1161 [12:11<02:03,  1.35it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 994/1161 [12:11<02:03,  1.35it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 995/1161 [12:11<02:02,  1.35it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 995/1161 [12:12<02:02,  1.35it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 996/1161 [12:12<02:01,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 996/1161 [12:13<02:01,  1.36it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 997/1161 [12:13<02:01,  1.35it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 997/1161 [12:14<02:01,  1.35it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 998/1161 [12:14<01:59,  1.36it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 998/1161 [12:14<01:59,  1.36it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 999/1161 [12:14<01:59,  1.35it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 999/1161 [12:15<01:59,  1.35it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1000/1161 [12:15<01:59,  1.35it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1000/1161 [12:16<01:59,  1.35it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1001/1161 [12:16<01:58,  1.35it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1001/1161 [12:17<01:58,  1.35it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 1002/1161 [12:17<01:57,  1.35it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 1002/1161 [12:17<01:57,  1.35it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 1003/1161 [12:17<01:56,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 1003/1161 [12:18<01:56,  1.36it/s, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 1004/1161 [12:18<01:55,  1.36it/s, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 1004/1161 [12:19<01:55,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1005/1161 [12:19<01:55,  1.35it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1005/1161 [12:20<01:55,  1.35it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1006/1161 [12:20<01:54,  1.36it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1006/1161 [12:20<01:54,  1.36it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1007/1161 [12:20<01:53,  1.35it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1007/1161 [12:21<01:53,  1.35it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1008/1161 [12:21<01:52,  1.36it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1008/1161 [12:22<01:52,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1009/1161 [12:22<01:52,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1009/1161 [12:22<01:52,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1010/1161 [12:23<01:51,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1010/1161 [12:23<01:51,  1.36it/s, training_loss=0.429]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1011/1161 [12:23<01:50,  1.36it/s, training_loss=0.429]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1011/1161 [12:24<01:50,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1012/1161 [12:24<01:49,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1012/1161 [12:25<01:49,  1.36it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1013/1161 [12:25<01:49,  1.35it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1013/1161 [12:25<01:49,  1.35it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1014/1161 [12:25<01:48,  1.36it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1014/1161 [12:26<01:48,  1.36it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1015/1161 [12:26<01:47,  1.36it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1015/1161 [12:27<01:47,  1.36it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1016/1161 [12:27<01:47,  1.35it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1016/1161 [12:28<01:47,  1.35it/s, training_loss=0.424]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1017/1161 [12:28<01:46,  1.36it/s, training_loss=0.424]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1017/1161 [12:28<01:46,  1.36it/s, training_loss=0.459]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1018/1161 [12:28<01:45,  1.36it/s, training_loss=0.459]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1018/1161 [12:29<01:45,  1.36it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1019/1161 [12:29<01:44,  1.36it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1019/1161 [12:30<01:44,  1.36it/s, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1020/1161 [12:30<01:44,  1.35it/s, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1020/1161 [12:31<01:44,  1.35it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1021/1161 [12:31<01:43,  1.36it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1021/1161 [12:31<01:43,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1022/1161 [12:31<01:42,  1.35it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1022/1161 [12:32<01:42,  1.35it/s, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1023/1161 [12:32<01:41,  1.36it/s, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1023/1161 [12:33<01:41,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1024/1161 [12:33<01:40,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1024/1161 [12:34<01:40,  1.36it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1025/1161 [12:34<01:39,  1.36it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1025/1161 [12:34<01:39,  1.36it/s, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1026/1161 [12:34<01:38,  1.37it/s, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1026/1161 [12:35<01:38,  1.37it/s, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1027/1161 [12:35<01:38,  1.37it/s, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1027/1161 [12:36<01:38,  1.37it/s, training_loss=0.031]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 1028/1161 [12:36<01:37,  1.36it/s, training_loss=0.031]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 1028/1161 [12:36<01:37,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 1029/1161 [12:36<01:36,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 1029/1161 [12:37<01:36,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 1030/1161 [12:37<01:35,  1.37it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 1030/1161 [12:38<01:35,  1.37it/s, training_loss=0.362]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1031/1161 [12:38<01:34,  1.37it/s, training_loss=0.362]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1031/1161 [12:39<01:34,  1.37it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1032/1161 [12:39<01:34,  1.37it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1032/1161 [12:39<01:34,  1.37it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1033/1161 [12:39<01:33,  1.37it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1033/1161 [12:40<01:33,  1.37it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1034/1161 [12:40<01:32,  1.37it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1034/1161 [12:41<01:32,  1.37it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1035/1161 [12:41<01:32,  1.37it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1035/1161 [12:42<01:32,  1.37it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1036/1161 [12:42<01:31,  1.37it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1036/1161 [12:42<01:31,  1.37it/s, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1037/1161 [12:42<01:30,  1.37it/s, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1037/1161 [12:43<01:30,  1.37it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1038/1161 [12:43<01:30,  1.36it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1038/1161 [12:44<01:30,  1.36it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1039/1161 [12:44<01:29,  1.36it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1039/1161 [12:45<01:29,  1.36it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1040/1161 [12:45<01:28,  1.36it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1040/1161 [12:45<01:28,  1.36it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1041/1161 [12:45<01:27,  1.37it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1041/1161 [12:46<01:27,  1.37it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1042/1161 [12:46<01:27,  1.37it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1042/1161 [12:47<01:27,  1.37it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1043/1161 [12:47<01:26,  1.37it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1043/1161 [12:47<01:26,  1.37it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1044/1161 [12:47<01:25,  1.37it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1044/1161 [12:48<01:25,  1.37it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1045/1161 [12:48<01:24,  1.37it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1045/1161 [12:49<01:24,  1.37it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1046/1161 [12:49<01:24,  1.37it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1046/1161 [12:50<01:24,  1.37it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1047/1161 [12:50<01:23,  1.37it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1047/1161 [12:50<01:23,  1.37it/s, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1048/1161 [12:50<01:22,  1.37it/s, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1048/1161 [12:51<01:22,  1.37it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1049/1161 [12:51<01:22,  1.36it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1049/1161 [12:52<01:22,  1.36it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1050/1161 [12:52<01:21,  1.37it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1050/1161 [12:53<01:21,  1.37it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1051/1161 [12:53<01:20,  1.37it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1051/1161 [12:53<01:20,  1.37it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1052/1161 [12:53<01:19,  1.37it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1052/1161 [12:54<01:19,  1.37it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1053/1161 [12:54<01:18,  1.37it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1053/1161 [12:55<01:18,  1.37it/s, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1054/1161 [12:55<01:18,  1.37it/s, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1054/1161 [12:55<01:18,  1.37it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1055/1161 [12:56<01:17,  1.37it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1055/1161 [12:56<01:17,  1.37it/s, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1056/1161 [12:56<01:16,  1.37it/s, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1056/1161 [12:57<01:16,  1.37it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1057/1161 [12:57<01:16,  1.36it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1057/1161 [12:58<01:16,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1058/1161 [12:58<01:15,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1058/1161 [12:58<01:15,  1.36it/s, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1059/1161 [12:58<01:15,  1.36it/s, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1059/1161 [12:59<01:15,  1.36it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 1060/1161 [12:59<01:14,  1.36it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 1060/1161 [13:00<01:14,  1.36it/s, training_loss=0.474]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 1061/1161 [13:00<01:13,  1.36it/s, training_loss=0.474]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 1061/1161 [13:01<01:13,  1.36it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 1062/1161 [13:01<01:12,  1.36it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 1062/1161 [13:01<01:12,  1.36it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1063/1161 [13:01<01:12,  1.36it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1063/1161 [13:02<01:12,  1.36it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1064/1161 [13:02<01:11,  1.36it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1064/1161 [13:03<01:11,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1065/1161 [13:03<01:10,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1065/1161 [13:04<01:10,  1.36it/s, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1066/1161 [13:04<01:10,  1.36it/s, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1066/1161 [13:04<01:10,  1.36it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1067/1161 [13:04<01:08,  1.36it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1067/1161 [13:05<01:08,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1068/1161 [13:05<01:08,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1068/1161 [13:06<01:08,  1.36it/s, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1069/1161 [13:06<01:07,  1.36it/s, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1069/1161 [13:07<01:07,  1.36it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1070/1161 [13:07<01:06,  1.36it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1070/1161 [13:07<01:06,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1071/1161 [13:07<01:06,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1071/1161 [13:08<01:06,  1.36it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1072/1161 [13:08<01:05,  1.36it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1072/1161 [13:09<01:05,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1073/1161 [13:09<01:04,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1073/1161 [13:09<01:04,  1.36it/s, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1074/1161 [13:09<01:03,  1.36it/s, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1074/1161 [13:10<01:03,  1.36it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1075/1161 [13:10<01:03,  1.37it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1075/1161 [13:11<01:03,  1.37it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1076/1161 [13:11<01:02,  1.36it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1076/1161 [13:12<01:02,  1.36it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1077/1161 [13:12<01:01,  1.36it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1077/1161 [13:12<01:01,  1.36it/s, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1078/1161 [13:12<01:01,  1.36it/s, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1078/1161 [13:13<01:01,  1.36it/s, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1079/1161 [13:13<01:00,  1.36it/s, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1079/1161 [13:14<01:00,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1080/1161 [13:14<00:59,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1080/1161 [13:15<00:59,  1.36it/s, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1081/1161 [13:15<00:58,  1.36it/s, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1081/1161 [13:15<00:58,  1.36it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1082/1161 [13:15<00:57,  1.36it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1082/1161 [13:16<00:57,  1.36it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1083/1161 [13:16<00:57,  1.36it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1083/1161 [13:17<00:57,  1.36it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1084/1161 [13:17<00:56,  1.37it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1084/1161 [13:18<00:56,  1.37it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1085/1161 [13:18<00:55,  1.36it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1085/1161 [13:18<00:55,  1.36it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 1086/1161 [13:18<00:55,  1.36it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 1086/1161 [13:19<00:55,  1.36it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 1087/1161 [13:19<00:54,  1.36it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 1087/1161 [13:20<00:54,  1.36it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 1088/1161 [13:20<00:53,  1.36it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 1088/1161 [13:20<00:53,  1.36it/s, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1089/1161 [13:21<00:53,  1.35it/s, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1089/1161 [13:21<00:53,  1.35it/s, training_loss=0.328]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1090/1161 [13:21<00:52,  1.36it/s, training_loss=0.328]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1090/1161 [13:22<00:52,  1.36it/s, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1091/1161 [13:22<00:51,  1.36it/s, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1091/1161 [13:23<00:51,  1.36it/s, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1092/1161 [13:23<00:50,  1.36it/s, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1092/1161 [13:23<00:50,  1.36it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1093/1161 [13:23<00:50,  1.36it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1093/1161 [13:24<00:50,  1.36it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1094/1161 [13:24<00:49,  1.36it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1094/1161 [13:25<00:49,  1.36it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1095/1161 [13:25<00:48,  1.36it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1095/1161 [13:26<00:48,  1.36it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1096/1161 [13:26<00:47,  1.36it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1096/1161 [13:26<00:47,  1.36it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1097/1161 [13:26<00:46,  1.36it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1097/1161 [13:27<00:46,  1.36it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1098/1161 [13:27<00:46,  1.36it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1098/1161 [13:28<00:46,  1.36it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1099/1161 [13:28<00:45,  1.36it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1099/1161 [13:29<00:45,  1.36it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1100/1161 [13:29<00:44,  1.36it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1100/1161 [13:29<00:44,  1.36it/s, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1101/1161 [13:29<00:44,  1.35it/s, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1101/1161 [13:30<00:44,  1.35it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1102/1161 [13:30<00:43,  1.35it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1102/1161 [13:31<00:43,  1.35it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1103/1161 [13:31<00:42,  1.35it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1103/1161 [13:32<00:42,  1.35it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1104/1161 [13:32<00:42,  1.35it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1104/1161 [13:32<00:42,  1.35it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1105/1161 [13:32<00:41,  1.36it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1105/1161 [13:33<00:41,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1106/1161 [13:33<00:40,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1106/1161 [13:34<00:40,  1.36it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1107/1161 [13:34<00:39,  1.36it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1107/1161 [13:34<00:39,  1.36it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1108/1161 [13:34<00:38,  1.36it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1108/1161 [13:35<00:38,  1.36it/s, training_loss=0.359]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1109/1161 [13:35<00:38,  1.36it/s, training_loss=0.359]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1109/1161 [13:36<00:38,  1.36it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1110/1161 [13:36<00:37,  1.36it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1110/1161 [13:37<00:37,  1.36it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1111/1161 [13:37<00:36,  1.37it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1111/1161 [13:37<00:36,  1.37it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1112/1161 [13:37<00:35,  1.36it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1112/1161 [13:38<00:35,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1113/1161 [13:38<00:35,  1.37it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1113/1161 [13:39<00:35,  1.37it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1114/1161 [13:39<00:34,  1.37it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1114/1161 [13:40<00:34,  1.37it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1115/1161 [13:40<00:33,  1.37it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1115/1161 [13:40<00:33,  1.37it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1116/1161 [13:40<00:32,  1.37it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1116/1161 [13:41<00:32,  1.37it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1117/1161 [13:41<00:32,  1.37it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1117/1161 [13:42<00:32,  1.37it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 1118/1161 [13:42<00:31,  1.36it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 1118/1161 [13:43<00:31,  1.36it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 1119/1161 [13:43<00:30,  1.36it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 1119/1161 [13:43<00:30,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 1120/1161 [13:43<00:30,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 1120/1161 [13:44<00:30,  1.36it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1121/1161 [13:44<00:29,  1.37it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1121/1161 [13:45<00:29,  1.37it/s, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1122/1161 [13:45<00:28,  1.36it/s, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1122/1161 [13:45<00:28,  1.36it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1123/1161 [13:45<00:27,  1.36it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1123/1161 [13:46<00:27,  1.36it/s, training_loss=0.338]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1124/1161 [13:46<00:27,  1.36it/s, training_loss=0.338]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1124/1161 [13:47<00:27,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1125/1161 [13:47<00:26,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1125/1161 [13:48<00:26,  1.36it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1126/1161 [13:48<00:25,  1.36it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1126/1161 [13:48<00:25,  1.36it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1127/1161 [13:48<00:24,  1.37it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1127/1161 [13:49<00:24,  1.37it/s, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1128/1161 [13:49<00:24,  1.37it/s, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1128/1161 [13:50<00:24,  1.37it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1129/1161 [13:50<00:23,  1.37it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1129/1161 [13:51<00:23,  1.37it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1130/1161 [13:51<00:22,  1.37it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1130/1161 [13:51<00:22,  1.37it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1131/1161 [13:51<00:22,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1131/1161 [13:52<00:22,  1.36it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1132/1161 [13:52<00:21,  1.36it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1132/1161 [13:53<00:21,  1.36it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1133/1161 [13:53<00:20,  1.36it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1133/1161 [13:54<00:20,  1.36it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1134/1161 [13:54<00:19,  1.36it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1134/1161 [13:54<00:19,  1.36it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1135/1161 [13:54<00:19,  1.36it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1135/1161 [13:55<00:19,  1.36it/s, training_loss=0.415]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1136/1161 [13:55<00:18,  1.36it/s, training_loss=0.415]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1136/1161 [13:56<00:18,  1.36it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1137/1161 [13:56<00:17,  1.36it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1137/1161 [13:56<00:17,  1.36it/s, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1138/1161 [13:56<00:16,  1.37it/s, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1138/1161 [13:57<00:16,  1.37it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1139/1161 [13:57<00:16,  1.37it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1139/1161 [13:58<00:16,  1.37it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1140/1161 [13:58<00:15,  1.37it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1140/1161 [13:59<00:15,  1.37it/s, training_loss=0.349]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1141/1161 [13:59<00:14,  1.36it/s, training_loss=0.349]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1141/1161 [13:59<00:14,  1.36it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1142/1161 [13:59<00:13,  1.37it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1142/1161 [14:00<00:13,  1.37it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1143/1161 [14:00<00:13,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1143/1161 [14:01<00:13,  1.36it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 1144/1161 [14:01<00:12,  1.36it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 1144/1161 [14:02<00:12,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 1145/1161 [14:02<00:11,  1.37it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 1145/1161 [14:02<00:11,  1.37it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 1146/1161 [14:02<00:10,  1.36it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 1146/1161 [14:03<00:10,  1.36it/s, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1147/1161 [14:03<00:10,  1.36it/s, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1147/1161 [14:04<00:10,  1.36it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1148/1161 [14:04<00:09,  1.37it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1148/1161 [14:05<00:09,  1.37it/s, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1149/1161 [14:05<00:08,  1.37it/s, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1149/1161 [14:05<00:08,  1.37it/s, training_loss=0.249]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1150/1161 [14:05<00:08,  1.37it/s, training_loss=0.249]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1150/1161 [14:06<00:08,  1.37it/s, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1151/1161 [14:06<00:07,  1.37it/s, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1151/1161 [14:07<00:07,  1.37it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1152/1161 [14:07<00:06,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1152/1161 [14:07<00:06,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1153/1161 [14:07<00:05,  1.35it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1153/1161 [14:08<00:05,  1.35it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1154/1161 [14:08<00:05,  1.35it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1154/1161 [14:09<00:05,  1.35it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1155/1161 [14:09<00:04,  1.35it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1155/1161 [14:10<00:04,  1.35it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1156/1161 [14:10<00:03,  1.35it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1156/1161 [14:10<00:03,  1.35it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1157/1161 [14:10<00:02,  1.35it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1157/1161 [14:11<00:02,  1.35it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1158/1161 [14:11<00:02,  1.35it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1158/1161 [14:12<00:02,  1.35it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1159/1161 [14:12<00:01,  1.35it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1159/1161 [14:13<00:01,  1.35it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1160/1161 [14:13<00:00,  1.35it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1160/1161 [14:13<00:00,  1.35it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 1: 100%|██████████| 1161/1161 [14:13<00:00,  1.40it/s, training_loss=0.188]\u001b[A\n",
            "  0%|          | 0/2 [14:15<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training loss: 0.7535473093788343\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1/2 [15:58<15:58, 958.87s/it]\n",
            "Epoch 2:   0%|          | 0/1161 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5752791383084709\n",
            "F1 Score (Weighted): 0.7897417570780163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2:   0%|          | 0/1161 [00:00<?, ?it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:   0%|          | 1/1161 [00:00<13:55,  1.39it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:   0%|          | 1/1161 [00:01<13:55,  1.39it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 2:   0%|          | 2/1161 [00:01<14:07,  1.37it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 2:   0%|          | 2/1161 [00:02<14:07,  1.37it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:   0%|          | 3/1161 [00:02<14:09,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:   0%|          | 3/1161 [00:02<14:09,  1.36it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:   0%|          | 4/1161 [00:02<14:08,  1.36it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:   0%|          | 4/1161 [00:03<14:08,  1.36it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 2:   0%|          | 5/1161 [00:03<14:07,  1.36it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 2:   0%|          | 5/1161 [00:04<14:07,  1.36it/s, training_loss=0.313]\u001b[A\n",
            "Epoch 2:   1%|          | 6/1161 [00:04<14:07,  1.36it/s, training_loss=0.313]\u001b[A\n",
            "Epoch 2:   1%|          | 6/1161 [00:05<14:07,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:   1%|          | 7/1161 [00:05<14:07,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:   1%|          | 7/1161 [00:05<14:07,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:   1%|          | 8/1161 [00:05<14:07,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:   1%|          | 8/1161 [00:06<14:07,  1.36it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 2:   1%|          | 9/1161 [00:06<14:10,  1.35it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 2:   1%|          | 9/1161 [00:07<14:10,  1.35it/s, training_loss=0.291]\u001b[A\n",
            "Epoch 2:   1%|          | 10/1161 [00:07<14:10,  1.35it/s, training_loss=0.291]\u001b[A\n",
            "Epoch 2:   1%|          | 10/1161 [00:08<14:10,  1.35it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:   1%|          | 11/1161 [00:08<14:09,  1.35it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:   1%|          | 11/1161 [00:08<14:09,  1.35it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 2:   1%|          | 12/1161 [00:08<14:09,  1.35it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 2:   1%|          | 12/1161 [00:09<14:09,  1.35it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:   1%|          | 13/1161 [00:09<14:06,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:   1%|          | 13/1161 [00:10<14:06,  1.36it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:   1%|          | 14/1161 [00:10<14:07,  1.35it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:   1%|          | 14/1161 [00:11<14:07,  1.35it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 2:   1%|▏         | 15/1161 [00:11<14:09,  1.35it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 2:   1%|▏         | 15/1161 [00:11<14:09,  1.35it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 2:   1%|▏         | 16/1161 [00:11<14:05,  1.35it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 2:   1%|▏         | 16/1161 [00:12<14:05,  1.35it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 2:   1%|▏         | 17/1161 [00:12<14:04,  1.35it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 2:   1%|▏         | 17/1161 [00:13<14:04,  1.35it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:   2%|▏         | 18/1161 [00:13<14:04,  1.35it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:   2%|▏         | 18/1161 [00:14<14:04,  1.35it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 2:   2%|▏         | 19/1161 [00:14<14:02,  1.36it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 2:   2%|▏         | 19/1161 [00:14<14:02,  1.36it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:   2%|▏         | 20/1161 [00:14<14:03,  1.35it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:   2%|▏         | 20/1161 [00:15<14:03,  1.35it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:   2%|▏         | 21/1161 [00:15<14:03,  1.35it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:   2%|▏         | 21/1161 [00:16<14:03,  1.35it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:   2%|▏         | 22/1161 [00:16<14:04,  1.35it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:   2%|▏         | 22/1161 [00:16<14:04,  1.35it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:   2%|▏         | 23/1161 [00:16<14:01,  1.35it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:   2%|▏         | 23/1161 [00:17<14:01,  1.35it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 2:   2%|▏         | 24/1161 [00:17<13:58,  1.36it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 2:   2%|▏         | 24/1161 [00:18<13:58,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:   2%|▏         | 25/1161 [00:18<13:57,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:   2%|▏         | 25/1161 [00:19<13:57,  1.36it/s, training_loss=0.320]\u001b[A\n",
            "Epoch 2:   2%|▏         | 26/1161 [00:19<13:59,  1.35it/s, training_loss=0.320]\u001b[A\n",
            "Epoch 2:   2%|▏         | 26/1161 [00:19<13:59,  1.35it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 2:   2%|▏         | 27/1161 [00:19<13:57,  1.35it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 2:   2%|▏         | 27/1161 [00:20<13:57,  1.35it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:   2%|▏         | 28/1161 [00:20<13:59,  1.35it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:   2%|▏         | 28/1161 [00:21<13:59,  1.35it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:   2%|▏         | 29/1161 [00:21<13:56,  1.35it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:   2%|▏         | 29/1161 [00:22<13:56,  1.35it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:   3%|▎         | 30/1161 [00:22<13:55,  1.35it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:   3%|▎         | 30/1161 [00:22<13:55,  1.35it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:   3%|▎         | 31/1161 [00:22<13:54,  1.35it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:   3%|▎         | 31/1161 [00:23<13:54,  1.35it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 2:   3%|▎         | 32/1161 [00:23<13:54,  1.35it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 2:   3%|▎         | 32/1161 [00:24<13:54,  1.35it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 2:   3%|▎         | 33/1161 [00:24<13:53,  1.35it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 2:   3%|▎         | 33/1161 [00:25<13:53,  1.35it/s, training_loss=0.475]\u001b[A\n",
            "Epoch 2:   3%|▎         | 34/1161 [00:25<13:54,  1.35it/s, training_loss=0.475]\u001b[A\n",
            "Epoch 2:   3%|▎         | 34/1161 [00:25<13:54,  1.35it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 2:   3%|▎         | 35/1161 [00:25<13:49,  1.36it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 2:   3%|▎         | 35/1161 [00:26<13:49,  1.36it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 2:   3%|▎         | 36/1161 [00:26<13:52,  1.35it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 2:   3%|▎         | 36/1161 [00:27<13:52,  1.35it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:   3%|▎         | 37/1161 [00:27<13:53,  1.35it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:   3%|▎         | 37/1161 [00:28<13:53,  1.35it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:   3%|▎         | 38/1161 [00:28<13:52,  1.35it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:   3%|▎         | 38/1161 [00:28<13:52,  1.35it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:   3%|▎         | 39/1161 [00:28<13:48,  1.35it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:   3%|▎         | 39/1161 [00:29<13:48,  1.35it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 2:   3%|▎         | 40/1161 [00:29<13:46,  1.36it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 2:   3%|▎         | 40/1161 [00:30<13:46,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:   4%|▎         | 41/1161 [00:30<13:44,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:   4%|▎         | 41/1161 [00:31<13:44,  1.36it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:   4%|▎         | 42/1161 [00:31<13:45,  1.36it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:   4%|▎         | 42/1161 [00:31<13:45,  1.36it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:   4%|▎         | 43/1161 [00:31<13:43,  1.36it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:   4%|▎         | 43/1161 [00:32<13:43,  1.36it/s, training_loss=0.221]\u001b[A\n",
            "Epoch 2:   4%|▍         | 44/1161 [00:32<13:43,  1.36it/s, training_loss=0.221]\u001b[A\n",
            "Epoch 2:   4%|▍         | 44/1161 [00:33<13:43,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 2:   4%|▍         | 45/1161 [00:33<13:38,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 2:   4%|▍         | 45/1161 [00:33<13:38,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:   4%|▍         | 46/1161 [00:33<13:41,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:   4%|▍         | 46/1161 [00:34<13:41,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:   4%|▍         | 47/1161 [00:34<13:44,  1.35it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:   4%|▍         | 47/1161 [00:35<13:44,  1.35it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 2:   4%|▍         | 48/1161 [00:35<13:46,  1.35it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 2:   4%|▍         | 48/1161 [00:36<13:46,  1.35it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:   4%|▍         | 49/1161 [00:36<13:42,  1.35it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:   4%|▍         | 49/1161 [00:36<13:42,  1.35it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:   4%|▍         | 50/1161 [00:36<13:41,  1.35it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:   4%|▍         | 50/1161 [00:37<13:41,  1.35it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:   4%|▍         | 51/1161 [00:37<13:38,  1.36it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:   4%|▍         | 51/1161 [00:38<13:38,  1.36it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 2:   4%|▍         | 52/1161 [00:38<13:39,  1.35it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 2:   4%|▍         | 52/1161 [00:39<13:39,  1.35it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:   5%|▍         | 53/1161 [00:39<13:36,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:   5%|▍         | 53/1161 [00:39<13:36,  1.36it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:   5%|▍         | 54/1161 [00:39<13:34,  1.36it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:   5%|▍         | 54/1161 [00:40<13:34,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:   5%|▍         | 55/1161 [00:40<13:35,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:   5%|▍         | 55/1161 [00:41<13:35,  1.36it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:   5%|▍         | 56/1161 [00:41<13:32,  1.36it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:   5%|▍         | 56/1161 [00:42<13:32,  1.36it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:   5%|▍         | 57/1161 [00:42<13:28,  1.37it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:   5%|▍         | 57/1161 [00:42<13:28,  1.37it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:   5%|▍         | 58/1161 [00:42<13:28,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:   5%|▍         | 58/1161 [00:43<13:28,  1.36it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 2:   5%|▌         | 59/1161 [00:43<13:27,  1.36it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 2:   5%|▌         | 59/1161 [00:44<13:27,  1.36it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:   5%|▌         | 60/1161 [00:44<13:28,  1.36it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:   5%|▌         | 60/1161 [00:44<13:28,  1.36it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:   5%|▌         | 61/1161 [00:45<13:28,  1.36it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:   5%|▌         | 61/1161 [00:45<13:28,  1.36it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 2:   5%|▌         | 62/1161 [00:45<13:26,  1.36it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 2:   5%|▌         | 62/1161 [00:46<13:26,  1.36it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 2:   5%|▌         | 63/1161 [00:46<13:26,  1.36it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 2:   5%|▌         | 63/1161 [00:47<13:26,  1.36it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 2:   6%|▌         | 64/1161 [00:47<13:24,  1.36it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 2:   6%|▌         | 64/1161 [00:47<13:24,  1.36it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 2:   6%|▌         | 65/1161 [00:47<13:24,  1.36it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 2:   6%|▌         | 65/1161 [00:48<13:24,  1.36it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:   6%|▌         | 66/1161 [00:48<13:25,  1.36it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:   6%|▌         | 66/1161 [00:49<13:25,  1.36it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:   6%|▌         | 67/1161 [00:49<13:25,  1.36it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:   6%|▌         | 67/1161 [00:50<13:25,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:   6%|▌         | 68/1161 [00:50<13:23,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:   6%|▌         | 68/1161 [00:50<13:23,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 2:   6%|▌         | 69/1161 [00:50<13:23,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 2:   6%|▌         | 69/1161 [00:51<13:23,  1.36it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 2:   6%|▌         | 70/1161 [00:51<13:22,  1.36it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 2:   6%|▌         | 70/1161 [00:52<13:22,  1.36it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:   6%|▌         | 71/1161 [00:52<13:23,  1.36it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:   6%|▌         | 71/1161 [00:53<13:23,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 2:   6%|▌         | 72/1161 [00:53<13:22,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 2:   6%|▌         | 72/1161 [00:53<13:22,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:   6%|▋         | 73/1161 [00:53<13:20,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:   6%|▋         | 73/1161 [00:54<13:20,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:   6%|▋         | 74/1161 [00:54<13:18,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:   6%|▋         | 74/1161 [00:55<13:18,  1.36it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:   6%|▋         | 75/1161 [00:55<13:14,  1.37it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:   6%|▋         | 75/1161 [00:56<13:14,  1.37it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:   7%|▋         | 76/1161 [00:56<13:13,  1.37it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:   7%|▋         | 76/1161 [00:56<13:13,  1.37it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 2:   7%|▋         | 77/1161 [00:56<13:13,  1.37it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 2:   7%|▋         | 77/1161 [00:57<13:13,  1.37it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:   7%|▋         | 78/1161 [00:57<13:14,  1.36it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:   7%|▋         | 78/1161 [00:58<13:14,  1.36it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 2:   7%|▋         | 79/1161 [00:58<13:15,  1.36it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 2:   7%|▋         | 79/1161 [00:58<13:15,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:   7%|▋         | 80/1161 [00:58<13:13,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:   7%|▋         | 80/1161 [00:59<13:13,  1.36it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:   7%|▋         | 81/1161 [00:59<13:15,  1.36it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:   7%|▋         | 81/1161 [01:00<13:15,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:   7%|▋         | 82/1161 [01:00<13:13,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:   7%|▋         | 82/1161 [01:01<13:13,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 2:   7%|▋         | 83/1161 [01:01<13:13,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 2:   7%|▋         | 83/1161 [01:01<13:13,  1.36it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:   7%|▋         | 84/1161 [01:01<13:10,  1.36it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:   7%|▋         | 84/1161 [01:02<13:10,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:   7%|▋         | 85/1161 [01:02<13:08,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:   7%|▋         | 85/1161 [01:03<13:08,  1.36it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2:   7%|▋         | 86/1161 [01:03<13:08,  1.36it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2:   7%|▋         | 86/1161 [01:04<13:08,  1.36it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 2:   7%|▋         | 87/1161 [01:04<13:11,  1.36it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 2:   7%|▋         | 87/1161 [01:04<13:11,  1.36it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:   8%|▊         | 88/1161 [01:04<13:12,  1.35it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:   8%|▊         | 88/1161 [01:05<13:12,  1.35it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:   8%|▊         | 89/1161 [01:05<13:12,  1.35it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:   8%|▊         | 89/1161 [01:06<13:12,  1.35it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:   8%|▊         | 90/1161 [01:06<13:11,  1.35it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:   8%|▊         | 90/1161 [01:07<13:11,  1.35it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:   8%|▊         | 91/1161 [01:07<13:06,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:   8%|▊         | 91/1161 [01:07<13:06,  1.36it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:   8%|▊         | 92/1161 [01:07<13:07,  1.36it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:   8%|▊         | 92/1161 [01:08<13:07,  1.36it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:   8%|▊         | 93/1161 [01:08<13:04,  1.36it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:   8%|▊         | 93/1161 [01:09<13:04,  1.36it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:   8%|▊         | 94/1161 [01:09<13:03,  1.36it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:   8%|▊         | 94/1161 [01:09<13:03,  1.36it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:   8%|▊         | 95/1161 [01:10<13:04,  1.36it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:   8%|▊         | 95/1161 [01:10<13:04,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:   8%|▊         | 96/1161 [01:10<13:05,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:   8%|▊         | 96/1161 [01:11<13:05,  1.36it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 2:   8%|▊         | 97/1161 [01:11<13:02,  1.36it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 2:   8%|▊         | 97/1161 [01:12<13:02,  1.36it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:   8%|▊         | 98/1161 [01:12<13:01,  1.36it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:   8%|▊         | 98/1161 [01:12<13:01,  1.36it/s, training_loss=0.426]\u001b[A\n",
            "Epoch 2:   9%|▊         | 99/1161 [01:12<13:00,  1.36it/s, training_loss=0.426]\u001b[A\n",
            "Epoch 2:   9%|▊         | 99/1161 [01:13<13:00,  1.36it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 2:   9%|▊         | 100/1161 [01:13<12:58,  1.36it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 2:   9%|▊         | 100/1161 [01:14<12:58,  1.36it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:   9%|▊         | 101/1161 [01:14<12:56,  1.37it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:   9%|▊         | 101/1161 [01:15<12:56,  1.37it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:   9%|▉         | 102/1161 [01:15<12:56,  1.36it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:   9%|▉         | 102/1161 [01:15<12:56,  1.36it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 2:   9%|▉         | 103/1161 [01:15<12:56,  1.36it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 2:   9%|▉         | 103/1161 [01:16<12:56,  1.36it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 2:   9%|▉         | 104/1161 [01:16<12:58,  1.36it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 2:   9%|▉         | 104/1161 [01:17<12:58,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:   9%|▉         | 105/1161 [01:17<12:58,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:   9%|▉         | 105/1161 [01:18<12:58,  1.36it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 2:   9%|▉         | 106/1161 [01:18<13:00,  1.35it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 2:   9%|▉         | 106/1161 [01:18<13:00,  1.35it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 2:   9%|▉         | 107/1161 [01:18<12:58,  1.35it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 2:   9%|▉         | 107/1161 [01:19<12:58,  1.35it/s, training_loss=0.245]\u001b[A\n",
            "Epoch 2:   9%|▉         | 108/1161 [01:19<12:56,  1.36it/s, training_loss=0.245]\u001b[A\n",
            "Epoch 2:   9%|▉         | 108/1161 [01:20<12:56,  1.36it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 2:   9%|▉         | 109/1161 [01:20<12:53,  1.36it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 2:   9%|▉         | 109/1161 [01:21<12:53,  1.36it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 2:   9%|▉         | 110/1161 [01:21<12:56,  1.35it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 2:   9%|▉         | 110/1161 [01:21<12:56,  1.35it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 2:  10%|▉         | 111/1161 [01:21<12:53,  1.36it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 2:  10%|▉         | 111/1161 [01:22<12:53,  1.36it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  10%|▉         | 112/1161 [01:22<12:52,  1.36it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  10%|▉         | 112/1161 [01:23<12:52,  1.36it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  10%|▉         | 113/1161 [01:23<12:52,  1.36it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  10%|▉         | 113/1161 [01:23<12:52,  1.36it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  10%|▉         | 114/1161 [01:23<12:51,  1.36it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  10%|▉         | 114/1161 [01:24<12:51,  1.36it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  10%|▉         | 115/1161 [01:24<12:48,  1.36it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  10%|▉         | 115/1161 [01:25<12:48,  1.36it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  10%|▉         | 116/1161 [01:25<12:49,  1.36it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  10%|▉         | 116/1161 [01:26<12:49,  1.36it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  10%|█         | 117/1161 [01:26<12:48,  1.36it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  10%|█         | 117/1161 [01:26<12:48,  1.36it/s, training_loss=0.382]\u001b[A\n",
            "Epoch 2:  10%|█         | 118/1161 [01:26<12:47,  1.36it/s, training_loss=0.382]\u001b[A\n",
            "Epoch 2:  10%|█         | 118/1161 [01:27<12:47,  1.36it/s, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  10%|█         | 119/1161 [01:27<12:48,  1.36it/s, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  10%|█         | 119/1161 [01:28<12:48,  1.36it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  10%|█         | 120/1161 [01:28<12:45,  1.36it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  10%|█         | 120/1161 [01:29<12:45,  1.36it/s, training_loss=0.027]\u001b[A\n",
            "Epoch 2:  10%|█         | 121/1161 [01:29<12:45,  1.36it/s, training_loss=0.027]\u001b[A\n",
            "Epoch 2:  10%|█         | 121/1161 [01:29<12:45,  1.36it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  11%|█         | 122/1161 [01:29<12:43,  1.36it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  11%|█         | 122/1161 [01:30<12:43,  1.36it/s, training_loss=0.347]\u001b[A\n",
            "Epoch 2:  11%|█         | 123/1161 [01:30<12:40,  1.36it/s, training_loss=0.347]\u001b[A\n",
            "Epoch 2:  11%|█         | 123/1161 [01:31<12:40,  1.36it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  11%|█         | 124/1161 [01:31<12:39,  1.37it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  11%|█         | 124/1161 [01:32<12:39,  1.37it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  11%|█         | 125/1161 [01:32<12:40,  1.36it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  11%|█         | 125/1161 [01:32<12:40,  1.36it/s, training_loss=0.313]\u001b[A\n",
            "Epoch 2:  11%|█         | 126/1161 [01:32<12:39,  1.36it/s, training_loss=0.313]\u001b[A\n",
            "Epoch 2:  11%|█         | 126/1161 [01:33<12:39,  1.36it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  11%|█         | 127/1161 [01:33<12:36,  1.37it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  11%|█         | 127/1161 [01:34<12:36,  1.37it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  11%|█         | 128/1161 [01:34<12:38,  1.36it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  11%|█         | 128/1161 [01:34<12:38,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  11%|█         | 129/1161 [01:35<12:36,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  11%|█         | 129/1161 [01:35<12:36,  1.36it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  11%|█         | 130/1161 [01:35<12:38,  1.36it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  11%|█         | 130/1161 [01:36<12:38,  1.36it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 131/1161 [01:36<12:36,  1.36it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 131/1161 [01:37<12:36,  1.36it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 132/1161 [01:37<12:36,  1.36it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 132/1161 [01:37<12:36,  1.36it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 133/1161 [01:37<12:33,  1.37it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 133/1161 [01:38<12:33,  1.37it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 134/1161 [01:38<12:31,  1.37it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 134/1161 [01:39<12:31,  1.37it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 135/1161 [01:39<12:31,  1.37it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 135/1161 [01:40<12:31,  1.37it/s, training_loss=0.267]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 136/1161 [01:40<12:31,  1.36it/s, training_loss=0.267]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 136/1161 [01:40<12:31,  1.36it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 137/1161 [01:40<12:30,  1.36it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 137/1161 [01:41<12:30,  1.36it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 138/1161 [01:41<12:31,  1.36it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 138/1161 [01:42<12:31,  1.36it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 139/1161 [01:42<12:31,  1.36it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 139/1161 [01:43<12:31,  1.36it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 140/1161 [01:43<12:31,  1.36it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 140/1161 [01:43<12:31,  1.36it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 141/1161 [01:43<12:29,  1.36it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 141/1161 [01:44<12:29,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 142/1161 [01:44<12:27,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 142/1161 [01:45<12:27,  1.36it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 143/1161 [01:45<12:27,  1.36it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 143/1161 [01:46<12:27,  1.36it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 144/1161 [01:46<12:25,  1.36it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 144/1161 [01:46<12:25,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 145/1161 [01:46<12:24,  1.37it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 145/1161 [01:47<12:24,  1.37it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 146/1161 [01:47<12:25,  1.36it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 146/1161 [01:48<12:25,  1.36it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 147/1161 [01:48<12:24,  1.36it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 147/1161 [01:48<12:24,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 148/1161 [01:48<12:24,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 148/1161 [01:49<12:24,  1.36it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 149/1161 [01:49<12:22,  1.36it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 149/1161 [01:50<12:22,  1.36it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 150/1161 [01:50<12:20,  1.37it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 150/1161 [01:51<12:20,  1.37it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 151/1161 [01:51<12:21,  1.36it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 151/1161 [01:51<12:21,  1.36it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 152/1161 [01:51<12:20,  1.36it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 152/1161 [01:52<12:20,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 153/1161 [01:52<12:22,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 153/1161 [01:53<12:22,  1.36it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 154/1161 [01:53<12:25,  1.35it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 154/1161 [01:54<12:25,  1.35it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 155/1161 [01:54<12:21,  1.36it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 155/1161 [01:54<12:21,  1.36it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 156/1161 [01:54<12:21,  1.36it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 156/1161 [01:55<12:21,  1.36it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 157/1161 [01:55<12:19,  1.36it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 157/1161 [01:56<12:19,  1.36it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 158/1161 [01:56<12:17,  1.36it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 158/1161 [01:57<12:17,  1.36it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 159/1161 [01:57<12:19,  1.35it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 159/1161 [01:57<12:19,  1.35it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 160/1161 [01:57<12:16,  1.36it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 160/1161 [01:58<12:16,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 161/1161 [01:58<12:14,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 161/1161 [01:59<12:14,  1.36it/s, training_loss=0.325]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 162/1161 [01:59<12:16,  1.36it/s, training_loss=0.325]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 162/1161 [01:59<12:16,  1.36it/s, training_loss=0.289]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 163/1161 [02:00<12:14,  1.36it/s, training_loss=0.289]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 163/1161 [02:00<12:14,  1.36it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 164/1161 [02:00<12:16,  1.35it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 164/1161 [02:01<12:16,  1.35it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 165/1161 [02:01<12:14,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 165/1161 [02:02<12:14,  1.36it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 166/1161 [02:02<12:16,  1.35it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 166/1161 [02:02<12:16,  1.35it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 167/1161 [02:02<12:12,  1.36it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 167/1161 [02:03<12:12,  1.36it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 168/1161 [02:03<12:10,  1.36it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 168/1161 [02:04<12:10,  1.36it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 169/1161 [02:04<12:07,  1.36it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 169/1161 [02:05<12:07,  1.36it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 170/1161 [02:05<12:05,  1.37it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 170/1161 [02:05<12:05,  1.37it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 171/1161 [02:05<12:03,  1.37it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 171/1161 [02:06<12:03,  1.37it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 172/1161 [02:06<12:06,  1.36it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 172/1161 [02:07<12:06,  1.36it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 173/1161 [02:07<12:06,  1.36it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 173/1161 [02:08<12:06,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 174/1161 [02:08<12:06,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 174/1161 [02:08<12:06,  1.36it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 175/1161 [02:08<12:06,  1.36it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 175/1161 [02:09<12:06,  1.36it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 176/1161 [02:09<12:06,  1.36it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 176/1161 [02:10<12:06,  1.36it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 177/1161 [02:10<12:03,  1.36it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 177/1161 [02:11<12:03,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 178/1161 [02:11<12:00,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 178/1161 [02:11<12:00,  1.36it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 179/1161 [02:11<11:59,  1.36it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 179/1161 [02:12<11:59,  1.36it/s, training_loss=0.288]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 180/1161 [02:12<11:59,  1.36it/s, training_loss=0.288]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 180/1161 [02:13<11:59,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 181/1161 [02:13<12:00,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 181/1161 [02:13<12:00,  1.36it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 182/1161 [02:13<11:58,  1.36it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 182/1161 [02:14<11:58,  1.36it/s, training_loss=0.307]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 183/1161 [02:14<12:02,  1.35it/s, training_loss=0.307]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 183/1161 [02:15<12:02,  1.35it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 184/1161 [02:15<11:59,  1.36it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 184/1161 [02:16<11:59,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 185/1161 [02:16<11:59,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 185/1161 [02:16<11:59,  1.36it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 186/1161 [02:16<11:58,  1.36it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 186/1161 [02:17<11:58,  1.36it/s, training_loss=0.377]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 187/1161 [02:17<11:58,  1.36it/s, training_loss=0.377]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 187/1161 [02:18<11:58,  1.36it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 188/1161 [02:18<11:55,  1.36it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 188/1161 [02:19<11:55,  1.36it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 189/1161 [02:19<11:56,  1.36it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 189/1161 [02:19<11:56,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 190/1161 [02:19<11:53,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 190/1161 [02:20<11:53,  1.36it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 191/1161 [02:20<11:52,  1.36it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 191/1161 [02:21<11:52,  1.36it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 192/1161 [02:21<11:50,  1.36it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 192/1161 [02:22<11:50,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 193/1161 [02:22<11:56,  1.35it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 193/1161 [02:22<11:56,  1.35it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 194/1161 [02:22<11:52,  1.36it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 194/1161 [02:23<11:52,  1.36it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 195/1161 [02:23<11:50,  1.36it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 195/1161 [02:24<11:50,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 196/1161 [02:24<11:48,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 196/1161 [02:25<11:48,  1.36it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 197/1161 [02:25<11:47,  1.36it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 197/1161 [02:25<11:47,  1.36it/s, training_loss=0.339]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 198/1161 [02:25<11:45,  1.36it/s, training_loss=0.339]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 198/1161 [02:26<11:45,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 199/1161 [02:26<11:46,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 199/1161 [02:27<11:46,  1.36it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 200/1161 [02:27<11:45,  1.36it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 200/1161 [02:27<11:45,  1.36it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 201/1161 [02:27<11:45,  1.36it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 201/1161 [02:28<11:45,  1.36it/s, training_loss=0.381]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 202/1161 [02:28<11:43,  1.36it/s, training_loss=0.381]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 202/1161 [02:29<11:43,  1.36it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 203/1161 [02:29<11:42,  1.36it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 203/1161 [02:30<11:42,  1.36it/s, training_loss=0.326]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 204/1161 [02:30<11:41,  1.36it/s, training_loss=0.326]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 204/1161 [02:30<11:41,  1.36it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 205/1161 [02:30<11:39,  1.37it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 205/1161 [02:31<11:39,  1.37it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 206/1161 [02:31<11:40,  1.36it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 206/1161 [02:32<11:40,  1.36it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 207/1161 [02:32<11:39,  1.36it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 207/1161 [02:33<11:39,  1.36it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 208/1161 [02:33<11:38,  1.36it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 208/1161 [02:33<11:38,  1.36it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 209/1161 [02:33<11:35,  1.37it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 209/1161 [02:34<11:35,  1.37it/s, training_loss=0.271]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 210/1161 [02:34<11:36,  1.36it/s, training_loss=0.271]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 210/1161 [02:35<11:36,  1.36it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 211/1161 [02:35<11:35,  1.37it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 211/1161 [02:36<11:35,  1.37it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 212/1161 [02:36<11:42,  1.35it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 212/1161 [02:36<11:42,  1.35it/s, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 213/1161 [02:36<11:38,  1.36it/s, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 213/1161 [02:37<11:38,  1.36it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 214/1161 [02:37<11:40,  1.35it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 214/1161 [02:38<11:40,  1.35it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 215/1161 [02:38<11:38,  1.36it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 215/1161 [02:38<11:38,  1.36it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 216/1161 [02:38<11:40,  1.35it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 216/1161 [02:39<11:40,  1.35it/s, training_loss=0.245]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 217/1161 [02:39<11:39,  1.35it/s, training_loss=0.245]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 217/1161 [02:40<11:39,  1.35it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 218/1161 [02:40<11:38,  1.35it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 218/1161 [02:41<11:38,  1.35it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 219/1161 [02:41<11:39,  1.35it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 219/1161 [02:41<11:39,  1.35it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 220/1161 [02:41<11:34,  1.35it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 220/1161 [02:42<11:34,  1.35it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 221/1161 [02:42<11:33,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 221/1161 [02:43<11:33,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 222/1161 [02:43<11:29,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 222/1161 [02:44<11:29,  1.36it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 223/1161 [02:44<11:27,  1.36it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 223/1161 [02:44<11:27,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 224/1161 [02:44<11:28,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 224/1161 [02:45<11:28,  1.36it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 225/1161 [02:45<11:28,  1.36it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 225/1161 [02:46<11:28,  1.36it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 226/1161 [02:46<11:26,  1.36it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 226/1161 [02:47<11:26,  1.36it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 227/1161 [02:47<11:27,  1.36it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 227/1161 [02:47<11:27,  1.36it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 228/1161 [02:47<11:26,  1.36it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 228/1161 [02:48<11:26,  1.36it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 229/1161 [02:48<11:25,  1.36it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 229/1161 [02:49<11:25,  1.36it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 230/1161 [02:49<11:24,  1.36it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 230/1161 [02:50<11:24,  1.36it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 231/1161 [02:50<11:22,  1.36it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 231/1161 [02:50<11:22,  1.36it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 232/1161 [02:50<11:21,  1.36it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 232/1161 [02:51<11:21,  1.36it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  20%|██        | 233/1161 [02:51<11:21,  1.36it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  20%|██        | 233/1161 [02:52<11:21,  1.36it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  20%|██        | 234/1161 [02:52<11:18,  1.37it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  20%|██        | 234/1161 [02:52<11:18,  1.37it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  20%|██        | 235/1161 [02:52<11:16,  1.37it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  20%|██        | 235/1161 [02:53<11:16,  1.37it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  20%|██        | 236/1161 [02:53<11:16,  1.37it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  20%|██        | 236/1161 [02:54<11:16,  1.37it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  20%|██        | 237/1161 [02:54<11:15,  1.37it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  20%|██        | 237/1161 [02:55<11:15,  1.37it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  20%|██        | 238/1161 [02:55<11:18,  1.36it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  20%|██        | 238/1161 [02:55<11:18,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  21%|██        | 239/1161 [02:55<11:19,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  21%|██        | 239/1161 [02:56<11:19,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  21%|██        | 240/1161 [02:56<11:17,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  21%|██        | 240/1161 [02:57<11:17,  1.36it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  21%|██        | 241/1161 [02:57<11:19,  1.35it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  21%|██        | 241/1161 [02:58<11:19,  1.35it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 2:  21%|██        | 242/1161 [02:58<11:15,  1.36it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 2:  21%|██        | 242/1161 [02:58<11:15,  1.36it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  21%|██        | 243/1161 [02:58<11:13,  1.36it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  21%|██        | 243/1161 [02:59<11:13,  1.36it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  21%|██        | 244/1161 [02:59<11:12,  1.36it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  21%|██        | 244/1161 [03:00<11:12,  1.36it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  21%|██        | 245/1161 [03:00<11:12,  1.36it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  21%|██        | 245/1161 [03:01<11:12,  1.36it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  21%|██        | 246/1161 [03:01<11:12,  1.36it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  21%|██        | 246/1161 [03:01<11:12,  1.36it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 247/1161 [03:01<11:12,  1.36it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 247/1161 [03:02<11:12,  1.36it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 248/1161 [03:02<11:11,  1.36it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 248/1161 [03:03<11:11,  1.36it/s, training_loss=0.333]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 249/1161 [03:03<11:10,  1.36it/s, training_loss=0.333]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 249/1161 [03:03<11:10,  1.36it/s, training_loss=0.322]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 250/1161 [03:03<11:11,  1.36it/s, training_loss=0.322]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 250/1161 [03:04<11:11,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 251/1161 [03:04<11:11,  1.35it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 251/1161 [03:05<11:11,  1.35it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 252/1161 [03:05<11:09,  1.36it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 252/1161 [03:06<11:09,  1.36it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 253/1161 [03:06<11:06,  1.36it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 253/1161 [03:06<11:06,  1.36it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 254/1161 [03:06<11:05,  1.36it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 254/1161 [03:07<11:05,  1.36it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 255/1161 [03:07<11:04,  1.36it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 255/1161 [03:08<11:04,  1.36it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 256/1161 [03:08<11:03,  1.36it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 256/1161 [03:09<11:03,  1.36it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 257/1161 [03:09<11:06,  1.36it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 257/1161 [03:09<11:06,  1.36it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 258/1161 [03:09<11:04,  1.36it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 258/1161 [03:10<11:04,  1.36it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 259/1161 [03:10<11:06,  1.35it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 259/1161 [03:11<11:06,  1.35it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 260/1161 [03:11<11:04,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 260/1161 [03:12<11:04,  1.36it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 261/1161 [03:12<11:00,  1.36it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 261/1161 [03:12<11:00,  1.36it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 262/1161 [03:12<10:59,  1.36it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 262/1161 [03:13<10:59,  1.36it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 263/1161 [03:13<11:00,  1.36it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 263/1161 [03:14<11:00,  1.36it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 264/1161 [03:14<10:56,  1.37it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 264/1161 [03:14<10:56,  1.37it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 265/1161 [03:14<10:54,  1.37it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 265/1161 [03:15<10:54,  1.37it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 266/1161 [03:15<10:54,  1.37it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 266/1161 [03:16<10:54,  1.37it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 267/1161 [03:16<10:54,  1.37it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 267/1161 [03:17<10:54,  1.37it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 268/1161 [03:17<10:55,  1.36it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 268/1161 [03:17<10:55,  1.36it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 269/1161 [03:17<10:54,  1.36it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 269/1161 [03:18<10:54,  1.36it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 270/1161 [03:18<10:57,  1.35it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 270/1161 [03:19<10:57,  1.35it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 271/1161 [03:19<10:57,  1.35it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 271/1161 [03:20<10:57,  1.35it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 272/1161 [03:20<10:54,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 272/1161 [03:20<10:54,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 273/1161 [03:20<10:50,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 273/1161 [03:21<10:50,  1.36it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 274/1161 [03:21<10:53,  1.36it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 274/1161 [03:22<10:53,  1.36it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 275/1161 [03:22<10:52,  1.36it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 275/1161 [03:23<10:52,  1.36it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 276/1161 [03:23<10:52,  1.36it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 276/1161 [03:23<10:52,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 277/1161 [03:23<10:48,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 277/1161 [03:24<10:48,  1.36it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 278/1161 [03:24<10:47,  1.36it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 278/1161 [03:25<10:47,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 279/1161 [03:25<10:45,  1.37it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 279/1161 [03:26<10:45,  1.37it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 280/1161 [03:26<10:49,  1.36it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 280/1161 [03:26<10:49,  1.36it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 281/1161 [03:26<10:45,  1.36it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 281/1161 [03:27<10:45,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 282/1161 [03:27<10:48,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 282/1161 [03:28<10:48,  1.36it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 283/1161 [03:28<10:48,  1.35it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 283/1161 [03:28<10:48,  1.35it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 284/1161 [03:28<10:48,  1.35it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 284/1161 [03:29<10:48,  1.35it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 285/1161 [03:29<10:46,  1.35it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 285/1161 [03:30<10:46,  1.35it/s, training_loss=0.355]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 286/1161 [03:30<10:43,  1.36it/s, training_loss=0.355]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 286/1161 [03:31<10:43,  1.36it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 287/1161 [03:31<10:42,  1.36it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 287/1161 [03:31<10:42,  1.36it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 288/1161 [03:31<10:41,  1.36it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 288/1161 [03:32<10:41,  1.36it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 289/1161 [03:32<10:41,  1.36it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 289/1161 [03:33<10:41,  1.36it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 290/1161 [03:33<10:40,  1.36it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 290/1161 [03:34<10:40,  1.36it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 291/1161 [03:34<10:39,  1.36it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 291/1161 [03:34<10:39,  1.36it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 292/1161 [03:34<10:37,  1.36it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 292/1161 [03:35<10:37,  1.36it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 293/1161 [03:35<10:37,  1.36it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 293/1161 [03:36<10:37,  1.36it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 294/1161 [03:36<10:35,  1.36it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 294/1161 [03:37<10:35,  1.36it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 295/1161 [03:37<10:32,  1.37it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 295/1161 [03:37<10:32,  1.37it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 296/1161 [03:37<10:32,  1.37it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 296/1161 [03:38<10:32,  1.37it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 297/1161 [03:38<10:32,  1.37it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 297/1161 [03:39<10:32,  1.37it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 298/1161 [03:39<10:31,  1.37it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 298/1161 [03:39<10:31,  1.37it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 299/1161 [03:39<10:31,  1.36it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 299/1161 [03:40<10:31,  1.36it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 300/1161 [03:40<10:29,  1.37it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 300/1161 [03:41<10:29,  1.37it/s, training_loss=0.225]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 301/1161 [03:41<10:29,  1.37it/s, training_loss=0.225]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 301/1161 [03:42<10:29,  1.37it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 302/1161 [03:42<10:28,  1.37it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 302/1161 [03:42<10:28,  1.37it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 303/1161 [03:42<10:28,  1.36it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 303/1161 [03:43<10:28,  1.36it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 304/1161 [03:43<10:29,  1.36it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 304/1161 [03:44<10:29,  1.36it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 305/1161 [03:44<10:28,  1.36it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 305/1161 [03:45<10:28,  1.36it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 306/1161 [03:45<10:29,  1.36it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 306/1161 [03:45<10:29,  1.36it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 307/1161 [03:45<10:30,  1.36it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 307/1161 [03:46<10:30,  1.36it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 308/1161 [03:46<10:31,  1.35it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 308/1161 [03:47<10:31,  1.35it/s, training_loss=0.253]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 309/1161 [03:47<10:28,  1.36it/s, training_loss=0.253]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 309/1161 [03:48<10:28,  1.36it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 310/1161 [03:48<10:23,  1.36it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 310/1161 [03:48<10:23,  1.36it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 311/1161 [03:48<10:22,  1.37it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 311/1161 [03:49<10:22,  1.37it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 312/1161 [03:49<10:21,  1.37it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 312/1161 [03:50<10:21,  1.37it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 313/1161 [03:50<10:21,  1.36it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 313/1161 [03:50<10:21,  1.36it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 314/1161 [03:50<10:21,  1.36it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 314/1161 [03:51<10:21,  1.36it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 315/1161 [03:51<10:21,  1.36it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 315/1161 [03:52<10:21,  1.36it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 316/1161 [03:52<10:18,  1.37it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 316/1161 [03:53<10:18,  1.37it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 317/1161 [03:53<10:17,  1.37it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 317/1161 [03:53<10:17,  1.37it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 318/1161 [03:53<10:17,  1.36it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 318/1161 [03:54<10:17,  1.36it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 319/1161 [03:54<10:16,  1.37it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 319/1161 [03:55<10:16,  1.37it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 320/1161 [03:55<10:17,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 320/1161 [03:56<10:17,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 321/1161 [03:56<10:14,  1.37it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 321/1161 [03:56<10:14,  1.37it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 322/1161 [03:56<10:15,  1.36it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 322/1161 [03:57<10:15,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 323/1161 [03:57<10:14,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 323/1161 [03:58<10:14,  1.36it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 324/1161 [03:58<10:13,  1.36it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 324/1161 [03:59<10:13,  1.36it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 325/1161 [03:59<10:16,  1.36it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 325/1161 [03:59<10:16,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 326/1161 [03:59<10:15,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 326/1161 [04:00<10:15,  1.36it/s, training_loss=0.266]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 327/1161 [04:00<10:14,  1.36it/s, training_loss=0.266]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 327/1161 [04:01<10:14,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 328/1161 [04:01<10:13,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 328/1161 [04:01<10:13,  1.36it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 329/1161 [04:02<10:11,  1.36it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 329/1161 [04:02<10:11,  1.36it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 330/1161 [04:02<10:10,  1.36it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 330/1161 [04:03<10:10,  1.36it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 331/1161 [04:03<10:10,  1.36it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 331/1161 [04:04<10:10,  1.36it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 332/1161 [04:04<10:08,  1.36it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 332/1161 [04:04<10:08,  1.36it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 333/1161 [04:04<10:07,  1.36it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 333/1161 [04:05<10:07,  1.36it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 334/1161 [04:05<10:06,  1.36it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 334/1161 [04:06<10:06,  1.36it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 335/1161 [04:06<10:05,  1.36it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 335/1161 [04:07<10:05,  1.36it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 336/1161 [04:07<10:03,  1.37it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 336/1161 [04:07<10:03,  1.37it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 337/1161 [04:07<10:03,  1.36it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 337/1161 [04:08<10:03,  1.36it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 338/1161 [04:08<10:03,  1.36it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 338/1161 [04:09<10:03,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 339/1161 [04:09<10:02,  1.37it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 339/1161 [04:10<10:02,  1.37it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 340/1161 [04:10<10:02,  1.36it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 340/1161 [04:10<10:02,  1.36it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 341/1161 [04:10<10:00,  1.37it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 341/1161 [04:11<10:00,  1.37it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 342/1161 [04:11<09:59,  1.37it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 342/1161 [04:12<09:59,  1.37it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 343/1161 [04:12<09:57,  1.37it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 343/1161 [04:12<09:57,  1.37it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 344/1161 [04:12<09:57,  1.37it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 344/1161 [04:13<09:57,  1.37it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 345/1161 [04:13<09:56,  1.37it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 345/1161 [04:14<09:56,  1.37it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 346/1161 [04:14<09:54,  1.37it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 346/1161 [04:15<09:54,  1.37it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 347/1161 [04:15<09:55,  1.37it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 347/1161 [04:15<09:55,  1.37it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 348/1161 [04:15<09:54,  1.37it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 348/1161 [04:16<09:54,  1.37it/s, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  30%|███       | 349/1161 [04:16<09:53,  1.37it/s, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  30%|███       | 349/1161 [04:17<09:53,  1.37it/s, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  30%|███       | 350/1161 [04:17<09:54,  1.36it/s, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  30%|███       | 350/1161 [04:18<09:54,  1.36it/s, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  30%|███       | 351/1161 [04:18<09:53,  1.37it/s, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  30%|███       | 351/1161 [04:18<09:53,  1.37it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  30%|███       | 352/1161 [04:18<09:52,  1.37it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  30%|███       | 352/1161 [04:19<09:52,  1.37it/s, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  30%|███       | 353/1161 [04:19<09:51,  1.37it/s, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  30%|███       | 353/1161 [04:20<09:51,  1.37it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  30%|███       | 354/1161 [04:20<09:52,  1.36it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  30%|███       | 354/1161 [04:21<09:52,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  31%|███       | 355/1161 [04:21<09:50,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  31%|███       | 355/1161 [04:21<09:50,  1.36it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  31%|███       | 356/1161 [04:21<09:50,  1.36it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  31%|███       | 356/1161 [04:22<09:50,  1.36it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  31%|███       | 357/1161 [04:22<09:48,  1.37it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  31%|███       | 357/1161 [04:23<09:48,  1.37it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  31%|███       | 358/1161 [04:23<09:46,  1.37it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  31%|███       | 358/1161 [04:23<09:46,  1.37it/s, training_loss=0.278]\u001b[A\n",
            "Epoch 2:  31%|███       | 359/1161 [04:23<09:46,  1.37it/s, training_loss=0.278]\u001b[A\n",
            "Epoch 2:  31%|███       | 359/1161 [04:24<09:46,  1.37it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  31%|███       | 360/1161 [04:24<09:44,  1.37it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  31%|███       | 360/1161 [04:25<09:44,  1.37it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  31%|███       | 361/1161 [04:25<09:47,  1.36it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  31%|███       | 361/1161 [04:26<09:47,  1.36it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  31%|███       | 362/1161 [04:26<09:46,  1.36it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  31%|███       | 362/1161 [04:26<09:46,  1.36it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 363/1161 [04:26<09:45,  1.36it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 363/1161 [04:27<09:45,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 364/1161 [04:27<09:42,  1.37it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 364/1161 [04:28<09:42,  1.37it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 365/1161 [04:28<09:42,  1.37it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 365/1161 [04:29<09:42,  1.37it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 366/1161 [04:29<09:40,  1.37it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 366/1161 [04:29<09:40,  1.37it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 367/1161 [04:29<09:40,  1.37it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 367/1161 [04:30<09:40,  1.37it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 368/1161 [04:30<09:40,  1.37it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 368/1161 [04:31<09:40,  1.37it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 369/1161 [04:31<09:38,  1.37it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 369/1161 [04:32<09:38,  1.37it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 370/1161 [04:32<09:39,  1.37it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 370/1161 [04:32<09:39,  1.37it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 371/1161 [04:32<09:39,  1.36it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 371/1161 [04:33<09:39,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 372/1161 [04:33<09:39,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 372/1161 [04:34<09:39,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 373/1161 [04:34<09:39,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 373/1161 [04:34<09:39,  1.36it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 374/1161 [04:34<09:37,  1.36it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 374/1161 [04:35<09:37,  1.36it/s, training_loss=0.303]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 375/1161 [04:35<09:35,  1.37it/s, training_loss=0.303]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 375/1161 [04:36<09:35,  1.37it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 376/1161 [04:36<09:35,  1.36it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 376/1161 [04:37<09:35,  1.36it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 377/1161 [04:37<09:34,  1.36it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 377/1161 [04:37<09:34,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 378/1161 [04:37<09:34,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 378/1161 [04:38<09:34,  1.36it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 379/1161 [04:38<09:33,  1.36it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 379/1161 [04:39<09:33,  1.36it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 380/1161 [04:39<09:32,  1.36it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 380/1161 [04:40<09:32,  1.36it/s, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 381/1161 [04:40<09:32,  1.36it/s, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 381/1161 [04:40<09:32,  1.36it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 382/1161 [04:40<09:32,  1.36it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 382/1161 [04:41<09:32,  1.36it/s, training_loss=0.354]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 383/1161 [04:41<09:32,  1.36it/s, training_loss=0.354]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 383/1161 [04:42<09:32,  1.36it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 384/1161 [04:42<09:30,  1.36it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 384/1161 [04:43<09:30,  1.36it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 385/1161 [04:43<09:30,  1.36it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 385/1161 [04:43<09:30,  1.36it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 386/1161 [04:43<09:29,  1.36it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 386/1161 [04:44<09:29,  1.36it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 387/1161 [04:44<09:28,  1.36it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 387/1161 [04:45<09:28,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 388/1161 [04:45<09:28,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 388/1161 [04:45<09:28,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 389/1161 [04:45<09:27,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 389/1161 [04:46<09:27,  1.36it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 390/1161 [04:46<09:26,  1.36it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 390/1161 [04:47<09:26,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 391/1161 [04:47<09:25,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 391/1161 [04:48<09:25,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 392/1161 [04:48<09:23,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 392/1161 [04:48<09:23,  1.36it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 393/1161 [04:48<09:25,  1.36it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 393/1161 [04:49<09:25,  1.36it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 394/1161 [04:49<09:24,  1.36it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 394/1161 [04:50<09:24,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 395/1161 [04:50<09:23,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 395/1161 [04:51<09:23,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 396/1161 [04:51<09:21,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 396/1161 [04:51<09:21,  1.36it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 397/1161 [04:51<09:23,  1.36it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 397/1161 [04:52<09:23,  1.36it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 398/1161 [04:52<09:24,  1.35it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 398/1161 [04:53<09:24,  1.35it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 399/1161 [04:53<09:24,  1.35it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 399/1161 [04:54<09:24,  1.35it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 400/1161 [04:54<09:21,  1.36it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 400/1161 [04:54<09:21,  1.36it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 401/1161 [04:54<09:21,  1.35it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 401/1161 [04:55<09:21,  1.35it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 402/1161 [04:55<09:20,  1.35it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 402/1161 [04:56<09:20,  1.35it/s, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 403/1161 [04:56<09:20,  1.35it/s, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 403/1161 [04:57<09:20,  1.35it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 404/1161 [04:57<09:21,  1.35it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 404/1161 [04:57<09:21,  1.35it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 405/1161 [04:57<09:19,  1.35it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 405/1161 [04:58<09:19,  1.35it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 406/1161 [04:58<09:16,  1.36it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 406/1161 [04:59<09:16,  1.36it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 407/1161 [04:59<09:15,  1.36it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 407/1161 [04:59<09:15,  1.36it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 408/1161 [04:59<09:14,  1.36it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 408/1161 [05:00<09:14,  1.36it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 409/1161 [05:00<09:11,  1.36it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 409/1161 [05:01<09:11,  1.36it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 410/1161 [05:01<09:11,  1.36it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 410/1161 [05:02<09:11,  1.36it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 411/1161 [05:02<09:10,  1.36it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 411/1161 [05:02<09:10,  1.36it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 412/1161 [05:02<09:11,  1.36it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 412/1161 [05:03<09:11,  1.36it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 413/1161 [05:03<09:11,  1.36it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 413/1161 [05:04<09:11,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 414/1161 [05:04<09:10,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 414/1161 [05:05<09:10,  1.36it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 415/1161 [05:05<09:11,  1.35it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 415/1161 [05:05<09:11,  1.35it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 416/1161 [05:05<09:11,  1.35it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 416/1161 [05:06<09:11,  1.35it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 417/1161 [05:06<09:11,  1.35it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 417/1161 [05:07<09:11,  1.35it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 418/1161 [05:07<09:10,  1.35it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 418/1161 [05:08<09:10,  1.35it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 419/1161 [05:08<09:07,  1.36it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 419/1161 [05:08<09:07,  1.36it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 420/1161 [05:08<09:04,  1.36it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 420/1161 [05:09<09:04,  1.36it/s, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 421/1161 [05:09<09:02,  1.36it/s, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 421/1161 [05:10<09:02,  1.36it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 422/1161 [05:10<09:00,  1.37it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 422/1161 [05:11<09:00,  1.37it/s, training_loss=0.315]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 423/1161 [05:11<08:59,  1.37it/s, training_loss=0.315]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 423/1161 [05:11<08:59,  1.37it/s, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 424/1161 [05:11<08:58,  1.37it/s, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 424/1161 [05:12<08:58,  1.37it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 425/1161 [05:12<08:58,  1.37it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 425/1161 [05:13<08:58,  1.37it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 426/1161 [05:13<09:00,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 426/1161 [05:13<09:00,  1.36it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 427/1161 [05:13<08:59,  1.36it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 427/1161 [05:14<08:59,  1.36it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 428/1161 [05:14<08:59,  1.36it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 428/1161 [05:15<08:59,  1.36it/s, training_loss=0.393]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 429/1161 [05:15<08:57,  1.36it/s, training_loss=0.393]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 429/1161 [05:16<08:57,  1.36it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 430/1161 [05:16<08:57,  1.36it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 430/1161 [05:16<08:57,  1.36it/s, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 431/1161 [05:16<08:59,  1.35it/s, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 431/1161 [05:17<08:59,  1.35it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 432/1161 [05:17<08:58,  1.35it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 432/1161 [05:18<08:58,  1.35it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 433/1161 [05:18<08:56,  1.36it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 433/1161 [05:19<08:56,  1.36it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 434/1161 [05:19<08:54,  1.36it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 434/1161 [05:19<08:54,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 435/1161 [05:19<08:54,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 435/1161 [05:20<08:54,  1.36it/s, training_loss=0.335]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 436/1161 [05:20<08:53,  1.36it/s, training_loss=0.335]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 436/1161 [05:21<08:53,  1.36it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 437/1161 [05:21<08:53,  1.36it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 437/1161 [05:22<08:53,  1.36it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 438/1161 [05:22<08:53,  1.35it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 438/1161 [05:22<08:53,  1.35it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 439/1161 [05:22<08:53,  1.35it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 439/1161 [05:23<08:53,  1.35it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 440/1161 [05:23<08:52,  1.35it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 440/1161 [05:24<08:52,  1.35it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 441/1161 [05:24<08:51,  1.36it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 441/1161 [05:24<08:51,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 442/1161 [05:25<08:49,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 442/1161 [05:25<08:49,  1.36it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 443/1161 [05:25<08:47,  1.36it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 443/1161 [05:26<08:47,  1.36it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 444/1161 [05:26<08:47,  1.36it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 444/1161 [05:27<08:47,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 445/1161 [05:27<08:47,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 445/1161 [05:27<08:47,  1.36it/s, training_loss=0.331]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 446/1161 [05:27<08:45,  1.36it/s, training_loss=0.331]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 446/1161 [05:28<08:45,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 447/1161 [05:28<08:44,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 447/1161 [05:29<08:44,  1.36it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 448/1161 [05:29<08:42,  1.36it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 448/1161 [05:30<08:42,  1.36it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 449/1161 [05:30<08:42,  1.36it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 449/1161 [05:30<08:42,  1.36it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 450/1161 [05:30<08:42,  1.36it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 450/1161 [05:31<08:42,  1.36it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 451/1161 [05:31<08:42,  1.36it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 451/1161 [05:32<08:42,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 452/1161 [05:32<08:40,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 452/1161 [05:33<08:40,  1.36it/s, training_loss=0.275]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 453/1161 [05:33<08:40,  1.36it/s, training_loss=0.275]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 453/1161 [05:33<08:40,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 454/1161 [05:33<08:41,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 454/1161 [05:34<08:41,  1.36it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 455/1161 [05:34<08:39,  1.36it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 455/1161 [05:35<08:39,  1.36it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 456/1161 [05:35<08:37,  1.36it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 456/1161 [05:36<08:37,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 457/1161 [05:36<08:37,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 457/1161 [05:36<08:37,  1.36it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 458/1161 [05:36<08:34,  1.37it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 458/1161 [05:37<08:34,  1.37it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 459/1161 [05:37<08:33,  1.37it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 459/1161 [05:38<08:33,  1.37it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 460/1161 [05:38<08:32,  1.37it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 460/1161 [05:38<08:32,  1.37it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 461/1161 [05:38<08:31,  1.37it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 461/1161 [05:39<08:31,  1.37it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 462/1161 [05:39<08:30,  1.37it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 462/1161 [05:40<08:30,  1.37it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 463/1161 [05:40<08:29,  1.37it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 463/1161 [05:41<08:29,  1.37it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 464/1161 [05:41<08:30,  1.36it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 464/1161 [05:41<08:30,  1.36it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  40%|████      | 465/1161 [05:41<08:29,  1.37it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  40%|████      | 465/1161 [05:42<08:29,  1.37it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  40%|████      | 466/1161 [05:42<08:29,  1.36it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  40%|████      | 466/1161 [05:43<08:29,  1.36it/s, training_loss=0.393]\u001b[A\n",
            "Epoch 2:  40%|████      | 467/1161 [05:43<08:30,  1.36it/s, training_loss=0.393]\u001b[A\n",
            "Epoch 2:  40%|████      | 467/1161 [05:44<08:30,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  40%|████      | 468/1161 [05:44<08:30,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  40%|████      | 468/1161 [05:44<08:30,  1.36it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  40%|████      | 469/1161 [05:44<08:30,  1.35it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  40%|████      | 469/1161 [05:45<08:30,  1.35it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  40%|████      | 470/1161 [05:45<08:31,  1.35it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  40%|████      | 470/1161 [05:46<08:31,  1.35it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  41%|████      | 471/1161 [05:46<08:29,  1.35it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  41%|████      | 471/1161 [05:47<08:29,  1.35it/s, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  41%|████      | 472/1161 [05:47<08:28,  1.36it/s, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  41%|████      | 472/1161 [05:47<08:28,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  41%|████      | 473/1161 [05:47<08:26,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  41%|████      | 473/1161 [05:48<08:26,  1.36it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  41%|████      | 474/1161 [05:48<08:25,  1.36it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  41%|████      | 474/1161 [05:49<08:25,  1.36it/s, training_loss=0.268]\u001b[A\n",
            "Epoch 2:  41%|████      | 475/1161 [05:49<08:25,  1.36it/s, training_loss=0.268]\u001b[A\n",
            "Epoch 2:  41%|████      | 475/1161 [05:49<08:25,  1.36it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  41%|████      | 476/1161 [05:49<08:22,  1.36it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  41%|████      | 476/1161 [05:50<08:22,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  41%|████      | 477/1161 [05:50<08:22,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  41%|████      | 477/1161 [05:51<08:22,  1.36it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  41%|████      | 478/1161 [05:51<08:21,  1.36it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  41%|████      | 478/1161 [05:52<08:21,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 479/1161 [05:52<08:20,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 479/1161 [05:52<08:20,  1.36it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 480/1161 [05:52<08:22,  1.36it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 480/1161 [05:53<08:22,  1.36it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 481/1161 [05:53<08:20,  1.36it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 481/1161 [05:54<08:20,  1.36it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 482/1161 [05:54<08:18,  1.36it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 482/1161 [05:55<08:18,  1.36it/s, training_loss=0.288]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 483/1161 [05:55<08:18,  1.36it/s, training_loss=0.288]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 483/1161 [05:55<08:18,  1.36it/s, training_loss=0.291]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 484/1161 [05:55<08:18,  1.36it/s, training_loss=0.291]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 484/1161 [05:56<08:18,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 485/1161 [05:56<08:17,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 485/1161 [05:57<08:17,  1.36it/s, training_loss=0.303]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 486/1161 [05:57<08:17,  1.36it/s, training_loss=0.303]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 486/1161 [05:58<08:17,  1.36it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 487/1161 [05:58<08:15,  1.36it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 487/1161 [05:58<08:15,  1.36it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 488/1161 [05:58<08:14,  1.36it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 488/1161 [05:59<08:14,  1.36it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 489/1161 [05:59<08:13,  1.36it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 489/1161 [06:00<08:13,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 490/1161 [06:00<08:13,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 490/1161 [06:01<08:13,  1.36it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 491/1161 [06:01<08:13,  1.36it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 491/1161 [06:01<08:13,  1.36it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 492/1161 [06:01<08:13,  1.35it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 492/1161 [06:02<08:13,  1.35it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 493/1161 [06:02<08:11,  1.36it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 493/1161 [06:03<08:11,  1.36it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 494/1161 [06:03<08:12,  1.35it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 494/1161 [06:03<08:12,  1.35it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 495/1161 [06:03<08:10,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 495/1161 [06:04<08:10,  1.36it/s, training_loss=0.262]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 496/1161 [06:04<08:11,  1.35it/s, training_loss=0.262]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 496/1161 [06:05<08:11,  1.35it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 497/1161 [06:05<08:10,  1.35it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 497/1161 [06:06<08:10,  1.35it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 498/1161 [06:06<08:07,  1.36it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 498/1161 [06:06<08:07,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 499/1161 [06:06<08:09,  1.35it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 499/1161 [06:07<08:09,  1.35it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 500/1161 [06:07<08:07,  1.36it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 500/1161 [06:08<08:07,  1.36it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 501/1161 [06:08<08:06,  1.36it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 501/1161 [06:09<08:06,  1.36it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 502/1161 [06:09<08:05,  1.36it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 502/1161 [06:09<08:05,  1.36it/s, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 503/1161 [06:09<08:03,  1.36it/s, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 503/1161 [06:10<08:03,  1.36it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 504/1161 [06:10<08:03,  1.36it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 504/1161 [06:11<08:03,  1.36it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 505/1161 [06:11<08:04,  1.35it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 505/1161 [06:12<08:04,  1.35it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 506/1161 [06:12<08:02,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 506/1161 [06:12<08:02,  1.36it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 507/1161 [06:12<08:01,  1.36it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 507/1161 [06:13<08:01,  1.36it/s, training_loss=0.276]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 508/1161 [06:13<08:01,  1.36it/s, training_loss=0.276]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 508/1161 [06:14<08:01,  1.36it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 509/1161 [06:14<07:58,  1.36it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 509/1161 [06:15<07:58,  1.36it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 510/1161 [06:15<07:57,  1.36it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 510/1161 [06:15<07:57,  1.36it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 511/1161 [06:15<07:55,  1.37it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 511/1161 [06:16<07:55,  1.37it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 512/1161 [06:16<07:54,  1.37it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 512/1161 [06:17<07:54,  1.37it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 513/1161 [06:17<07:55,  1.36it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 513/1161 [06:17<07:55,  1.36it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 514/1161 [06:17<07:54,  1.36it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 514/1161 [06:18<07:54,  1.36it/s, training_loss=0.042]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 515/1161 [06:18<07:53,  1.36it/s, training_loss=0.042]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 515/1161 [06:19<07:53,  1.36it/s, training_loss=0.445]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 516/1161 [06:19<07:54,  1.36it/s, training_loss=0.445]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 516/1161 [06:20<07:54,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 517/1161 [06:20<07:53,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 517/1161 [06:20<07:53,  1.36it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 518/1161 [06:20<07:53,  1.36it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 518/1161 [06:21<07:53,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 519/1161 [06:21<07:54,  1.35it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 519/1161 [06:22<07:54,  1.35it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 520/1161 [06:22<07:52,  1.36it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 520/1161 [06:23<07:52,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 521/1161 [06:23<07:51,  1.36it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 521/1161 [06:23<07:51,  1.36it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 522/1161 [06:23<07:50,  1.36it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 522/1161 [06:24<07:50,  1.36it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 523/1161 [06:24<07:49,  1.36it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 523/1161 [06:25<07:49,  1.36it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 524/1161 [06:25<07:48,  1.36it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 524/1161 [06:26<07:48,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 525/1161 [06:26<07:46,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 525/1161 [06:26<07:46,  1.36it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 526/1161 [06:26<07:45,  1.37it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 526/1161 [06:27<07:45,  1.37it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 527/1161 [06:27<07:44,  1.36it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 527/1161 [06:28<07:44,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 528/1161 [06:28<07:43,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 528/1161 [06:28<07:43,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 529/1161 [06:28<07:43,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 529/1161 [06:29<07:43,  1.36it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 530/1161 [06:29<07:41,  1.37it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 530/1161 [06:30<07:41,  1.37it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 531/1161 [06:30<07:41,  1.37it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 531/1161 [06:31<07:41,  1.37it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 532/1161 [06:31<07:39,  1.37it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 532/1161 [06:31<07:39,  1.37it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 533/1161 [06:31<07:39,  1.37it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 533/1161 [06:32<07:39,  1.37it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 534/1161 [06:32<07:38,  1.37it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 534/1161 [06:33<07:38,  1.37it/s, training_loss=0.027]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 535/1161 [06:33<07:38,  1.36it/s, training_loss=0.027]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 535/1161 [06:34<07:38,  1.36it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 536/1161 [06:34<07:38,  1.36it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 536/1161 [06:34<07:38,  1.36it/s, training_loss=0.291]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 537/1161 [06:34<07:40,  1.36it/s, training_loss=0.291]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 537/1161 [06:35<07:40,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 538/1161 [06:35<07:37,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 538/1161 [06:36<07:37,  1.36it/s, training_loss=0.324]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 539/1161 [06:36<07:39,  1.35it/s, training_loss=0.324]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 539/1161 [06:37<07:39,  1.35it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 540/1161 [06:37<07:35,  1.36it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 540/1161 [06:37<07:35,  1.36it/s, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 541/1161 [06:37<07:34,  1.37it/s, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 541/1161 [06:38<07:34,  1.37it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 542/1161 [06:38<07:33,  1.37it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 542/1161 [06:39<07:33,  1.37it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 543/1161 [06:39<07:31,  1.37it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 543/1161 [06:39<07:31,  1.37it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 544/1161 [06:39<07:30,  1.37it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 544/1161 [06:40<07:30,  1.37it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 545/1161 [06:40<07:30,  1.37it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 545/1161 [06:41<07:30,  1.37it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 546/1161 [06:41<07:29,  1.37it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 546/1161 [06:42<07:29,  1.37it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 547/1161 [06:42<07:29,  1.36it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 547/1161 [06:42<07:29,  1.36it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 548/1161 [06:42<07:29,  1.36it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 548/1161 [06:43<07:29,  1.36it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 549/1161 [06:43<07:29,  1.36it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 549/1161 [06:44<07:29,  1.36it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 550/1161 [06:44<07:28,  1.36it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 550/1161 [06:45<07:28,  1.36it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 551/1161 [06:45<07:26,  1.37it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 551/1161 [06:45<07:26,  1.37it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 552/1161 [06:45<07:26,  1.37it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 552/1161 [06:46<07:26,  1.37it/s, training_loss=0.266]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 553/1161 [06:46<07:26,  1.36it/s, training_loss=0.266]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 553/1161 [06:47<07:26,  1.36it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 554/1161 [06:47<07:27,  1.36it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 554/1161 [06:48<07:27,  1.36it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 555/1161 [06:48<07:25,  1.36it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 555/1161 [06:48<07:25,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 556/1161 [06:48<07:25,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 556/1161 [06:49<07:25,  1.36it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 557/1161 [06:49<07:23,  1.36it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 557/1161 [06:50<07:23,  1.36it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 558/1161 [06:50<07:23,  1.36it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 558/1161 [06:50<07:23,  1.36it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 559/1161 [06:50<07:22,  1.36it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 559/1161 [06:51<07:22,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 560/1161 [06:51<07:21,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 560/1161 [06:52<07:21,  1.36it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 561/1161 [06:52<07:20,  1.36it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 561/1161 [06:53<07:20,  1.36it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 562/1161 [06:53<07:20,  1.36it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 562/1161 [06:53<07:20,  1.36it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 563/1161 [06:53<07:20,  1.36it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 563/1161 [06:54<07:20,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 564/1161 [06:54<07:19,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 564/1161 [06:55<07:19,  1.36it/s, training_loss=0.375]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 565/1161 [06:55<07:19,  1.36it/s, training_loss=0.375]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 565/1161 [06:56<07:19,  1.36it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 566/1161 [06:56<07:17,  1.36it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 566/1161 [06:56<07:17,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 567/1161 [06:56<07:19,  1.35it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 567/1161 [06:57<07:19,  1.35it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 568/1161 [06:57<07:16,  1.36it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 568/1161 [06:58<07:16,  1.36it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 569/1161 [06:58<07:15,  1.36it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 569/1161 [06:59<07:15,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 570/1161 [06:59<07:13,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 570/1161 [06:59<07:13,  1.36it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 571/1161 [06:59<07:13,  1.36it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 571/1161 [07:00<07:13,  1.36it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 572/1161 [07:00<07:12,  1.36it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 572/1161 [07:01<07:12,  1.36it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 573/1161 [07:01<07:11,  1.36it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 573/1161 [07:01<07:11,  1.36it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 574/1161 [07:02<07:09,  1.37it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 574/1161 [07:02<07:09,  1.37it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 575/1161 [07:02<07:07,  1.37it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 575/1161 [07:03<07:07,  1.37it/s, training_loss=0.399]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 576/1161 [07:03<07:08,  1.37it/s, training_loss=0.399]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 576/1161 [07:04<07:08,  1.37it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 577/1161 [07:04<07:06,  1.37it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 577/1161 [07:04<07:06,  1.37it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 578/1161 [07:04<07:06,  1.37it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 578/1161 [07:05<07:06,  1.37it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 579/1161 [07:05<07:06,  1.36it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 579/1161 [07:06<07:06,  1.36it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 580/1161 [07:06<07:05,  1.36it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 580/1161 [07:07<07:05,  1.36it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 2:  50%|█████     | 581/1161 [07:07<07:03,  1.37it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 2:  50%|█████     | 581/1161 [07:07<07:03,  1.37it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  50%|█████     | 582/1161 [07:07<07:03,  1.37it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  50%|█████     | 582/1161 [07:08<07:03,  1.37it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  50%|█████     | 583/1161 [07:08<07:03,  1.36it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  50%|█████     | 583/1161 [07:09<07:03,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  50%|█████     | 584/1161 [07:09<07:05,  1.35it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  50%|█████     | 584/1161 [07:10<07:05,  1.35it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  50%|█████     | 585/1161 [07:10<07:04,  1.36it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  50%|█████     | 585/1161 [07:10<07:04,  1.36it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  50%|█████     | 586/1161 [07:10<07:01,  1.36it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  50%|█████     | 586/1161 [07:11<07:01,  1.36it/s, training_loss=0.036]\u001b[A\n",
            "Epoch 2:  51%|█████     | 587/1161 [07:11<07:01,  1.36it/s, training_loss=0.036]\u001b[A\n",
            "Epoch 2:  51%|█████     | 587/1161 [07:12<07:01,  1.36it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  51%|█████     | 588/1161 [07:12<07:02,  1.36it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  51%|█████     | 588/1161 [07:13<07:02,  1.36it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  51%|█████     | 589/1161 [07:13<07:01,  1.36it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  51%|█████     | 589/1161 [07:13<07:01,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  51%|█████     | 590/1161 [07:13<06:59,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  51%|█████     | 590/1161 [07:14<06:59,  1.36it/s, training_loss=0.259]\u001b[A\n",
            "Epoch 2:  51%|█████     | 591/1161 [07:14<06:58,  1.36it/s, training_loss=0.259]\u001b[A\n",
            "Epoch 2:  51%|█████     | 591/1161 [07:15<06:58,  1.36it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  51%|█████     | 592/1161 [07:15<06:58,  1.36it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  51%|█████     | 592/1161 [07:15<06:58,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  51%|█████     | 593/1161 [07:15<06:55,  1.37it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  51%|█████     | 593/1161 [07:16<06:55,  1.37it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 2:  51%|█████     | 594/1161 [07:16<06:55,  1.37it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 2:  51%|█████     | 594/1161 [07:17<06:55,  1.37it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  51%|█████     | 595/1161 [07:17<06:54,  1.37it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  51%|█████     | 595/1161 [07:18<06:54,  1.37it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 596/1161 [07:18<06:53,  1.37it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 596/1161 [07:18<06:53,  1.37it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 597/1161 [07:18<06:52,  1.37it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 597/1161 [07:19<06:52,  1.37it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 598/1161 [07:19<06:52,  1.36it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 598/1161 [07:20<06:52,  1.36it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 599/1161 [07:20<06:50,  1.37it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 599/1161 [07:21<06:50,  1.37it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 600/1161 [07:21<06:51,  1.36it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 600/1161 [07:21<06:51,  1.36it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 601/1161 [07:21<06:49,  1.37it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 601/1161 [07:22<06:49,  1.37it/s, training_loss=0.318]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 602/1161 [07:22<06:47,  1.37it/s, training_loss=0.318]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 602/1161 [07:23<06:47,  1.37it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 603/1161 [07:23<06:46,  1.37it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 603/1161 [07:23<06:46,  1.37it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 604/1161 [07:23<06:45,  1.37it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 604/1161 [07:24<06:45,  1.37it/s, training_loss=0.308]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 605/1161 [07:24<06:46,  1.37it/s, training_loss=0.308]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 605/1161 [07:25<06:46,  1.37it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 606/1161 [07:25<06:45,  1.37it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 606/1161 [07:26<06:45,  1.37it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 607/1161 [07:26<06:45,  1.37it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 607/1161 [07:26<06:45,  1.37it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 608/1161 [07:26<06:45,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 608/1161 [07:27<06:45,  1.36it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 609/1161 [07:27<06:44,  1.37it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 609/1161 [07:28<06:44,  1.37it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 610/1161 [07:28<06:44,  1.36it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 610/1161 [07:29<06:44,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 611/1161 [07:29<06:43,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 611/1161 [07:29<06:43,  1.36it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 612/1161 [07:29<06:44,  1.36it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 612/1161 [07:30<06:44,  1.36it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 613/1161 [07:30<06:43,  1.36it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 613/1161 [07:31<06:43,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 614/1161 [07:31<06:42,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 614/1161 [07:32<06:42,  1.36it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 615/1161 [07:32<06:39,  1.37it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 615/1161 [07:32<06:39,  1.37it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 616/1161 [07:32<06:39,  1.36it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 616/1161 [07:33<06:39,  1.36it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 617/1161 [07:33<06:37,  1.37it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 617/1161 [07:34<06:37,  1.37it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 618/1161 [07:34<06:37,  1.37it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 618/1161 [07:34<06:37,  1.37it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 619/1161 [07:34<06:36,  1.37it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 619/1161 [07:35<06:36,  1.37it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 620/1161 [07:35<06:35,  1.37it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 620/1161 [07:36<06:35,  1.37it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 621/1161 [07:36<06:34,  1.37it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 621/1161 [07:37<06:34,  1.37it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 622/1161 [07:37<06:33,  1.37it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 622/1161 [07:37<06:33,  1.37it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 623/1161 [07:37<06:32,  1.37it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 623/1161 [07:38<06:32,  1.37it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 624/1161 [07:38<06:33,  1.37it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 624/1161 [07:39<06:33,  1.37it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 625/1161 [07:39<06:34,  1.36it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 625/1161 [07:40<06:34,  1.36it/s, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 626/1161 [07:40<06:32,  1.36it/s, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 626/1161 [07:40<06:32,  1.36it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 627/1161 [07:40<06:34,  1.35it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 627/1161 [07:41<06:34,  1.35it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 628/1161 [07:41<06:33,  1.36it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 628/1161 [07:42<06:33,  1.36it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 629/1161 [07:42<06:33,  1.35it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 629/1161 [07:43<06:33,  1.35it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 630/1161 [07:43<06:30,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 630/1161 [07:43<06:30,  1.36it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 631/1161 [07:43<06:31,  1.35it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 631/1161 [07:44<06:31,  1.35it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 632/1161 [07:44<06:29,  1.36it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 632/1161 [07:45<06:29,  1.36it/s, training_loss=0.301]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 633/1161 [07:45<06:28,  1.36it/s, training_loss=0.301]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 633/1161 [07:45<06:28,  1.36it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 634/1161 [07:45<06:26,  1.36it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 634/1161 [07:46<06:26,  1.36it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 635/1161 [07:46<06:26,  1.36it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 635/1161 [07:47<06:26,  1.36it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 636/1161 [07:47<06:25,  1.36it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 636/1161 [07:48<06:25,  1.36it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 637/1161 [07:48<06:23,  1.37it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 637/1161 [07:48<06:23,  1.37it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 638/1161 [07:48<06:21,  1.37it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 638/1161 [07:49<06:21,  1.37it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 639/1161 [07:49<06:20,  1.37it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 639/1161 [07:50<06:20,  1.37it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 640/1161 [07:50<06:20,  1.37it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 640/1161 [07:51<06:20,  1.37it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 641/1161 [07:51<06:21,  1.36it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 641/1161 [07:51<06:21,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 642/1161 [07:51<06:22,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 642/1161 [07:52<06:22,  1.36it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 643/1161 [07:52<06:20,  1.36it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 643/1161 [07:53<06:20,  1.36it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 644/1161 [07:53<06:19,  1.36it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 644/1161 [07:54<06:19,  1.36it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 645/1161 [07:54<06:18,  1.36it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 645/1161 [07:54<06:18,  1.36it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 646/1161 [07:54<06:17,  1.36it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 646/1161 [07:55<06:17,  1.36it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 647/1161 [07:55<06:18,  1.36it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 647/1161 [07:56<06:18,  1.36it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 648/1161 [07:56<06:16,  1.36it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 648/1161 [07:56<06:16,  1.36it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 649/1161 [07:57<06:16,  1.36it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 649/1161 [07:57<06:16,  1.36it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 650/1161 [07:57<06:15,  1.36it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 650/1161 [07:58<06:15,  1.36it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 651/1161 [07:58<06:16,  1.36it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 651/1161 [07:59<06:16,  1.36it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 652/1161 [07:59<06:13,  1.36it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 652/1161 [07:59<06:13,  1.36it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 653/1161 [07:59<06:12,  1.36it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 653/1161 [08:00<06:12,  1.36it/s, training_loss=0.259]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 654/1161 [08:00<06:11,  1.37it/s, training_loss=0.259]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 654/1161 [08:01<06:11,  1.37it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 655/1161 [08:01<06:10,  1.37it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 655/1161 [08:02<06:10,  1.37it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 656/1161 [08:02<06:12,  1.35it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 656/1161 [08:02<06:12,  1.35it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 657/1161 [08:02<06:11,  1.36it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 657/1161 [08:03<06:11,  1.36it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 658/1161 [08:03<06:10,  1.36it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 658/1161 [08:04<06:10,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 659/1161 [08:04<06:09,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 659/1161 [08:05<06:09,  1.36it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 660/1161 [08:05<06:08,  1.36it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 660/1161 [08:05<06:08,  1.36it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 661/1161 [08:05<06:07,  1.36it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 661/1161 [08:06<06:07,  1.36it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 662/1161 [08:06<06:05,  1.36it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 662/1161 [08:07<06:05,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 663/1161 [08:07<06:04,  1.37it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 663/1161 [08:08<06:04,  1.37it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 664/1161 [08:08<06:03,  1.37it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 664/1161 [08:08<06:03,  1.37it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 665/1161 [08:08<06:03,  1.36it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 665/1161 [08:09<06:03,  1.36it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 666/1161 [08:09<06:01,  1.37it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 666/1161 [08:10<06:01,  1.37it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 667/1161 [08:10<06:01,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 667/1161 [08:10<06:01,  1.36it/s, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 668/1161 [08:10<06:00,  1.37it/s, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 668/1161 [08:11<06:00,  1.37it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 669/1161 [08:11<05:59,  1.37it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 669/1161 [08:12<05:59,  1.37it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 670/1161 [08:12<06:01,  1.36it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 670/1161 [08:13<06:01,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 671/1161 [08:13<05:59,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 671/1161 [08:13<05:59,  1.36it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 672/1161 [08:13<05:58,  1.36it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 672/1161 [08:14<05:58,  1.36it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 673/1161 [08:14<05:58,  1.36it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 673/1161 [08:15<05:58,  1.36it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 674/1161 [08:15<05:57,  1.36it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 674/1161 [08:16<05:57,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 675/1161 [08:16<05:57,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 675/1161 [08:16<05:57,  1.36it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 676/1161 [08:16<05:56,  1.36it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 676/1161 [08:17<05:56,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 677/1161 [08:17<05:56,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 677/1161 [08:18<05:56,  1.36it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 678/1161 [08:18<05:56,  1.36it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 678/1161 [08:19<05:56,  1.36it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 679/1161 [08:19<05:55,  1.36it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 679/1161 [08:19<05:55,  1.36it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 680/1161 [08:19<05:53,  1.36it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 680/1161 [08:20<05:53,  1.36it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 681/1161 [08:20<05:53,  1.36it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 681/1161 [08:21<05:53,  1.36it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 682/1161 [08:21<05:51,  1.36it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 682/1161 [08:21<05:51,  1.36it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 683/1161 [08:21<05:50,  1.36it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 683/1161 [08:22<05:50,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 684/1161 [08:22<05:48,  1.37it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 684/1161 [08:23<05:48,  1.37it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 685/1161 [08:23<05:48,  1.37it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 685/1161 [08:24<05:48,  1.37it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 686/1161 [08:24<05:46,  1.37it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 686/1161 [08:24<05:46,  1.37it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 687/1161 [08:24<05:46,  1.37it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 687/1161 [08:25<05:46,  1.37it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 688/1161 [08:25<05:45,  1.37it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 688/1161 [08:26<05:45,  1.37it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 689/1161 [08:26<05:45,  1.37it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 689/1161 [08:27<05:45,  1.37it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 690/1161 [08:27<05:45,  1.36it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 690/1161 [08:27<05:45,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 691/1161 [08:27<05:46,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 691/1161 [08:28<05:46,  1.36it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 692/1161 [08:28<05:43,  1.37it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 692/1161 [08:29<05:43,  1.37it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 693/1161 [08:29<05:42,  1.36it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 693/1161 [08:30<05:42,  1.36it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 694/1161 [08:30<05:43,  1.36it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 694/1161 [08:30<05:43,  1.36it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 695/1161 [08:30<05:41,  1.36it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 695/1161 [08:31<05:41,  1.36it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 696/1161 [08:31<05:41,  1.36it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 696/1161 [08:32<05:41,  1.36it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  60%|██████    | 697/1161 [08:32<05:41,  1.36it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  60%|██████    | 697/1161 [08:32<05:41,  1.36it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  60%|██████    | 698/1161 [08:32<05:40,  1.36it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  60%|██████    | 698/1161 [08:33<05:40,  1.36it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  60%|██████    | 699/1161 [08:33<05:40,  1.36it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  60%|██████    | 699/1161 [08:34<05:40,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  60%|██████    | 700/1161 [08:34<05:39,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  60%|██████    | 700/1161 [08:35<05:39,  1.36it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 2:  60%|██████    | 701/1161 [08:35<05:38,  1.36it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 2:  60%|██████    | 701/1161 [08:35<05:38,  1.36it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  60%|██████    | 702/1161 [08:35<05:37,  1.36it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  60%|██████    | 702/1161 [08:36<05:37,  1.36it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  61%|██████    | 703/1161 [08:36<05:37,  1.36it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  61%|██████    | 703/1161 [08:37<05:37,  1.36it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  61%|██████    | 704/1161 [08:37<05:37,  1.35it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  61%|██████    | 704/1161 [08:38<05:37,  1.35it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 2:  61%|██████    | 705/1161 [08:38<05:35,  1.36it/s, training_loss=0.294]\u001b[A\n",
            "Epoch 2:  61%|██████    | 705/1161 [08:38<05:35,  1.36it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  61%|██████    | 706/1161 [08:38<05:34,  1.36it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  61%|██████    | 706/1161 [08:39<05:34,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  61%|██████    | 707/1161 [08:39<05:33,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  61%|██████    | 707/1161 [08:40<05:33,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  61%|██████    | 708/1161 [08:40<05:32,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  61%|██████    | 708/1161 [08:41<05:32,  1.36it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  61%|██████    | 709/1161 [08:41<05:31,  1.36it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  61%|██████    | 709/1161 [08:41<05:31,  1.36it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  61%|██████    | 710/1161 [08:41<05:31,  1.36it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  61%|██████    | 710/1161 [08:42<05:31,  1.36it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  61%|██████    | 711/1161 [08:42<05:29,  1.37it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  61%|██████    | 711/1161 [08:43<05:29,  1.37it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 712/1161 [08:43<05:28,  1.37it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 712/1161 [08:43<05:28,  1.37it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 713/1161 [08:44<05:29,  1.36it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 713/1161 [08:44<05:29,  1.36it/s, training_loss=0.245]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 714/1161 [08:44<05:28,  1.36it/s, training_loss=0.245]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 714/1161 [08:45<05:28,  1.36it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 715/1161 [08:45<05:28,  1.36it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 715/1161 [08:46<05:28,  1.36it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 716/1161 [08:46<05:26,  1.36it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 716/1161 [08:46<05:26,  1.36it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 717/1161 [08:46<05:25,  1.36it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 717/1161 [08:47<05:25,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 718/1161 [08:47<05:25,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 718/1161 [08:48<05:25,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 719/1161 [08:48<05:24,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 719/1161 [08:49<05:24,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 720/1161 [08:49<05:23,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 720/1161 [08:49<05:23,  1.36it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 721/1161 [08:49<05:23,  1.36it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 721/1161 [08:50<05:23,  1.36it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 722/1161 [08:50<05:23,  1.36it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 722/1161 [08:51<05:23,  1.36it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 723/1161 [08:51<05:22,  1.36it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 723/1161 [08:52<05:22,  1.36it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 724/1161 [08:52<05:22,  1.36it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 724/1161 [08:52<05:22,  1.36it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 725/1161 [08:52<05:20,  1.36it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 725/1161 [08:53<05:20,  1.36it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 726/1161 [08:53<05:19,  1.36it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 726/1161 [08:54<05:19,  1.36it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 727/1161 [08:54<05:18,  1.36it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 727/1161 [08:55<05:18,  1.36it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 728/1161 [08:55<05:17,  1.36it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 728/1161 [08:55<05:17,  1.36it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 729/1161 [08:55<05:17,  1.36it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 729/1161 [08:56<05:17,  1.36it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 730/1161 [08:56<05:16,  1.36it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 730/1161 [08:57<05:16,  1.36it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 731/1161 [08:57<05:16,  1.36it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 731/1161 [08:57<05:16,  1.36it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 732/1161 [08:57<05:15,  1.36it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 732/1161 [08:58<05:15,  1.36it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 733/1161 [08:58<05:16,  1.35it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 733/1161 [08:59<05:16,  1.35it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 734/1161 [08:59<05:14,  1.36it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 734/1161 [09:00<05:14,  1.36it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 735/1161 [09:00<05:13,  1.36it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 735/1161 [09:00<05:13,  1.36it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 736/1161 [09:00<05:12,  1.36it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 736/1161 [09:01<05:12,  1.36it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 737/1161 [09:01<05:12,  1.36it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 737/1161 [09:02<05:12,  1.36it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 738/1161 [09:02<05:11,  1.36it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 738/1161 [09:03<05:11,  1.36it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 739/1161 [09:03<05:11,  1.35it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 739/1161 [09:03<05:11,  1.35it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 740/1161 [09:03<05:12,  1.35it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 740/1161 [09:04<05:12,  1.35it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 741/1161 [09:04<05:10,  1.35it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 741/1161 [09:05<05:10,  1.35it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 742/1161 [09:05<05:09,  1.35it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 742/1161 [09:06<05:09,  1.35it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 743/1161 [09:06<05:06,  1.36it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 743/1161 [09:06<05:06,  1.36it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 744/1161 [09:06<05:06,  1.36it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 744/1161 [09:07<05:06,  1.36it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 745/1161 [09:07<05:04,  1.37it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 745/1161 [09:08<05:04,  1.37it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 746/1161 [09:08<05:04,  1.36it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 746/1161 [09:08<05:04,  1.36it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 747/1161 [09:09<05:03,  1.36it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 747/1161 [09:09<05:03,  1.36it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 748/1161 [09:09<05:03,  1.36it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 748/1161 [09:10<05:03,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 749/1161 [09:10<05:02,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 749/1161 [09:11<05:02,  1.36it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 750/1161 [09:11<05:01,  1.36it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 750/1161 [09:11<05:01,  1.36it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 751/1161 [09:11<05:00,  1.36it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 751/1161 [09:12<05:00,  1.36it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 752/1161 [09:12<05:00,  1.36it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 752/1161 [09:13<05:00,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 753/1161 [09:13<04:59,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 753/1161 [09:14<04:59,  1.36it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 754/1161 [09:14<04:59,  1.36it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 754/1161 [09:14<04:59,  1.36it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 755/1161 [09:14<04:58,  1.36it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 755/1161 [09:15<04:58,  1.36it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 756/1161 [09:15<04:58,  1.36it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 756/1161 [09:16<04:58,  1.36it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 757/1161 [09:16<04:57,  1.36it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 757/1161 [09:17<04:57,  1.36it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 758/1161 [09:17<04:56,  1.36it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 758/1161 [09:17<04:56,  1.36it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 759/1161 [09:17<04:55,  1.36it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 759/1161 [09:18<04:55,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 760/1161 [09:18<04:55,  1.36it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 760/1161 [09:19<04:55,  1.36it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 761/1161 [09:19<04:54,  1.36it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 761/1161 [09:20<04:54,  1.36it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 762/1161 [09:20<04:55,  1.35it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 762/1161 [09:20<04:55,  1.35it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 763/1161 [09:20<04:53,  1.35it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 763/1161 [09:21<04:53,  1.35it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 764/1161 [09:21<04:53,  1.35it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 764/1161 [09:22<04:53,  1.35it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 765/1161 [09:22<04:52,  1.35it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 765/1161 [09:23<04:52,  1.35it/s, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 766/1161 [09:23<04:51,  1.35it/s, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 766/1161 [09:23<04:51,  1.35it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 767/1161 [09:23<04:49,  1.36it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 767/1161 [09:24<04:49,  1.36it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 768/1161 [09:24<04:49,  1.36it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 768/1161 [09:25<04:49,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 769/1161 [09:25<04:48,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 769/1161 [09:25<04:48,  1.36it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 770/1161 [09:25<04:47,  1.36it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 770/1161 [09:26<04:47,  1.36it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 771/1161 [09:26<04:47,  1.36it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 771/1161 [09:27<04:47,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 772/1161 [09:27<04:46,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 772/1161 [09:28<04:46,  1.36it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 773/1161 [09:28<04:45,  1.36it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 773/1161 [09:28<04:45,  1.36it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 774/1161 [09:28<04:44,  1.36it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 774/1161 [09:29<04:44,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 775/1161 [09:29<04:43,  1.36it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 775/1161 [09:30<04:43,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 776/1161 [09:30<04:42,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 776/1161 [09:31<04:42,  1.36it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 777/1161 [09:31<04:43,  1.36it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 777/1161 [09:31<04:43,  1.36it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 778/1161 [09:31<04:42,  1.36it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 778/1161 [09:32<04:42,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 779/1161 [09:32<04:42,  1.35it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 779/1161 [09:33<04:42,  1.35it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 780/1161 [09:33<04:41,  1.35it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 780/1161 [09:34<04:41,  1.35it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 781/1161 [09:34<04:40,  1.36it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 781/1161 [09:34<04:40,  1.36it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 782/1161 [09:34<04:39,  1.36it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 782/1161 [09:35<04:39,  1.36it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 783/1161 [09:35<04:38,  1.36it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 783/1161 [09:36<04:38,  1.36it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 784/1161 [09:36<04:37,  1.36it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 784/1161 [09:36<04:37,  1.36it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 785/1161 [09:37<04:37,  1.36it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 785/1161 [09:37<04:37,  1.36it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 786/1161 [09:37<04:36,  1.35it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 786/1161 [09:38<04:36,  1.35it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 787/1161 [09:38<04:35,  1.36it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 787/1161 [09:39<04:35,  1.36it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 788/1161 [09:39<04:34,  1.36it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 788/1161 [09:39<04:34,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 789/1161 [09:39<04:33,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 789/1161 [09:40<04:33,  1.36it/s, training_loss=0.285]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 790/1161 [09:40<04:32,  1.36it/s, training_loss=0.285]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 790/1161 [09:41<04:32,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 791/1161 [09:41<04:31,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 791/1161 [09:42<04:31,  1.36it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 792/1161 [09:42<04:31,  1.36it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 792/1161 [09:42<04:31,  1.36it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 793/1161 [09:42<04:32,  1.35it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 793/1161 [09:43<04:32,  1.35it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 794/1161 [09:43<04:30,  1.36it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 794/1161 [09:44<04:30,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 795/1161 [09:44<04:29,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 795/1161 [09:45<04:29,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 796/1161 [09:45<04:29,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 796/1161 [09:45<04:29,  1.36it/s, training_loss=0.338]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 797/1161 [09:45<04:28,  1.36it/s, training_loss=0.338]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 797/1161 [09:46<04:28,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 798/1161 [09:46<04:28,  1.35it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 798/1161 [09:47<04:28,  1.35it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 799/1161 [09:47<04:26,  1.36it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 799/1161 [09:48<04:26,  1.36it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 800/1161 [09:48<04:24,  1.36it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 800/1161 [09:48<04:24,  1.36it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 801/1161 [09:48<04:23,  1.36it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 801/1161 [09:49<04:23,  1.36it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 802/1161 [09:49<04:23,  1.36it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 802/1161 [09:50<04:23,  1.36it/s, training_loss=0.288]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 803/1161 [09:50<04:22,  1.37it/s, training_loss=0.288]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 803/1161 [09:50<04:22,  1.37it/s, training_loss=0.379]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 804/1161 [09:50<04:22,  1.36it/s, training_loss=0.379]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 804/1161 [09:51<04:22,  1.36it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 805/1161 [09:51<04:21,  1.36it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 805/1161 [09:52<04:21,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 806/1161 [09:52<04:21,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 806/1161 [09:53<04:21,  1.36it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 807/1161 [09:53<04:21,  1.35it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 807/1161 [09:53<04:21,  1.35it/s, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 808/1161 [09:53<04:20,  1.35it/s, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 808/1161 [09:54<04:20,  1.35it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 809/1161 [09:54<04:19,  1.36it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 809/1161 [09:55<04:19,  1.36it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 810/1161 [09:55<04:19,  1.35it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 810/1161 [09:56<04:19,  1.35it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 811/1161 [09:56<04:18,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 811/1161 [09:56<04:18,  1.36it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 812/1161 [09:56<04:17,  1.36it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 812/1161 [09:57<04:17,  1.36it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  70%|███████   | 813/1161 [09:57<04:16,  1.36it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  70%|███████   | 813/1161 [09:58<04:16,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  70%|███████   | 814/1161 [09:58<04:15,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  70%|███████   | 814/1161 [09:59<04:15,  1.36it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  70%|███████   | 815/1161 [09:59<04:15,  1.36it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  70%|███████   | 815/1161 [09:59<04:15,  1.36it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  70%|███████   | 816/1161 [09:59<04:13,  1.36it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  70%|███████   | 816/1161 [10:00<04:13,  1.36it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  70%|███████   | 817/1161 [10:00<04:12,  1.36it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  70%|███████   | 817/1161 [10:01<04:12,  1.36it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  70%|███████   | 818/1161 [10:01<04:11,  1.36it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  70%|███████   | 818/1161 [10:02<04:11,  1.36it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  71%|███████   | 819/1161 [10:02<04:10,  1.37it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  71%|███████   | 819/1161 [10:02<04:10,  1.37it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  71%|███████   | 820/1161 [10:02<04:09,  1.37it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  71%|███████   | 820/1161 [10:03<04:09,  1.37it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  71%|███████   | 821/1161 [10:03<04:08,  1.37it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  71%|███████   | 821/1161 [10:04<04:08,  1.37it/s, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  71%|███████   | 822/1161 [10:04<04:08,  1.36it/s, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  71%|███████   | 822/1161 [10:04<04:08,  1.36it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  71%|███████   | 823/1161 [10:04<04:07,  1.37it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  71%|███████   | 823/1161 [10:05<04:07,  1.37it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  71%|███████   | 824/1161 [10:05<04:06,  1.37it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  71%|███████   | 824/1161 [10:06<04:06,  1.37it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  71%|███████   | 825/1161 [10:06<04:06,  1.36it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  71%|███████   | 825/1161 [10:07<04:06,  1.36it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  71%|███████   | 826/1161 [10:07<04:05,  1.36it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  71%|███████   | 826/1161 [10:07<04:05,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  71%|███████   | 827/1161 [10:07<04:05,  1.36it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  71%|███████   | 827/1161 [10:08<04:05,  1.36it/s, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 828/1161 [10:08<04:03,  1.36it/s, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 828/1161 [10:09<04:03,  1.36it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 829/1161 [10:09<04:03,  1.37it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 829/1161 [10:10<04:03,  1.37it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 830/1161 [10:10<04:02,  1.37it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 830/1161 [10:10<04:02,  1.37it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 831/1161 [10:10<04:01,  1.37it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 831/1161 [10:11<04:01,  1.37it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 832/1161 [10:11<04:01,  1.36it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 832/1161 [10:12<04:01,  1.36it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 833/1161 [10:12<04:01,  1.36it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 833/1161 [10:13<04:01,  1.36it/s, training_loss=0.368]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 834/1161 [10:13<04:00,  1.36it/s, training_loss=0.368]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 834/1161 [10:13<04:00,  1.36it/s, training_loss=0.343]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 835/1161 [10:13<04:00,  1.36it/s, training_loss=0.343]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 835/1161 [10:14<04:00,  1.36it/s, training_loss=0.281]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 836/1161 [10:14<03:59,  1.36it/s, training_loss=0.281]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 836/1161 [10:15<03:59,  1.36it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 837/1161 [10:15<03:58,  1.36it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 837/1161 [10:15<03:58,  1.36it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 838/1161 [10:15<03:58,  1.36it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 838/1161 [10:16<03:58,  1.36it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 839/1161 [10:16<03:57,  1.36it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 839/1161 [10:17<03:57,  1.36it/s, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 840/1161 [10:17<03:56,  1.36it/s, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 840/1161 [10:18<03:56,  1.36it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 841/1161 [10:18<03:55,  1.36it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 841/1161 [10:18<03:55,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 842/1161 [10:18<03:54,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 842/1161 [10:19<03:54,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 843/1161 [10:19<03:53,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 843/1161 [10:20<03:53,  1.36it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 844/1161 [10:20<03:52,  1.36it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 844/1161 [10:21<03:52,  1.36it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 845/1161 [10:21<03:51,  1.37it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 845/1161 [10:21<03:51,  1.37it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 846/1161 [10:21<03:50,  1.37it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 846/1161 [10:22<03:50,  1.37it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 847/1161 [10:22<03:49,  1.37it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 847/1161 [10:23<03:49,  1.37it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 848/1161 [10:23<03:50,  1.36it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 848/1161 [10:24<03:50,  1.36it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 849/1161 [10:24<03:49,  1.36it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 849/1161 [10:24<03:49,  1.36it/s, training_loss=0.337]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 850/1161 [10:24<03:49,  1.35it/s, training_loss=0.337]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 850/1161 [10:25<03:49,  1.35it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 851/1161 [10:25<03:47,  1.36it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 851/1161 [10:26<03:47,  1.36it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 852/1161 [10:26<03:48,  1.35it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 852/1161 [10:26<03:48,  1.35it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 853/1161 [10:27<03:47,  1.35it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 853/1161 [10:27<03:47,  1.35it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 854/1161 [10:27<03:46,  1.36it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 854/1161 [10:28<03:46,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 855/1161 [10:28<03:45,  1.36it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 855/1161 [10:29<03:45,  1.36it/s, training_loss=0.249]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 856/1161 [10:29<03:44,  1.36it/s, training_loss=0.249]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 856/1161 [10:29<03:44,  1.36it/s, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 857/1161 [10:29<03:43,  1.36it/s, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 857/1161 [10:30<03:43,  1.36it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 858/1161 [10:30<03:42,  1.36it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 858/1161 [10:31<03:42,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 859/1161 [10:31<03:41,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 859/1161 [10:32<03:41,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 860/1161 [10:32<03:40,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 860/1161 [10:32<03:40,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 861/1161 [10:32<03:39,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 861/1161 [10:33<03:39,  1.36it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 862/1161 [10:33<03:39,  1.36it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 862/1161 [10:34<03:39,  1.36it/s, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 863/1161 [10:34<03:38,  1.36it/s, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 863/1161 [10:35<03:38,  1.36it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 864/1161 [10:35<03:37,  1.36it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 864/1161 [10:35<03:37,  1.36it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 865/1161 [10:35<03:37,  1.36it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 865/1161 [10:36<03:37,  1.36it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 866/1161 [10:36<03:35,  1.37it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 866/1161 [10:37<03:35,  1.37it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 867/1161 [10:37<03:35,  1.36it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 867/1161 [10:37<03:35,  1.36it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 868/1161 [10:38<03:35,  1.36it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 868/1161 [10:38<03:35,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 869/1161 [10:38<03:33,  1.37it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 869/1161 [10:39<03:33,  1.37it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 870/1161 [10:39<03:33,  1.36it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 870/1161 [10:40<03:33,  1.36it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 871/1161 [10:40<03:32,  1.36it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 871/1161 [10:40<03:32,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 872/1161 [10:40<03:31,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 872/1161 [10:41<03:31,  1.36it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 873/1161 [10:41<03:31,  1.36it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 873/1161 [10:42<03:31,  1.36it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 874/1161 [10:42<03:31,  1.36it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 874/1161 [10:43<03:31,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 875/1161 [10:43<03:30,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 875/1161 [10:43<03:30,  1.36it/s, training_loss=0.354]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 876/1161 [10:43<03:30,  1.36it/s, training_loss=0.354]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 876/1161 [10:44<03:30,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 877/1161 [10:44<03:28,  1.36it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 877/1161 [10:45<03:28,  1.36it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 878/1161 [10:45<03:27,  1.36it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 878/1161 [10:46<03:27,  1.36it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 879/1161 [10:46<03:27,  1.36it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 879/1161 [10:46<03:27,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 880/1161 [10:46<03:25,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 880/1161 [10:47<03:25,  1.36it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 881/1161 [10:47<03:25,  1.36it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 881/1161 [10:48<03:25,  1.36it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 882/1161 [10:48<03:24,  1.36it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 882/1161 [10:49<03:24,  1.36it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 883/1161 [10:49<03:23,  1.36it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 883/1161 [10:49<03:23,  1.36it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 884/1161 [10:49<03:23,  1.36it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 884/1161 [10:50<03:23,  1.36it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 885/1161 [10:50<03:22,  1.36it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 885/1161 [10:51<03:22,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 886/1161 [10:51<03:21,  1.37it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 886/1161 [10:51<03:21,  1.37it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 887/1161 [10:51<03:22,  1.36it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 887/1161 [10:52<03:22,  1.36it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 888/1161 [10:52<03:20,  1.36it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 888/1161 [10:53<03:20,  1.36it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 889/1161 [10:53<03:20,  1.36it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 889/1161 [10:54<03:20,  1.36it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 890/1161 [10:54<03:18,  1.36it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 890/1161 [10:54<03:18,  1.36it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 891/1161 [10:54<03:17,  1.37it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 891/1161 [10:55<03:17,  1.37it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 892/1161 [10:55<03:17,  1.37it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 892/1161 [10:56<03:17,  1.37it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 893/1161 [10:56<03:15,  1.37it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 893/1161 [10:57<03:15,  1.37it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 894/1161 [10:57<03:16,  1.36it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 894/1161 [10:57<03:16,  1.36it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 895/1161 [10:57<03:15,  1.36it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 895/1161 [10:58<03:15,  1.36it/s, training_loss=0.252]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 896/1161 [10:58<03:15,  1.36it/s, training_loss=0.252]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 896/1161 [10:59<03:15,  1.36it/s, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 897/1161 [10:59<03:14,  1.35it/s, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 897/1161 [11:00<03:14,  1.35it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 898/1161 [11:00<03:13,  1.36it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 898/1161 [11:00<03:13,  1.36it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 899/1161 [11:00<03:12,  1.36it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 899/1161 [11:01<03:12,  1.36it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 900/1161 [11:01<03:12,  1.36it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 900/1161 [11:02<03:12,  1.36it/s, training_loss=0.287]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 901/1161 [11:02<03:11,  1.36it/s, training_loss=0.287]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 901/1161 [11:02<03:11,  1.36it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 902/1161 [11:02<03:11,  1.35it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 902/1161 [11:03<03:11,  1.35it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 903/1161 [11:03<03:10,  1.35it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 903/1161 [11:04<03:10,  1.35it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 904/1161 [11:04<03:09,  1.36it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 904/1161 [11:05<03:09,  1.36it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 905/1161 [11:05<03:08,  1.36it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 905/1161 [11:05<03:08,  1.36it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 906/1161 [11:05<03:06,  1.37it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 906/1161 [11:06<03:06,  1.37it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 907/1161 [11:06<03:05,  1.37it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 907/1161 [11:07<03:05,  1.37it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 908/1161 [11:07<03:05,  1.36it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 908/1161 [11:08<03:05,  1.36it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 909/1161 [11:08<03:05,  1.36it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 909/1161 [11:08<03:05,  1.36it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 910/1161 [11:08<03:04,  1.36it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 910/1161 [11:09<03:04,  1.36it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 911/1161 [11:09<03:03,  1.36it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 911/1161 [11:10<03:03,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 912/1161 [11:10<03:02,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 912/1161 [11:11<03:02,  1.36it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 913/1161 [11:11<03:02,  1.36it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 913/1161 [11:11<03:02,  1.36it/s, training_loss=0.341]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 914/1161 [11:11<03:01,  1.36it/s, training_loss=0.341]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 914/1161 [11:12<03:01,  1.36it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 915/1161 [11:12<03:01,  1.35it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 915/1161 [11:13<03:01,  1.35it/s, training_loss=0.281]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 916/1161 [11:13<03:00,  1.35it/s, training_loss=0.281]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 916/1161 [11:14<03:00,  1.35it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 917/1161 [11:14<03:00,  1.35it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 917/1161 [11:14<03:00,  1.35it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 918/1161 [11:14<02:58,  1.36it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 918/1161 [11:15<02:58,  1.36it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 919/1161 [11:15<02:57,  1.36it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 919/1161 [11:16<02:57,  1.36it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 920/1161 [11:16<02:56,  1.36it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 920/1161 [11:16<02:56,  1.36it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 921/1161 [11:16<02:56,  1.36it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 921/1161 [11:17<02:56,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 922/1161 [11:17<02:55,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 922/1161 [11:18<02:55,  1.36it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 923/1161 [11:18<02:54,  1.36it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 923/1161 [11:19<02:54,  1.36it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 924/1161 [11:19<02:54,  1.36it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 924/1161 [11:19<02:54,  1.36it/s, training_loss=0.321]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 925/1161 [11:19<02:53,  1.36it/s, training_loss=0.321]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 925/1161 [11:20<02:53,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 926/1161 [11:20<02:52,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 926/1161 [11:21<02:52,  1.36it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 927/1161 [11:21<02:51,  1.37it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 927/1161 [11:22<02:51,  1.37it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 928/1161 [11:22<02:50,  1.37it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 928/1161 [11:22<02:50,  1.37it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  80%|████████  | 929/1161 [11:22<02:49,  1.37it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  80%|████████  | 929/1161 [11:23<02:49,  1.37it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  80%|████████  | 930/1161 [11:23<02:49,  1.36it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  80%|████████  | 930/1161 [11:24<02:49,  1.36it/s, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  80%|████████  | 931/1161 [11:24<02:48,  1.36it/s, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  80%|████████  | 931/1161 [11:25<02:48,  1.36it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  80%|████████  | 932/1161 [11:25<02:48,  1.36it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  80%|████████  | 932/1161 [11:25<02:48,  1.36it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  80%|████████  | 933/1161 [11:25<02:47,  1.36it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  80%|████████  | 933/1161 [11:26<02:47,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  80%|████████  | 934/1161 [11:26<02:46,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  80%|████████  | 934/1161 [11:27<02:46,  1.36it/s, training_loss=0.036]\u001b[A\n",
            "Epoch 2:  81%|████████  | 935/1161 [11:27<02:45,  1.37it/s, training_loss=0.036]\u001b[A\n",
            "Epoch 2:  81%|████████  | 935/1161 [11:27<02:45,  1.37it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 2:  81%|████████  | 936/1161 [11:27<02:44,  1.37it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 2:  81%|████████  | 936/1161 [11:28<02:44,  1.37it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  81%|████████  | 937/1161 [11:28<02:44,  1.36it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  81%|████████  | 937/1161 [11:29<02:44,  1.36it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  81%|████████  | 938/1161 [11:29<02:42,  1.37it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  81%|████████  | 938/1161 [11:30<02:42,  1.37it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  81%|████████  | 939/1161 [11:30<02:42,  1.36it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  81%|████████  | 939/1161 [11:30<02:42,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  81%|████████  | 940/1161 [11:30<02:42,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  81%|████████  | 940/1161 [11:31<02:42,  1.36it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  81%|████████  | 941/1161 [11:31<02:41,  1.36it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  81%|████████  | 941/1161 [11:32<02:41,  1.36it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  81%|████████  | 942/1161 [11:32<02:41,  1.36it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  81%|████████  | 942/1161 [11:33<02:41,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  81%|████████  | 943/1161 [11:33<02:40,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  81%|████████  | 943/1161 [11:33<02:40,  1.36it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 944/1161 [11:33<02:39,  1.36it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 944/1161 [11:34<02:39,  1.36it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 945/1161 [11:34<02:39,  1.36it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 945/1161 [11:35<02:39,  1.36it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 946/1161 [11:35<02:39,  1.35it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 946/1161 [11:36<02:39,  1.35it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 947/1161 [11:36<02:38,  1.35it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 947/1161 [11:36<02:38,  1.35it/s, training_loss=0.337]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 948/1161 [11:36<02:37,  1.35it/s, training_loss=0.337]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 948/1161 [11:37<02:37,  1.35it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 949/1161 [11:37<02:36,  1.35it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 949/1161 [11:38<02:36,  1.35it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 950/1161 [11:38<02:35,  1.36it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 950/1161 [11:38<02:35,  1.36it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 951/1161 [11:39<02:34,  1.36it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 951/1161 [11:39<02:34,  1.36it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 952/1161 [11:39<02:33,  1.36it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 952/1161 [11:40<02:33,  1.36it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 953/1161 [11:40<02:32,  1.36it/s, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 953/1161 [11:41<02:32,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 954/1161 [11:41<02:31,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 954/1161 [11:41<02:31,  1.36it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 955/1161 [11:41<02:31,  1.36it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 955/1161 [11:42<02:31,  1.36it/s, training_loss=0.308]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 956/1161 [11:42<02:30,  1.36it/s, training_loss=0.308]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 956/1161 [11:43<02:30,  1.36it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 957/1161 [11:43<02:30,  1.36it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 957/1161 [11:44<02:30,  1.36it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 958/1161 [11:44<02:29,  1.36it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 958/1161 [11:44<02:29,  1.36it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 959/1161 [11:44<02:28,  1.36it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 959/1161 [11:45<02:28,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 960/1161 [11:45<02:28,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 960/1161 [11:46<02:28,  1.36it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 961/1161 [11:46<02:27,  1.36it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 961/1161 [11:47<02:27,  1.36it/s, training_loss=0.343]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 962/1161 [11:47<02:26,  1.35it/s, training_loss=0.343]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 962/1161 [11:47<02:26,  1.35it/s, training_loss=0.261]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 963/1161 [11:47<02:26,  1.35it/s, training_loss=0.261]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 963/1161 [11:48<02:26,  1.35it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 964/1161 [11:48<02:25,  1.35it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 964/1161 [11:49<02:25,  1.35it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 965/1161 [11:49<02:23,  1.37it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 965/1161 [11:50<02:23,  1.37it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 966/1161 [11:50<02:23,  1.36it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 966/1161 [11:50<02:23,  1.36it/s, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 967/1161 [11:50<02:22,  1.36it/s, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 967/1161 [11:51<02:22,  1.36it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 968/1161 [11:51<02:21,  1.36it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 968/1161 [11:52<02:21,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 969/1161 [11:52<02:21,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 969/1161 [11:52<02:21,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 970/1161 [11:52<02:20,  1.36it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 970/1161 [11:53<02:20,  1.36it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 971/1161 [11:53<02:19,  1.36it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 971/1161 [11:54<02:19,  1.36it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 972/1161 [11:54<02:19,  1.36it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 972/1161 [11:55<02:19,  1.36it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 973/1161 [11:55<02:18,  1.36it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 973/1161 [11:55<02:18,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 974/1161 [11:55<02:17,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 974/1161 [11:56<02:17,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 975/1161 [11:56<02:16,  1.37it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 975/1161 [11:57<02:16,  1.37it/s, training_loss=0.314]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 976/1161 [11:57<02:15,  1.37it/s, training_loss=0.314]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 976/1161 [11:58<02:15,  1.37it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 977/1161 [11:58<02:14,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 977/1161 [11:58<02:14,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 978/1161 [11:58<02:14,  1.36it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 978/1161 [11:59<02:14,  1.36it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 979/1161 [11:59<02:13,  1.36it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 979/1161 [12:00<02:13,  1.36it/s, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 980/1161 [12:00<02:13,  1.36it/s, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 980/1161 [12:01<02:13,  1.36it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 981/1161 [12:01<02:11,  1.36it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 981/1161 [12:01<02:11,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 982/1161 [12:01<02:11,  1.37it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 982/1161 [12:02<02:11,  1.37it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 983/1161 [12:02<02:10,  1.37it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 983/1161 [12:03<02:10,  1.37it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 984/1161 [12:03<02:10,  1.36it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 984/1161 [12:03<02:10,  1.36it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 985/1161 [12:03<02:09,  1.36it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 985/1161 [12:04<02:09,  1.36it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 986/1161 [12:04<02:08,  1.36it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 986/1161 [12:05<02:08,  1.36it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 987/1161 [12:05<02:08,  1.36it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 987/1161 [12:06<02:08,  1.36it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 988/1161 [12:06<02:07,  1.36it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 988/1161 [12:06<02:07,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 989/1161 [12:06<02:06,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 989/1161 [12:07<02:06,  1.36it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 990/1161 [12:07<02:05,  1.36it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 990/1161 [12:08<02:05,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 991/1161 [12:08<02:05,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 991/1161 [12:09<02:05,  1.36it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 992/1161 [12:09<02:04,  1.35it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 992/1161 [12:09<02:04,  1.35it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 993/1161 [12:09<02:03,  1.36it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 993/1161 [12:10<02:03,  1.36it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 994/1161 [12:10<02:02,  1.36it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 994/1161 [12:11<02:02,  1.36it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 995/1161 [12:11<02:01,  1.36it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 995/1161 [12:12<02:01,  1.36it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 996/1161 [12:12<02:01,  1.36it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 996/1161 [12:12<02:01,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 997/1161 [12:12<02:00,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 997/1161 [12:13<02:00,  1.36it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 998/1161 [12:13<02:00,  1.36it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 998/1161 [12:14<02:00,  1.36it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 999/1161 [12:14<01:58,  1.36it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 999/1161 [12:15<01:58,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1000/1161 [12:15<01:58,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1000/1161 [12:15<01:58,  1.36it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1001/1161 [12:15<01:57,  1.36it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1001/1161 [12:16<01:57,  1.36it/s, training_loss=0.279]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 1002/1161 [12:16<01:57,  1.35it/s, training_loss=0.279]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 1002/1161 [12:17<01:57,  1.35it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 1003/1161 [12:17<01:56,  1.36it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 1003/1161 [12:17<01:56,  1.36it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 1004/1161 [12:17<01:55,  1.36it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 1004/1161 [12:18<01:55,  1.36it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1005/1161 [12:18<01:54,  1.36it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1005/1161 [12:19<01:54,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1006/1161 [12:19<01:53,  1.36it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1006/1161 [12:20<01:53,  1.36it/s, training_loss=0.348]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1007/1161 [12:20<01:52,  1.36it/s, training_loss=0.348]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1007/1161 [12:20<01:52,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1008/1161 [12:20<01:52,  1.36it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1008/1161 [12:21<01:52,  1.36it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1009/1161 [12:21<01:51,  1.36it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1009/1161 [12:22<01:51,  1.36it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1010/1161 [12:22<01:51,  1.36it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1010/1161 [12:23<01:51,  1.36it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1011/1161 [12:23<01:50,  1.36it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1011/1161 [12:23<01:50,  1.36it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1012/1161 [12:23<01:49,  1.36it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1012/1161 [12:24<01:49,  1.36it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1013/1161 [12:24<01:48,  1.37it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1013/1161 [12:25<01:48,  1.37it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1014/1161 [12:25<01:48,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1014/1161 [12:26<01:48,  1.36it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1015/1161 [12:26<01:47,  1.36it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1015/1161 [12:26<01:47,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1016/1161 [12:26<01:46,  1.36it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1016/1161 [12:27<01:46,  1.36it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1017/1161 [12:27<01:45,  1.36it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1017/1161 [12:28<01:45,  1.36it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1018/1161 [12:28<01:44,  1.37it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1018/1161 [12:28<01:44,  1.37it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1019/1161 [12:28<01:44,  1.36it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1019/1161 [12:29<01:44,  1.36it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1020/1161 [12:29<01:43,  1.36it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1020/1161 [12:30<01:43,  1.36it/s, training_loss=0.389]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1021/1161 [12:30<01:42,  1.36it/s, training_loss=0.389]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1021/1161 [12:31<01:42,  1.36it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1022/1161 [12:31<01:42,  1.36it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1022/1161 [12:31<01:42,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1023/1161 [12:31<01:41,  1.36it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1023/1161 [12:32<01:41,  1.36it/s, training_loss=0.348]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1024/1161 [12:32<01:40,  1.36it/s, training_loss=0.348]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1024/1161 [12:33<01:40,  1.36it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1025/1161 [12:33<01:40,  1.36it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1025/1161 [12:34<01:40,  1.36it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1026/1161 [12:34<01:39,  1.36it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1026/1161 [12:34<01:39,  1.36it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1027/1161 [12:34<01:38,  1.36it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1027/1161 [12:35<01:38,  1.36it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 1028/1161 [12:35<01:38,  1.36it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 1028/1161 [12:36<01:38,  1.36it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 1029/1161 [12:36<01:36,  1.36it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 1029/1161 [12:37<01:36,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 1030/1161 [12:37<01:36,  1.36it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 1030/1161 [12:37<01:36,  1.36it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1031/1161 [12:37<01:35,  1.36it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1031/1161 [12:38<01:35,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1032/1161 [12:38<01:34,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1032/1161 [12:39<01:34,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1033/1161 [12:39<01:33,  1.37it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1033/1161 [12:39<01:33,  1.37it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1034/1161 [12:39<01:32,  1.37it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1034/1161 [12:40<01:32,  1.37it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1035/1161 [12:40<01:32,  1.37it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1035/1161 [12:41<01:32,  1.37it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1036/1161 [12:41<01:31,  1.36it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1036/1161 [12:42<01:31,  1.36it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1037/1161 [12:42<01:30,  1.37it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1037/1161 [12:42<01:30,  1.37it/s, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1038/1161 [12:42<01:29,  1.37it/s, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1038/1161 [12:43<01:29,  1.37it/s, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1039/1161 [12:43<01:29,  1.36it/s, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1039/1161 [12:44<01:29,  1.36it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1040/1161 [12:44<01:28,  1.37it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1040/1161 [12:45<01:28,  1.37it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1041/1161 [12:45<01:27,  1.37it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1041/1161 [12:45<01:27,  1.37it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1042/1161 [12:45<01:27,  1.37it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1042/1161 [12:46<01:27,  1.37it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1043/1161 [12:46<01:26,  1.36it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1043/1161 [12:47<01:26,  1.36it/s, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1044/1161 [12:47<01:25,  1.37it/s, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1044/1161 [12:48<01:25,  1.37it/s, training_loss=0.272]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1045/1161 [12:48<01:24,  1.37it/s, training_loss=0.272]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1045/1161 [12:48<01:24,  1.37it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1046/1161 [12:48<01:23,  1.37it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1046/1161 [12:49<01:23,  1.37it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1047/1161 [12:49<01:23,  1.37it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1047/1161 [12:50<01:23,  1.37it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1048/1161 [12:50<01:23,  1.36it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1048/1161 [12:50<01:23,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1049/1161 [12:50<01:22,  1.36it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1049/1161 [12:51<01:22,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1050/1161 [12:51<01:21,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1050/1161 [12:52<01:21,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1051/1161 [12:52<01:20,  1.36it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1051/1161 [12:53<01:20,  1.36it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1052/1161 [12:53<01:20,  1.36it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1052/1161 [12:53<01:20,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1053/1161 [12:53<01:19,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1053/1161 [12:54<01:19,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1054/1161 [12:54<01:18,  1.36it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1054/1161 [12:55<01:18,  1.36it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1055/1161 [12:55<01:17,  1.36it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1055/1161 [12:56<01:17,  1.36it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1056/1161 [12:56<01:17,  1.36it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1056/1161 [12:56<01:17,  1.36it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1057/1161 [12:56<01:16,  1.36it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1057/1161 [12:57<01:16,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1058/1161 [12:57<01:15,  1.36it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1058/1161 [12:58<01:15,  1.36it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1059/1161 [12:58<01:15,  1.36it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1059/1161 [12:59<01:15,  1.36it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 1060/1161 [12:59<01:14,  1.36it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 1060/1161 [12:59<01:14,  1.36it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 1061/1161 [12:59<01:13,  1.36it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 1061/1161 [13:00<01:13,  1.36it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 1062/1161 [13:00<01:12,  1.37it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 1062/1161 [13:01<01:12,  1.37it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1063/1161 [13:01<01:11,  1.37it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1063/1161 [13:01<01:11,  1.37it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1064/1161 [13:01<01:10,  1.37it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1064/1161 [13:02<01:10,  1.37it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1065/1161 [13:02<01:10,  1.36it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1065/1161 [13:03<01:10,  1.36it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1066/1161 [13:03<01:09,  1.37it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1066/1161 [13:04<01:09,  1.37it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1067/1161 [13:04<01:08,  1.37it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1067/1161 [13:04<01:08,  1.37it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1068/1161 [13:04<01:07,  1.37it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1068/1161 [13:05<01:07,  1.37it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1069/1161 [13:05<01:07,  1.37it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1069/1161 [13:06<01:07,  1.37it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1070/1161 [13:06<01:06,  1.37it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1070/1161 [13:07<01:06,  1.37it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1071/1161 [13:07<01:05,  1.37it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1071/1161 [13:07<01:05,  1.37it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1072/1161 [13:07<01:04,  1.37it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1072/1161 [13:08<01:04,  1.37it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1073/1161 [13:08<01:04,  1.37it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1073/1161 [13:09<01:04,  1.37it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1074/1161 [13:09<01:03,  1.36it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1074/1161 [13:10<01:03,  1.36it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1075/1161 [13:10<01:03,  1.36it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1075/1161 [13:10<01:03,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1076/1161 [13:10<01:02,  1.36it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1076/1161 [13:11<01:02,  1.36it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1077/1161 [13:11<01:01,  1.36it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1077/1161 [13:12<01:01,  1.36it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1078/1161 [13:12<01:00,  1.37it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1078/1161 [13:12<01:00,  1.37it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1079/1161 [13:12<00:59,  1.37it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1079/1161 [13:13<00:59,  1.37it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1080/1161 [13:13<00:59,  1.37it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1080/1161 [13:14<00:59,  1.37it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1081/1161 [13:14<00:58,  1.36it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1081/1161 [13:15<00:58,  1.36it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1082/1161 [13:15<00:57,  1.36it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1082/1161 [13:15<00:57,  1.36it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1083/1161 [13:15<00:57,  1.36it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1083/1161 [13:16<00:57,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1084/1161 [13:16<00:56,  1.36it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1084/1161 [13:17<00:56,  1.36it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1085/1161 [13:17<00:55,  1.36it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1085/1161 [13:18<00:55,  1.36it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 1086/1161 [13:18<00:54,  1.37it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 1086/1161 [13:18<00:54,  1.37it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 1087/1161 [13:18<00:54,  1.37it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 1087/1161 [13:19<00:54,  1.37it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 1088/1161 [13:19<00:53,  1.37it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 1088/1161 [13:20<00:53,  1.37it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1089/1161 [13:20<00:52,  1.37it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1089/1161 [13:21<00:52,  1.37it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1090/1161 [13:21<00:51,  1.37it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1090/1161 [13:21<00:51,  1.37it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1091/1161 [13:21<00:51,  1.36it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1091/1161 [13:22<00:51,  1.36it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1092/1161 [13:22<00:50,  1.37it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1092/1161 [13:23<00:50,  1.37it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1093/1161 [13:23<00:49,  1.37it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1093/1161 [13:23<00:49,  1.37it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1094/1161 [13:23<00:49,  1.37it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1094/1161 [13:24<00:49,  1.37it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1095/1161 [13:24<00:48,  1.37it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1095/1161 [13:25<00:48,  1.37it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1096/1161 [13:25<00:47,  1.37it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1096/1161 [13:26<00:47,  1.37it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1097/1161 [13:26<00:46,  1.37it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1097/1161 [13:26<00:46,  1.37it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1098/1161 [13:26<00:46,  1.37it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1098/1161 [13:27<00:46,  1.37it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1099/1161 [13:27<00:45,  1.37it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1099/1161 [13:28<00:45,  1.37it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1100/1161 [13:28<00:44,  1.36it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1100/1161 [13:29<00:44,  1.36it/s, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1101/1161 [13:29<00:44,  1.36it/s, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1101/1161 [13:29<00:44,  1.36it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1102/1161 [13:29<00:43,  1.36it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1102/1161 [13:30<00:43,  1.36it/s, training_loss=0.271]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1103/1161 [13:30<00:42,  1.36it/s, training_loss=0.271]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1103/1161 [13:31<00:42,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1104/1161 [13:31<00:41,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1104/1161 [13:32<00:41,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1105/1161 [13:32<00:41,  1.36it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1105/1161 [13:32<00:41,  1.36it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1106/1161 [13:32<00:40,  1.37it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1106/1161 [13:33<00:40,  1.37it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1107/1161 [13:33<00:39,  1.37it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1107/1161 [13:34<00:39,  1.37it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1108/1161 [13:34<00:38,  1.37it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1108/1161 [13:34<00:38,  1.37it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1109/1161 [13:34<00:38,  1.36it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1109/1161 [13:35<00:38,  1.36it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1110/1161 [13:35<00:37,  1.35it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1110/1161 [13:36<00:37,  1.35it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1111/1161 [13:36<00:37,  1.35it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1111/1161 [13:37<00:37,  1.35it/s, training_loss=0.494]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1112/1161 [13:37<00:36,  1.35it/s, training_loss=0.494]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1112/1161 [13:37<00:36,  1.35it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1113/1161 [13:37<00:35,  1.35it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1113/1161 [13:38<00:35,  1.35it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1114/1161 [13:38<00:34,  1.36it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1114/1161 [13:39<00:34,  1.36it/s, training_loss=0.252]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1115/1161 [13:39<00:33,  1.36it/s, training_loss=0.252]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1115/1161 [13:40<00:33,  1.36it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1116/1161 [13:40<00:33,  1.36it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1116/1161 [13:40<00:33,  1.36it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1117/1161 [13:40<00:32,  1.36it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1117/1161 [13:41<00:32,  1.36it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 1118/1161 [13:41<00:31,  1.37it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 1118/1161 [13:42<00:31,  1.37it/s, training_loss=0.266]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 1119/1161 [13:42<00:30,  1.37it/s, training_loss=0.266]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 1119/1161 [13:43<00:30,  1.37it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 1120/1161 [13:43<00:29,  1.37it/s, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 1120/1161 [13:43<00:29,  1.37it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1121/1161 [13:43<00:29,  1.36it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1121/1161 [13:44<00:29,  1.36it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1122/1161 [13:44<00:28,  1.36it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1122/1161 [13:45<00:28,  1.36it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1123/1161 [13:45<00:28,  1.35it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1123/1161 [13:45<00:28,  1.35it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1124/1161 [13:45<00:27,  1.36it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1124/1161 [13:46<00:27,  1.36it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1125/1161 [13:46<00:26,  1.36it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1125/1161 [13:47<00:26,  1.36it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1126/1161 [13:47<00:25,  1.37it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1126/1161 [13:48<00:25,  1.37it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1127/1161 [13:48<00:24,  1.37it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1127/1161 [13:48<00:24,  1.37it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1128/1161 [13:48<00:24,  1.36it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1128/1161 [13:49<00:24,  1.36it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1129/1161 [13:49<00:23,  1.36it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1129/1161 [13:50<00:23,  1.36it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1130/1161 [13:50<00:22,  1.36it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1130/1161 [13:51<00:22,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1131/1161 [13:51<00:22,  1.36it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1131/1161 [13:51<00:22,  1.36it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1132/1161 [13:51<00:21,  1.35it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1132/1161 [13:52<00:21,  1.35it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1133/1161 [13:52<00:20,  1.35it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1133/1161 [13:53<00:20,  1.35it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1134/1161 [13:53<00:19,  1.36it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1134/1161 [13:54<00:19,  1.36it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1135/1161 [13:54<00:19,  1.36it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1135/1161 [13:54<00:19,  1.36it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1136/1161 [13:54<00:18,  1.35it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1136/1161 [13:55<00:18,  1.35it/s, training_loss=0.299]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1137/1161 [13:55<00:17,  1.36it/s, training_loss=0.299]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1137/1161 [13:56<00:17,  1.36it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1138/1161 [13:56<00:17,  1.34it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1138/1161 [13:57<00:17,  1.34it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1139/1161 [13:57<00:16,  1.35it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1139/1161 [13:57<00:16,  1.35it/s, training_loss=0.373]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1140/1161 [13:57<00:15,  1.35it/s, training_loss=0.373]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1140/1161 [13:58<00:15,  1.35it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1141/1161 [13:58<00:14,  1.35it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1141/1161 [13:59<00:14,  1.35it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1142/1161 [13:59<00:14,  1.35it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1142/1161 [14:00<00:14,  1.35it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1143/1161 [14:00<00:13,  1.35it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1143/1161 [14:00<00:13,  1.35it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 1144/1161 [14:00<00:12,  1.35it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 1144/1161 [14:01<00:12,  1.35it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 1145/1161 [14:01<00:11,  1.36it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 1145/1161 [14:02<00:11,  1.36it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 1146/1161 [14:02<00:11,  1.35it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 1146/1161 [14:02<00:11,  1.35it/s, training_loss=0.390]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1147/1161 [14:02<00:10,  1.35it/s, training_loss=0.390]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1147/1161 [14:03<00:10,  1.35it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1148/1161 [14:03<00:09,  1.35it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1148/1161 [14:04<00:09,  1.35it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1149/1161 [14:04<00:08,  1.35it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1149/1161 [14:05<00:08,  1.35it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1150/1161 [14:05<00:08,  1.35it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1150/1161 [14:05<00:08,  1.35it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1151/1161 [14:05<00:07,  1.36it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1151/1161 [14:06<00:07,  1.36it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1152/1161 [14:06<00:06,  1.35it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1152/1161 [14:07<00:06,  1.35it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1153/1161 [14:07<00:05,  1.35it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1153/1161 [14:08<00:05,  1.35it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1154/1161 [14:08<00:05,  1.35it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1154/1161 [14:08<00:05,  1.35it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1155/1161 [14:08<00:04,  1.35it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1155/1161 [14:09<00:04,  1.35it/s, training_loss=0.290]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1156/1161 [14:09<00:03,  1.36it/s, training_loss=0.290]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1156/1161 [14:10<00:03,  1.36it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1157/1161 [14:10<00:02,  1.35it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1157/1161 [14:11<00:02,  1.35it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1158/1161 [14:11<00:02,  1.35it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1158/1161 [14:11<00:02,  1.35it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1159/1161 [14:11<00:01,  1.36it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1159/1161 [14:12<00:01,  1.36it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1160/1161 [14:12<00:00,  1.35it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1160/1161 [14:13<00:00,  1.35it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2: 100%|██████████| 1161/1161 [14:13<00:00,  1.40it/s, training_loss=0.081]\u001b[A\n",
            " 50%|█████     | 1/2 [30:13<15:58, 958.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2\n",
            "Training loss: 0.4712699044601708\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [31:56<00:00, 958.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5587860437961973\n",
            "F1 Score (Weighted): 0.8090983338169278\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w3LIWQKqF9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21acd382-16ac-4a2f-9414-e7d2021a89e4"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: Yes\n",
            "Accuracy: 2563/2901\n",
            "\n",
            "Class: No\n",
            "Accuracy: 1866/2166\n",
            "\n",
            "Class: In the middle, neither yes nor no\n",
            "Accuracy: 43/128\n",
            "\n",
            "Class: Probably yes / sometimes yes\n",
            "Accuracy: 113/249\n",
            "\n",
            "Class: Probably no\n",
            "Accuracy: 41/232\n",
            "\n",
            "Class: Yes, subject to some conditions\n",
            "Accuracy: 450/516\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rjF9G7VqFPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b46d3a3-1c6c-4fcd-be2f-bec4382cacdc"
      },
      "source": [
        "print('Dev Accuracy:', end = ' ')\n",
        "flat_accuracy(predictions, true_vals)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dev Accuracy: "
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8197674418604651"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_bCLLiLqFDq"
      },
      "source": [
        "encoded_data_test = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='test'].YN_s.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=256, \n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_test = encoded_data_test['input_ids']\n",
        "attention_masks_test = encoded_data_test['attention_mask']\n",
        "labels_test = torch.tensor(df[df.data_type=='test'].strict.values)\n",
        "\n",
        "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "\n",
        "dataloader_test = DataLoader(dataset_test, \n",
        "                                   sampler=SequentialSampler(dataset_test), \n",
        "                                   batch_size=batch_size)\n",
        "\n",
        "test_loss, test_predictions, test_true_vals = evaluate(dataloader_test)\n",
        "test_f1 = f1_score_func(test_predictions, test_true_vals)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AegQA5eE-KqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae67846-5429-4cc0-bc0d-ae2f58903edd"
      },
      "source": [
        "accuracy_per_class(test_predictions, test_true_vals)\n",
        "print('Test Accuracy:', end = ' ')\n",
        "flat_accuracy(test_predictions, test_true_vals)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: Yes\n",
            "Accuracy: 2559/2901\n",
            "\n",
            "Class: No\n",
            "Accuracy: 1857/2166\n",
            "\n",
            "Class: In the middle, neither yes nor no\n",
            "Accuracy: 37/127\n",
            "\n",
            "Class: Probably yes / sometimes yes\n",
            "Accuracy: 108/249\n",
            "\n",
            "Class: Probably no\n",
            "Accuracy: 29/232\n",
            "\n",
            "Class: Yes, subject to some conditions\n",
            "Accuracy: 465/517\n",
            "\n",
            "Test Accuracy: "
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8163759689922481"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S91mcLzu94KP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}