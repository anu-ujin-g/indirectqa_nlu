{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bert_mnli_strict_matched",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6fd2a92bce544f1bbf1fcf0dc107af70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e4c5a5fcb6e4d06b263ddf33f19b5cb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_95d17932a57445449e971659a19ee4c9",
              "IPY_MODEL_31052654fb04444499139e1113bc4248"
            ]
          }
        },
        "8e4c5a5fcb6e4d06b263ddf33f19b5cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95d17932a57445449e971659a19ee4c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9367fa2104124577a9f6af298c1acd5c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_355d11d218354a3f93fdce67e048682e"
          }
        },
        "31052654fb04444499139e1113bc4248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3a55e729e7e84a5bad4dbc9d3e277185",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:02&lt;00:00, 255B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cee0671fc103451eaa7485a0e89ee325"
          }
        },
        "9367fa2104124577a9f6af298c1acd5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "355d11d218354a3f93fdce67e048682e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a55e729e7e84a5bad4dbc9d3e277185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cee0671fc103451eaa7485a0e89ee325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a13c76b1fea44c0f9bb49a9ee1ca246a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_31e04a8668ac4d199c1dd33b34e1e9ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db24165970084c8cb2f41bbce6ee4877",
              "IPY_MODEL_9a884a149b81494a890a0cb5e89acf2d"
            ]
          }
        },
        "31e04a8668ac4d199c1dd33b34e1e9ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db24165970084c8cb2f41bbce6ee4877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c146ab7e87754b5184fbdcc37f43aa77",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b33a21af4b03482c826dd6ef37aff37f"
          }
        },
        "9a884a149b81494a890a0cb5e89acf2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c80736186904b9a9d3a221deea37607",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 191kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db423a6512074fe4894eae6061384ee3"
          }
        },
        "c146ab7e87754b5184fbdcc37f43aa77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b33a21af4b03482c826dd6ef37aff37f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c80736186904b9a9d3a221deea37607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db423a6512074fe4894eae6061384ee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b13fd2a67794e81810b2dffbe7c567c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_326180b7416a43849695412318bd6933",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a627446208741518fe6e0f050f85011",
              "IPY_MODEL_3eacdc12a0f244508551bffd98dcac8b"
            ]
          }
        },
        "326180b7416a43849695412318bd6933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a627446208741518fe6e0f050f85011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_465ae5d300a44a3d92dce962c0fae647",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6793daa6ff04a45b3fa3f2240f68f15"
          }
        },
        "3eacdc12a0f244508551bffd98dcac8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_21e497ac9754444592822bcc0149ea3e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 152B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ea6a70a70f34c55b1231f7078240316"
          }
        },
        "465ae5d300a44a3d92dce962c0fae647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6793daa6ff04a45b3fa3f2240f68f15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21e497ac9754444592822bcc0149ea3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ea6a70a70f34c55b1231f7078240316": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d796b3d4a59846a194583f675ee43463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d20dc351ce074077b5da7c06d4a1c4f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6e9609341caf49789780b7bf06fb1cac",
              "IPY_MODEL_e8dc39b97d664342a38b5951ec3879db"
            ]
          }
        },
        "d20dc351ce074077b5da7c06d4a1c4f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e9609341caf49789780b7bf06fb1cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_72239663d8f146da8c4929ab18028dfe",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 48,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 48,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1fc0d888e4374289b5975527c0edbd22"
          }
        },
        "e8dc39b97d664342a38b5951ec3879db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b73ebaae53184b4a83df33d9d772432d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 48.0/48.0 [00:00&lt;00:00, 641B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_379ad766ff9845cd9a210f0febf4d651"
          }
        },
        "72239663d8f146da8c4929ab18028dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1fc0d888e4374289b5975527c0edbd22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b73ebaae53184b4a83df33d9d772432d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "379ad766ff9845cd9a210f0febf4d651": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0c6fec9a48741e8892ef26cc4f5b750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eeb8b027b60145b19db2a5cc9ea17986",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b6f35b34a6c844a8894ef785c8078517",
              "IPY_MODEL_88aba2268c46421f82e7bde150620212"
            ]
          }
        },
        "eeb8b027b60145b19db2a5cc9ea17986": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6f35b34a6c844a8894ef785c8078517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_09c48fcbd1874b3288184bc943c24882",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fda4c32684154f6999a4b95a16e633cf"
          }
        },
        "88aba2268c46421f82e7bde150620212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3859bb1330f14569b54bc812e45e85e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:01&lt;00:00, 346B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc7723844530453fb452b23d230b4145"
          }
        },
        "09c48fcbd1874b3288184bc943c24882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fda4c32684154f6999a4b95a16e633cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3859bb1330f14569b54bc812e45e85e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc7723844530453fb452b23d230b4145": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8eadcee5979b4bdcbe47ed1eff7e1f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_976de0774b4d4dc28af5fc638aea3f28",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4dd921890c764376a361e8bf6fe8ee3d",
              "IPY_MODEL_99eb0df729074748ac4b5797b02c81fe"
            ]
          }
        },
        "976de0774b4d4dc28af5fc638aea3f28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4dd921890c764376a361e8bf6fe8ee3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_346cd1c62fc64356b1c63835aea69f95",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5521305348f43fb8328a327ae919013"
          }
        },
        "99eb0df729074748ac4b5797b02c81fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f7bee59eb40d4077ba6e1baeedb35344",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:33&lt;00:00, 13.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90df63e55bb94deb8bdb227a6fd344b2"
          }
        },
        "346cd1c62fc64356b1c63835aea69f95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5521305348f43fb8328a327ae919013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7bee59eb40d4077ba6e1baeedb35344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90df63e55bb94deb8bdb227a6fd344b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHPrujng28-7",
        "outputId": "7f94ff2c-f2e9-48f1-d3d9-56916e430947"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HkugCqiD-e9",
        "outputId": "1915402d-1648-4c43-9c38-7fb2150ca488"
      },
      "source": [
        "!pip install transformers==2.5.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 7.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/e3/5e49e9a83fb605aaa34a1c1173e607302fecae529428c28696fb18f1c2c9/tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 11.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 54.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 55.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (3.0.12)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/a5/892ed5d2959b1fdf4f8aaccf96b299e57dd7f06db7072592901fbaa36d79/boto3-1.17.54-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 58.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (1.19.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (7.1.2)\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/50/ac379fa31377f5d316cad8967db9f73c50cd61b80153269bfd7d8b964fc8/s3transfer-0.4.0-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.3MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.54\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/e1/59cc39d22d44e64e96186db87d6e670e2119822d16299e18d0500198abb4/botocore-1.20.54-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 56.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.54->boto3->transformers==2.5.1) (2.8.1)\n",
            "\u001b[31mERROR: botocore 1.20.54 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, jmespath, botocore, s3transfer, boto3, transformers\n",
            "Successfully installed boto3-1.17.54 botocore-1.20.54 jmespath-0.10.0 s3transfer-0.4.0 sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3IdDlBz3ZaK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "# from transformers import AutoTokenizer, BertTokenizer, EvalPrediction, BertPreTrainedModel, BertConfig, BertModel, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV5G9TxitK8X"
      },
      "source": [
        "    import torch\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6PGzfGHq4kZ",
        "outputId": "8f4cd071-45b9-4462-db12-0604cca5a64a"
      },
      "source": [
        "cd '/content/drive/MyDrive/'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9_N6KwgmcXL"
      },
      "source": [
        "## Data pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzL4OXr_ZCZD"
      },
      "source": [
        "Strict-matched"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPj_AqIO4eeI"
      },
      "source": [
        "# circa_og = pd.read_csv('NLU_Project/circa-data.tsv', sep='\\t', index_col='id')\n",
        "circa_og = pd.read_csv('/content/drive/MyDrive/AMBER_TENG_NYU_DRIVE_TO_BROWN/NYU_SPRING2021/NLU/NLU_Project/circa-data.tsv', sep='\\t', index_col='id')\n",
        "circa_r = circa_og.drop(circa_og.loc[circa_og['goldstandard2']=='Other'].index)\n",
        "circa_r = circa_r.drop(circa_r.loc[circa_r['goldstandard2'].isnull()].index)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3zGnD5Vj_GD"
      },
      "source": [
        "# circa_og = pd.read_csv('circa-data.tsv', sep='\\t', index_col='id')\n",
        "circa_og = pd.read_csv('/content/drive/MyDrive/AMBER_TENG_NYU_DRIVE_TO_BROWN/NYU_SPRING2021/NLU/NLU_Project/circa-data.tsv', sep='\\t', index_col='id')\n",
        "circa_s = circa_og.drop(circa_og.loc[circa_og['goldstandard1']=='Other'].index)\n",
        "circa_s = circa_s.drop(circa_s.loc[circa_s['goldstandard1'].isnull()].index)\n",
        "circa_s = circa_s.drop(circa_s.loc[circa_s['goldstandard1']=='I am not sure how X will interpret Y’s answer'].index)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW9QqMAjf7p-"
      },
      "source": [
        "# YN_r = (circa_r['question-X'].map(str)+' '+circa_r['answer-Y']).apply(lambda row: row.strip())\n",
        "# relaxed_labels = circa_r['goldstandard2'].unique()\n",
        "# relaxed_label = circa_r['goldstandard2']\n",
        "# relaxed_dict = {}\n",
        "# for idx, label in enumerate(relaxed_labels):\n",
        "#     relaxed_dict[label] = idx\n",
        "# circa_r['relaxed'] = circa_r.goldstandard2.replace(relaxed_dict)\n",
        "# relaxed = circa_r['relaxed']\n",
        "YN_s = (circa_s['question-X'].map(str)+' '+circa_s['answer-Y']).apply(lambda row: row.strip())\n",
        "strict_labels = circa_s['goldstandard1'].unique()\n",
        "strict_label = circa_s['goldstandard1']\n",
        "strict_dict = {}\n",
        "for idx, label in enumerate(strict_labels):\n",
        "    strict_dict[label] = idx\n",
        "circa_s['strict'] = circa_s.goldstandard1.replace(strict_dict)\n",
        "strict = circa_s['strict']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn0h950hmUU5"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSmxC4gJ4ZE9",
        "outputId": "46ce87ee-c757-4de4-cd38-2fb1af162b72"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeoL9QXBmXR9"
      },
      "source": [
        "### Strict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b6Hm6JElryP"
      },
      "source": [
        "from transformers import PreTrainedModel\n",
        "from transformers import BertConfig, BertModel\n",
        "from transformers.modeling_tf_bert import TFBertForSequenceClassification\n",
        "from transformers import BertForSequenceClassification"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZfGsNNdVfyE"
      },
      "source": [
        "## Model Specs\n",
        "- BERT-MNLI-YN Relaxed learning rate: 5e-5\n",
        "- MNLI learning rate: 2e-5 ; 3 epochs; batch size 16 vs 32 \n",
        "  - https://huggingface.co/ishan/bert-base-uncased-mnli \n",
        "  - The training parameters were kept the same as Devlin et al., 2019 (learning rate = 2e-5, training epochs = 3, max_sequence_len = 128 and batch_size = 32).\n",
        "- BERT-MNLI-YN Strict learning rate: 2e-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jinT4bf1Zyc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313,
          "referenced_widgets": [
            "6fd2a92bce544f1bbf1fcf0dc107af70",
            "8e4c5a5fcb6e4d06b263ddf33f19b5cb",
            "95d17932a57445449e971659a19ee4c9",
            "31052654fb04444499139e1113bc4248",
            "9367fa2104124577a9f6af298c1acd5c",
            "355d11d218354a3f93fdce67e048682e",
            "3a55e729e7e84a5bad4dbc9d3e277185",
            "cee0671fc103451eaa7485a0e89ee325",
            "a13c76b1fea44c0f9bb49a9ee1ca246a",
            "31e04a8668ac4d199c1dd33b34e1e9ea",
            "db24165970084c8cb2f41bbce6ee4877",
            "9a884a149b81494a890a0cb5e89acf2d",
            "c146ab7e87754b5184fbdcc37f43aa77",
            "b33a21af4b03482c826dd6ef37aff37f",
            "6c80736186904b9a9d3a221deea37607",
            "db423a6512074fe4894eae6061384ee3",
            "6b13fd2a67794e81810b2dffbe7c567c",
            "326180b7416a43849695412318bd6933",
            "7a627446208741518fe6e0f050f85011",
            "3eacdc12a0f244508551bffd98dcac8b",
            "465ae5d300a44a3d92dce962c0fae647",
            "b6793daa6ff04a45b3fa3f2240f68f15",
            "21e497ac9754444592822bcc0149ea3e",
            "7ea6a70a70f34c55b1231f7078240316",
            "d796b3d4a59846a194583f675ee43463",
            "d20dc351ce074077b5da7c06d4a1c4f4",
            "6e9609341caf49789780b7bf06fb1cac",
            "e8dc39b97d664342a38b5951ec3879db",
            "72239663d8f146da8c4929ab18028dfe",
            "1fc0d888e4374289b5975527c0edbd22",
            "b73ebaae53184b4a83df33d9d772432d",
            "379ad766ff9845cd9a210f0febf4d651",
            "a0c6fec9a48741e8892ef26cc4f5b750",
            "eeb8b027b60145b19db2a5cc9ea17986",
            "b6f35b34a6c844a8894ef785c8078517",
            "88aba2268c46421f82e7bde150620212",
            "09c48fcbd1874b3288184bc943c24882",
            "fda4c32684154f6999a4b95a16e633cf",
            "3859bb1330f14569b54bc812e45e85e6",
            "bc7723844530453fb452b23d230b4145",
            "8eadcee5979b4bdcbe47ed1eff7e1f4c",
            "976de0774b4d4dc28af5fc638aea3f28",
            "4dd921890c764376a361e8bf6fe8ee3d",
            "99eb0df729074748ac4b5797b02c81fe",
            "346cd1c62fc64356b1c63835aea69f95",
            "c5521305348f43fb8328a327ae919013",
            "f7bee59eb40d4077ba6e1baeedb35344",
            "90df63e55bb94deb8bdb227a6fd344b2"
          ]
        },
        "outputId": "47087699-f324-4a00-e3c2-c7e62eb23410"
      },
      "source": [
        "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\") \n",
        "tokenizer = AutoTokenizer.from_pretrained('ishan/bert-base-uncased-mnli') \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "# device = torch.device(\"cpu\")\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "# model.cuda()\n",
        "model.to(device)\n",
        "\n",
        "learning_rate = 2e-5\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fd2a92bce544f1bbf1fcf0dc107af70",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a13c76b1fea44c0f9bb49a9ee1ca246a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b13fd2a67794e81810b2dffbe7c567c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d796b3d4a59846a194583f675ee43463",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=48.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0c6fec9a48741e8892ef26cc4f5b750",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8eadcee5979b4bdcbe47ed1eff7e1f4c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "TUedR74Kt4_I",
        "outputId": "b93cc8de-509c-47be-a79c-0d589f9fc4af"
      },
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |  428780 KB |  428780 KB |  428780 KB |       0 B  |\\n|       from large pool |  428288 KB |  428288 KB |  428288 KB |       0 B  |\\n|       from small pool |     492 KB |     492 KB |     492 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |  428780 KB |  428780 KB |  428780 KB |       0 B  |\\n|       from large pool |  428288 KB |  428288 KB |  428288 KB |       0 B  |\\n|       from small pool |     492 KB |     492 KB |     492 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |  483328 KB |  483328 KB |  483328 KB |       0 B  |\\n|       from large pool |  481280 KB |  481280 KB |  481280 KB |       0 B  |\\n|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   54547 KB |   54560 KB |  265210 KB |  210662 KB |\\n|       from large pool |   52992 KB |   52992 KB |  263168 KB |  210176 KB |\\n|       from small pool |    1555 KB |    2042 KB |    2042 KB |     486 KB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     201    |     201    |     201    |       0    |\\n|       from large pool |      75    |      75    |      75    |       0    |\\n|       from small pool |     126    |     126    |     126    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     201    |     201    |     201    |       0    |\\n|       from large pool |      75    |      75    |      75    |       0    |\\n|       from small pool |     126    |     126    |     126    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      21    |      21    |      21    |       0    |\\n|       from large pool |      20    |      20    |      20    |       0    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      19    |      19    |      20    |       1    |\\n|       from large pool |      18    |      18    |      19    |       1    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|===========================================================================|\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BjmZLHa7Nne",
        "outputId": "f0530629-5304-40b4-8e4e-2f7e43f67b1c"
      },
      "source": [
        "# max_len = 0\n",
        "# for entry in YN_r.values:\n",
        "#     input_ids = tokenizer.encode(entry,  add_special_tokens=True)\n",
        "#     max_len = max(max_len, len(input_ids))\n",
        "# print(max_len)\n",
        "\n",
        "max_len = 0\n",
        "for entry in YN_s.values:\n",
        "    input_ids = tokenizer.encode(entry,  add_special_tokens=True)\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "print(max_len)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYTos6aPksfw"
      },
      "source": [
        "strict_labels = circa_s['goldstandard1'].unique()\n",
        "strict_label = circa_s['goldstandard1']\n",
        "strict_dict = {}\n",
        "for idx, label in enumerate(strict_labels):\n",
        "    strict_dict[label] = idx\n",
        "circa_s['strict'] = circa_s.goldstandard1.replace(strict_dict)\n",
        "strict = circa_s['strict']\n",
        "\n",
        "YN_s = (circa_s['question-X'].map(str)+' '+circa_s['answer-Y']).apply(lambda row: row.strip())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "Fv5cc_qyWPFS",
        "outputId": "cc5c77a0-ec19-41da-bef9-9d1a336f1bc0"
      },
      "source": [
        "# df = pd.concat([YN_r, relaxed_label, relaxed], axis=1).rename(columns={0:'YN_r'})\n",
        "# df\n",
        "df = pd.concat([YN_s, strict_label, strict], axis=1).rename(columns={0:'YN_s'})\n",
        "df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YN_s</th>\n",
              "      <th>goldstandard1</th>\n",
              "      <th>strict</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Are you employed? I'm a veterinary technician.</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are you a fan of Korean food? I wouldn't say so</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Are you bringing any pets into the flat? I do ...</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Would you like to get some fresh air in your f...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Is your family still living in the neighborhoo...</td>\n",
              "      <td>In the middle, neither yes nor no</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34263</th>\n",
              "      <td>Do you like to drink? I am in AA.</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34264</th>\n",
              "      <td>Do you like pie? My favorite pie is pecan.</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34265</th>\n",
              "      <td>Want to go to a concert with me? I'd rather do...</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34266</th>\n",
              "      <td>Do you like hip/hop music? I can't dance to hi...</td>\n",
              "      <td>Probably no</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34267</th>\n",
              "      <td>Do you see yourself raising a family in New Yo...</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30958 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    YN_s  ... strict\n",
              "id                                                        ...       \n",
              "0         Are you employed? I'm a veterinary technician.  ...      0\n",
              "1        Are you a fan of Korean food? I wouldn't say so  ...      1\n",
              "2      Are you bringing any pets into the flat? I do ...  ...      1\n",
              "3      Would you like to get some fresh air in your f...  ...      0\n",
              "4      Is your family still living in the neighborhoo...  ...      2\n",
              "...                                                  ...  ...    ...\n",
              "34263                  Do you like to drink? I am in AA.  ...      1\n",
              "34264         Do you like pie? My favorite pie is pecan.  ...      0\n",
              "34265  Want to go to a concert with me? I'd rather do...  ...      1\n",
              "34266  Do you like hip/hop music? I can't dance to hi...  ...      4\n",
              "34267  Do you see yourself raising a family in New Yo...  ...      1\n",
              "\n",
              "[30958 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulXaXpJiVrcT"
      },
      "source": [
        "# train_relaxed, val_relaxed, trainy_relaxed, valy_relaxed = train_test_split(df.index.values, df.relaxed.values, test_size=.4, stratify=df.relaxed.values)\n",
        "# test_relaxed, dev_relaxed, testy_relaxed, devy_relaxed = train_test_split(val_relaxed, valy_relaxed, test_size=.5, stratify=valy_relaxed)\n",
        "\n",
        "train_strict, val_strict, trainy_strict, valy_strict = train_test_split(df.index.values, df.strict.values, test_size=.4, stratify=df.strict.values)\n",
        "test_strict, dev_strict, testy_strict, devy_strict = train_test_split(val_strict, valy_strict, test_size=.5, stratify=valy_strict)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O06VmOd-VrWL"
      },
      "source": [
        "# df['data_type'] = ['not_set']*df.shape[0]\n",
        "# df.loc[train_relaxed,'data_type'] = 'train'\n",
        "# df.loc[dev_relaxed,'data_type'] = 'dev'\n",
        "# df.loc[test_relaxed,'data_type'] = 'test'\n",
        "\n",
        "df['data_type'] = ['not_set']*df.shape[0]\n",
        "df.loc[train_strict,'data_type'] = 'train'\n",
        "df.loc[dev_strict,'data_type'] = 'dev'\n",
        "df.loc[test_strict,'data_type'] = 'test'"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "roLxfOJAVdt_",
        "outputId": "7a168185-09ac-41eb-be44-414a4993fdc6"
      },
      "source": [
        "# df.groupby(['goldstandard2','relaxed','data_type']).count()\n",
        "\n",
        "df.groupby(['goldstandard1','strict','data_type']).count()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>YN_s</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goldstandard1</th>\n",
              "      <th>strict</th>\n",
              "      <th>data_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">In the middle, neither yes nor no</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
              "      <th>dev</th>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">No</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
              "      <th>dev</th>\n",
              "      <td>2166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>2166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>6497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">Probably no</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">4</th>\n",
              "      <th>dev</th>\n",
              "      <td>232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">Probably yes / sometimes yes</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
              "      <th>dev</th>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">Yes</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
              "      <th>dev</th>\n",
              "      <td>2901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>2901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>8702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">Yes, subject to some conditions</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
              "      <th>dev</th>\n",
              "      <td>517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>1550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    YN_s\n",
              "goldstandard1                     strict data_type      \n",
              "In the middle, neither yes nor no 2      dev         127\n",
              "                                         test        128\n",
              "                                         train       383\n",
              "No                                1      dev        2166\n",
              "                                         test       2166\n",
              "                                         train      6497\n",
              "Probably no                       4      dev         232\n",
              "                                         test        232\n",
              "                                         train       696\n",
              "Probably yes / sometimes yes      3      dev         249\n",
              "                                         test        249\n",
              "                                         train       746\n",
              "Yes                               0      dev        2901\n",
              "                                         test       2901\n",
              "                                         train      8702\n",
              "Yes, subject to some conditions   5      dev         517\n",
              "                                         test        516\n",
              "                                         train      1550"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCQzgsZpYb7k"
      },
      "source": [
        "# encoded_data_train = tokenizer.batch_encode_plus(\n",
        "#     df[df.data_type=='train'].YN_r.values, \n",
        "#     add_special_tokens=True, \n",
        "#     return_attention_mask=True, \n",
        "#     pad_to_max_length=True, \n",
        "#     max_length=256, \n",
        "#     return_tensors='pt'\n",
        "# )\n",
        "\n",
        "# encoded_data_dev = tokenizer.batch_encode_plus(\n",
        "#     df[df.data_type=='dev'].YN_r.values, \n",
        "#     add_special_tokens=True, \n",
        "#     return_attention_mask=True, \n",
        "#     pad_to_max_length=True, \n",
        "#     max_length=256, \n",
        "#     return_tensors='pt'\n",
        "# )\n",
        "\n",
        "\n",
        "# input_ids_train = encoded_data_train['input_ids']\n",
        "# attention_masks_train = encoded_data_train['attention_mask']\n",
        "# labels_train = torch.tensor(df[df.data_type=='train'].relaxed.values)\n",
        "\n",
        "# input_ids_dev = encoded_data_dev['input_ids']\n",
        "# attention_masks_dev = encoded_data_dev['attention_mask']\n",
        "# labels_dev = torch.tensor(df[df.data_type=='dev'].relaxed.values)\n",
        "\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='train'].YN_s.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=256, \n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_dev = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='dev'].YN_s.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=256, \n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df[df.data_type=='train'].strict.values)\n",
        "\n",
        "input_ids_dev = encoded_data_dev['input_ids']\n",
        "attention_masks_dev = encoded_data_dev['attention_mask']\n",
        "labels_dev = torch.tensor(df[df.data_type=='dev'].strict.values)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlIrCldCnh-E"
      },
      "source": [
        "# encoded_data_train\n",
        "# input_ids_train\n",
        "# attention_masks_dev\n",
        "# labels_dev  "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITsWnPAoYb1B"
      },
      "source": [
        "# dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "# dataset_dev = TensorDataset(input_ids_dev, attention_masks_dev, labels_dev)\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_dev = TensorDataset(input_ids_dev, attention_masks_dev, labels_dev)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxXgN_qkYboP",
        "outputId": "8f41be6e-89a2-447c-dea4-02b5d5b7f4c0"
      },
      "source": [
        "len(dataset_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18574"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9wyJZKyoSvl",
        "outputId": "4b678ea3-2864-498d-bf8f-c7cea7e79dad"
      },
      "source": [
        "# model\n",
        "# relaxed_dict\n",
        "len(strict_dict)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Awf4-kru0Rb0",
        "outputId": "70b81aa0-9f9e-4b03-9895-1dd56933117e"
      },
      "source": [
        "model.classifier"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=768, out_features=3, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH9pv41v0b-I"
      },
      "source": [
        "# model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBGmxeLQYbh2",
        "outputId": "7da07300-a36c-444c-f690-f082f3a23d62"
      },
      "source": [
        "# model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "#                                                       num_labels=len(relaxed_dict),\n",
        "#                                                       output_attentions=False,\n",
        "#                                                       output_hidden_states=False)\n",
        "\n",
        "# model = BertForSequenceClassification.from_pretrained('ishan/bert-base-uncased-mnli',\n",
        "#                                                       num_labels=4,\n",
        "#                                                       # num_labels=len(relaxed_dict),\n",
        "#                                                       output_attentions=False,\n",
        "#                                                       output_hidden_states=False)\n",
        "model.classifier = torch.nn.Linear(model.classifier.in_features, 6)\n",
        "model.num_labels = 6\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
        "model.to(device)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f4D3pbiYbd9"
      },
      "source": [
        "batch_size = 32\n",
        "# batch_size = 16\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, \n",
        "                              sampler=RandomSampler(dataset_train), \n",
        "                              batch_size=batch_size)\n",
        "\n",
        "dataloader_validation = DataLoader(dataset_dev, \n",
        "                                   sampler=SequentialSampler(dataset_dev), \n",
        "                                   batch_size=batch_size)\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9mezaQuZtMn"
      },
      "source": [
        "epochs = 3\n",
        "# epochs = 2\n",
        "total_steps = len(dataloader_train) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3mrMRzuZtF5"
      },
      "source": [
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in strict_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98gXVUdIZs_F"
      },
      "source": [
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8O6SdezZs7E",
        "outputId": "941b692f-5fe2-40a0-f9c6-5588844ed692"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaOGmI3KZszz"
      },
      "source": [
        "\n",
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in dataloader_val:\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IquyMsgoZstF",
        "outputId": "e676c513-950a-4733-f0ca-f2a2020ca0d9"
      },
      "source": [
        "\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    loss_train_total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        model.zero_grad()\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }       \n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "         \n",
        "        \n",
        "    torch.save(model.state_dict(), f'finetuned_BERT_epoch_{epoch}.model')\n",
        "        \n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    dev_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
        "    dev_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {dev_loss}')\n",
        "    tqdm.write(f'F1 Score (Weighted): {dev_f1}')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 0/581 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Epoch 1:   0%|          | 0/581 [00:01<?, ?it/s, training_loss=0.755]\u001b[A\n",
            "Epoch 1:   0%|          | 1/581 [00:01<14:31,  1.50s/it, training_loss=0.755]\u001b[A\n",
            "Epoch 1:   0%|          | 1/581 [00:02<14:31,  1.50s/it, training_loss=0.681]\u001b[A\n",
            "Epoch 1:   0%|          | 2/581 [00:02<13:53,  1.44s/it, training_loss=0.681]\u001b[A\n",
            "Epoch 1:   0%|          | 2/581 [00:04<13:53,  1.44s/it, training_loss=0.618]\u001b[A\n",
            "Epoch 1:   1%|          | 3/581 [00:04<13:27,  1.40s/it, training_loss=0.618]\u001b[A\n",
            "Epoch 1:   1%|          | 3/581 [00:05<13:27,  1.40s/it, training_loss=0.650]\u001b[A\n",
            "Epoch 1:   1%|          | 4/581 [00:05<13:09,  1.37s/it, training_loss=0.650]\u001b[A\n",
            "Epoch 1:   1%|          | 4/581 [00:06<13:09,  1.37s/it, training_loss=0.613]\u001b[A\n",
            "Epoch 1:   1%|          | 5/581 [00:06<12:56,  1.35s/it, training_loss=0.613]\u001b[A\n",
            "Epoch 1:   1%|          | 5/581 [00:07<12:56,  1.35s/it, training_loss=0.587]\u001b[A\n",
            "Epoch 1:   1%|          | 6/581 [00:07<12:46,  1.33s/it, training_loss=0.587]\u001b[A\n",
            "Epoch 1:   1%|          | 6/581 [00:09<12:46,  1.33s/it, training_loss=0.566]\u001b[A\n",
            "Epoch 1:   1%|          | 7/581 [00:09<12:42,  1.33s/it, training_loss=0.566]\u001b[A\n",
            "Epoch 1:   1%|          | 7/581 [00:10<12:42,  1.33s/it, training_loss=0.526]\u001b[A\n",
            "Epoch 1:   1%|▏         | 8/581 [00:10<12:37,  1.32s/it, training_loss=0.526]\u001b[A\n",
            "Epoch 1:   1%|▏         | 8/581 [00:11<12:37,  1.32s/it, training_loss=0.527]\u001b[A\n",
            "Epoch 1:   2%|▏         | 9/581 [00:11<12:33,  1.32s/it, training_loss=0.527]\u001b[A\n",
            "Epoch 1:   2%|▏         | 9/581 [00:13<12:33,  1.32s/it, training_loss=0.509]\u001b[A\n",
            "Epoch 1:   2%|▏         | 10/581 [00:13<12:31,  1.32s/it, training_loss=0.509]\u001b[A\n",
            "Epoch 1:   2%|▏         | 10/581 [00:14<12:31,  1.32s/it, training_loss=0.513]\u001b[A\n",
            "Epoch 1:   2%|▏         | 11/581 [00:14<12:29,  1.31s/it, training_loss=0.513]\u001b[A\n",
            "Epoch 1:   2%|▏         | 11/581 [00:15<12:29,  1.31s/it, training_loss=0.510]\u001b[A\n",
            "Epoch 1:   2%|▏         | 12/581 [00:15<12:29,  1.32s/it, training_loss=0.510]\u001b[A\n",
            "Epoch 1:   2%|▏         | 12/581 [00:17<12:29,  1.32s/it, training_loss=0.472]\u001b[A\n",
            "Epoch 1:   2%|▏         | 13/581 [00:17<12:28,  1.32s/it, training_loss=0.472]\u001b[A\n",
            "Epoch 1:   2%|▏         | 13/581 [00:18<12:28,  1.32s/it, training_loss=0.432]\u001b[A\n",
            "Epoch 1:   2%|▏         | 14/581 [00:18<12:27,  1.32s/it, training_loss=0.432]\u001b[A\n",
            "Epoch 1:   2%|▏         | 14/581 [00:19<12:27,  1.32s/it, training_loss=0.436]\u001b[A\n",
            "Epoch 1:   3%|▎         | 15/581 [00:19<12:27,  1.32s/it, training_loss=0.436]\u001b[A\n",
            "Epoch 1:   3%|▎         | 15/581 [00:21<12:27,  1.32s/it, training_loss=0.442]\u001b[A\n",
            "Epoch 1:   3%|▎         | 16/581 [00:21<12:28,  1.32s/it, training_loss=0.442]\u001b[A\n",
            "Epoch 1:   3%|▎         | 16/581 [00:22<12:28,  1.32s/it, training_loss=0.464]\u001b[A\n",
            "Epoch 1:   3%|▎         | 17/581 [00:22<12:29,  1.33s/it, training_loss=0.464]\u001b[A\n",
            "Epoch 1:   3%|▎         | 17/581 [00:23<12:29,  1.33s/it, training_loss=0.438]\u001b[A\n",
            "Epoch 1:   3%|▎         | 18/581 [00:23<12:28,  1.33s/it, training_loss=0.438]\u001b[A\n",
            "Epoch 1:   3%|▎         | 18/581 [00:25<12:28,  1.33s/it, training_loss=0.434]\u001b[A\n",
            "Epoch 1:   3%|▎         | 19/581 [00:25<12:29,  1.33s/it, training_loss=0.434]\u001b[A\n",
            "Epoch 1:   3%|▎         | 19/581 [00:26<12:29,  1.33s/it, training_loss=0.420]\u001b[A\n",
            "Epoch 1:   3%|▎         | 20/581 [00:26<12:28,  1.33s/it, training_loss=0.420]\u001b[A\n",
            "Epoch 1:   3%|▎         | 20/581 [00:27<12:28,  1.33s/it, training_loss=0.436]\u001b[A\n",
            "Epoch 1:   4%|▎         | 21/581 [00:27<12:28,  1.34s/it, training_loss=0.436]\u001b[A\n",
            "Epoch 1:   4%|▎         | 21/581 [00:29<12:28,  1.34s/it, training_loss=0.404]\u001b[A\n",
            "Epoch 1:   4%|▍         | 22/581 [00:29<12:29,  1.34s/it, training_loss=0.404]\u001b[A\n",
            "Epoch 1:   4%|▍         | 22/581 [00:30<12:29,  1.34s/it, training_loss=0.394]\u001b[A\n",
            "Epoch 1:   4%|▍         | 23/581 [00:30<12:30,  1.35s/it, training_loss=0.394]\u001b[A\n",
            "Epoch 1:   4%|▍         | 23/581 [00:31<12:30,  1.35s/it, training_loss=0.428]\u001b[A\n",
            "Epoch 1:   4%|▍         | 24/581 [00:31<12:33,  1.35s/it, training_loss=0.428]\u001b[A\n",
            "Epoch 1:   4%|▍         | 24/581 [00:33<12:33,  1.35s/it, training_loss=0.411]\u001b[A\n",
            "Epoch 1:   4%|▍         | 25/581 [00:33<12:33,  1.35s/it, training_loss=0.411]\u001b[A\n",
            "Epoch 1:   4%|▍         | 25/581 [00:34<12:33,  1.35s/it, training_loss=0.494]\u001b[A\n",
            "Epoch 1:   4%|▍         | 26/581 [00:34<12:31,  1.35s/it, training_loss=0.494]\u001b[A\n",
            "Epoch 1:   4%|▍         | 26/581 [00:36<12:31,  1.35s/it, training_loss=0.394]\u001b[A\n",
            "Epoch 1:   5%|▍         | 27/581 [00:36<12:32,  1.36s/it, training_loss=0.394]\u001b[A\n",
            "Epoch 1:   5%|▍         | 27/581 [00:37<12:32,  1.36s/it, training_loss=0.363]\u001b[A\n",
            "Epoch 1:   5%|▍         | 28/581 [00:37<12:33,  1.36s/it, training_loss=0.363]\u001b[A\n",
            "Epoch 1:   5%|▍         | 28/581 [00:38<12:33,  1.36s/it, training_loss=0.442]\u001b[A\n",
            "Epoch 1:   5%|▍         | 29/581 [00:38<12:33,  1.37s/it, training_loss=0.442]\u001b[A\n",
            "Epoch 1:   5%|▍         | 29/581 [00:40<12:33,  1.37s/it, training_loss=0.463]\u001b[A\n",
            "Epoch 1:   5%|▌         | 30/581 [00:40<12:31,  1.36s/it, training_loss=0.463]\u001b[A\n",
            "Epoch 1:   5%|▌         | 30/581 [00:41<12:31,  1.36s/it, training_loss=0.404]\u001b[A\n",
            "Epoch 1:   5%|▌         | 31/581 [00:41<12:33,  1.37s/it, training_loss=0.404]\u001b[A\n",
            "Epoch 1:   5%|▌         | 31/581 [00:42<12:33,  1.37s/it, training_loss=0.414]\u001b[A\n",
            "Epoch 1:   6%|▌         | 32/581 [00:42<12:33,  1.37s/it, training_loss=0.414]\u001b[A\n",
            "Epoch 1:   6%|▌         | 32/581 [00:44<12:33,  1.37s/it, training_loss=0.414]\u001b[A\n",
            "Epoch 1:   6%|▌         | 33/581 [00:44<12:33,  1.38s/it, training_loss=0.414]\u001b[A\n",
            "Epoch 1:   6%|▌         | 33/581 [00:45<12:33,  1.38s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:   6%|▌         | 34/581 [00:45<12:34,  1.38s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:   6%|▌         | 34/581 [00:47<12:34,  1.38s/it, training_loss=0.390]\u001b[A\n",
            "Epoch 1:   6%|▌         | 35/581 [00:47<12:34,  1.38s/it, training_loss=0.390]\u001b[A\n",
            "Epoch 1:   6%|▌         | 35/581 [00:48<12:34,  1.38s/it, training_loss=0.384]\u001b[A\n",
            "Epoch 1:   6%|▌         | 36/581 [00:48<12:34,  1.38s/it, training_loss=0.384]\u001b[A\n",
            "Epoch 1:   6%|▌         | 36/581 [00:49<12:34,  1.38s/it, training_loss=0.380]\u001b[A\n",
            "Epoch 1:   6%|▋         | 37/581 [00:49<12:33,  1.38s/it, training_loss=0.380]\u001b[A\n",
            "Epoch 1:   6%|▋         | 37/581 [00:51<12:33,  1.38s/it, training_loss=0.349]\u001b[A\n",
            "Epoch 1:   7%|▋         | 38/581 [00:51<12:33,  1.39s/it, training_loss=0.349]\u001b[A\n",
            "Epoch 1:   7%|▋         | 38/581 [00:52<12:33,  1.39s/it, training_loss=0.409]\u001b[A\n",
            "Epoch 1:   7%|▋         | 39/581 [00:52<12:32,  1.39s/it, training_loss=0.409]\u001b[A\n",
            "Epoch 1:   7%|▋         | 39/581 [00:53<12:32,  1.39s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:   7%|▋         | 40/581 [00:53<12:29,  1.39s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:   7%|▋         | 40/581 [00:55<12:29,  1.39s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 1:   7%|▋         | 41/581 [00:55<12:26,  1.38s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 1:   7%|▋         | 41/581 [00:56<12:26,  1.38s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:   7%|▋         | 42/581 [00:56<12:23,  1.38s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:   7%|▋         | 42/581 [00:58<12:23,  1.38s/it, training_loss=0.413]\u001b[A\n",
            "Epoch 1:   7%|▋         | 43/581 [00:58<12:20,  1.38s/it, training_loss=0.413]\u001b[A\n",
            "Epoch 1:   7%|▋         | 43/581 [00:59<12:20,  1.38s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:   8%|▊         | 44/581 [00:59<12:17,  1.37s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:   8%|▊         | 44/581 [01:00<12:17,  1.37s/it, training_loss=0.369]\u001b[A\n",
            "Epoch 1:   8%|▊         | 45/581 [01:00<12:14,  1.37s/it, training_loss=0.369]\u001b[A\n",
            "Epoch 1:   8%|▊         | 45/581 [01:02<12:14,  1.37s/it, training_loss=0.363]\u001b[A\n",
            "Epoch 1:   8%|▊         | 46/581 [01:02<12:12,  1.37s/it, training_loss=0.363]\u001b[A\n",
            "Epoch 1:   8%|▊         | 46/581 [01:03<12:12,  1.37s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:   8%|▊         | 47/581 [01:03<12:07,  1.36s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:   8%|▊         | 47/581 [01:04<12:07,  1.36s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:   8%|▊         | 48/581 [01:04<12:05,  1.36s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:   8%|▊         | 48/581 [01:06<12:05,  1.36s/it, training_loss=0.434]\u001b[A\n",
            "Epoch 1:   8%|▊         | 49/581 [01:06<11:59,  1.35s/it, training_loss=0.434]\u001b[A\n",
            "Epoch 1:   8%|▊         | 49/581 [01:07<11:59,  1.35s/it, training_loss=0.373]\u001b[A\n",
            "Epoch 1:   9%|▊         | 50/581 [01:07<11:58,  1.35s/it, training_loss=0.373]\u001b[A\n",
            "Epoch 1:   9%|▊         | 50/581 [01:08<11:58,  1.35s/it, training_loss=0.408]\u001b[A\n",
            "Epoch 1:   9%|▉         | 51/581 [01:08<11:56,  1.35s/it, training_loss=0.408]\u001b[A\n",
            "Epoch 1:   9%|▉         | 51/581 [01:10<11:56,  1.35s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:   9%|▉         | 52/581 [01:10<11:52,  1.35s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:   9%|▉         | 52/581 [01:11<11:52,  1.35s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:   9%|▉         | 53/581 [01:11<11:49,  1.34s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:   9%|▉         | 53/581 [01:12<11:49,  1.34s/it, training_loss=0.386]\u001b[A\n",
            "Epoch 1:   9%|▉         | 54/581 [01:12<11:48,  1.35s/it, training_loss=0.386]\u001b[A\n",
            "Epoch 1:   9%|▉         | 54/581 [01:14<11:48,  1.35s/it, training_loss=0.338]\u001b[A\n",
            "Epoch 1:   9%|▉         | 55/581 [01:14<11:45,  1.34s/it, training_loss=0.338]\u001b[A\n",
            "Epoch 1:   9%|▉         | 55/581 [01:15<11:45,  1.34s/it, training_loss=0.407]\u001b[A\n",
            "Epoch 1:  10%|▉         | 56/581 [01:15<11:44,  1.34s/it, training_loss=0.407]\u001b[A\n",
            "Epoch 1:  10%|▉         | 56/581 [01:16<11:44,  1.34s/it, training_loss=0.412]\u001b[A\n",
            "Epoch 1:  10%|▉         | 57/581 [01:16<11:42,  1.34s/it, training_loss=0.412]\u001b[A\n",
            "Epoch 1:  10%|▉         | 57/581 [01:18<11:42,  1.34s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  10%|▉         | 58/581 [01:18<11:41,  1.34s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  10%|▉         | 58/581 [01:19<11:41,  1.34s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  10%|█         | 59/581 [01:19<11:39,  1.34s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  10%|█         | 59/581 [01:20<11:39,  1.34s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  10%|█         | 60/581 [01:20<11:37,  1.34s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  10%|█         | 60/581 [01:22<11:37,  1.34s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  10%|█         | 61/581 [01:22<11:35,  1.34s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  10%|█         | 61/581 [01:23<11:35,  1.34s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  11%|█         | 62/581 [01:23<11:31,  1.33s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  11%|█         | 62/581 [01:24<11:31,  1.33s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 1:  11%|█         | 63/581 [01:24<11:30,  1.33s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 1:  11%|█         | 63/581 [01:26<11:30,  1.33s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  11%|█         | 64/581 [01:26<11:29,  1.33s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  11%|█         | 64/581 [01:27<11:29,  1.33s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  11%|█         | 65/581 [01:27<11:26,  1.33s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  11%|█         | 65/581 [01:28<11:26,  1.33s/it, training_loss=0.350]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 66/581 [01:28<11:25,  1.33s/it, training_loss=0.350]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 66/581 [01:30<11:25,  1.33s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 67/581 [01:30<11:25,  1.33s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 67/581 [01:31<11:25,  1.33s/it, training_loss=0.385]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 68/581 [01:31<11:23,  1.33s/it, training_loss=0.385]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 68/581 [01:32<11:23,  1.33s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 69/581 [01:32<11:22,  1.33s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 69/581 [01:34<11:22,  1.33s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 70/581 [01:34<11:22,  1.34s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 70/581 [01:35<11:22,  1.34s/it, training_loss=0.418]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 71/581 [01:35<11:21,  1.34s/it, training_loss=0.418]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 71/581 [01:36<11:21,  1.34s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 72/581 [01:36<11:21,  1.34s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 72/581 [01:38<11:21,  1.34s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 73/581 [01:38<11:20,  1.34s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 73/581 [01:39<11:20,  1.34s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 74/581 [01:39<11:19,  1.34s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 74/581 [01:41<11:19,  1.34s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 75/581 [01:41<11:17,  1.34s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 75/581 [01:42<11:17,  1.34s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 76/581 [01:42<11:15,  1.34s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 76/581 [01:43<11:15,  1.34s/it, training_loss=0.409]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 77/581 [01:43<11:14,  1.34s/it, training_loss=0.409]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 77/581 [01:45<11:14,  1.34s/it, training_loss=0.413]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 78/581 [01:45<11:13,  1.34s/it, training_loss=0.413]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 78/581 [01:46<11:13,  1.34s/it, training_loss=0.338]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 79/581 [01:46<11:13,  1.34s/it, training_loss=0.338]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 79/581 [01:47<11:13,  1.34s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 80/581 [01:47<11:12,  1.34s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 80/581 [01:49<11:12,  1.34s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 81/581 [01:49<11:12,  1.34s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 81/581 [01:50<11:12,  1.34s/it, training_loss=0.412]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 82/581 [01:50<11:10,  1.34s/it, training_loss=0.412]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 82/581 [01:51<11:10,  1.34s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 83/581 [01:51<11:08,  1.34s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 83/581 [01:53<11:08,  1.34s/it, training_loss=0.377]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 84/581 [01:53<11:08,  1.35s/it, training_loss=0.377]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 84/581 [01:54<11:08,  1.35s/it, training_loss=0.464]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 85/581 [01:54<11:06,  1.34s/it, training_loss=0.464]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 85/581 [01:55<11:06,  1.34s/it, training_loss=0.373]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 86/581 [01:55<11:06,  1.35s/it, training_loss=0.373]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 86/581 [01:57<11:06,  1.35s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 87/581 [01:57<11:05,  1.35s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 87/581 [01:58<11:05,  1.35s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 88/581 [01:58<11:03,  1.35s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 88/581 [01:59<11:03,  1.35s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 89/581 [01:59<11:03,  1.35s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 89/581 [02:01<11:03,  1.35s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 90/581 [02:01<11:03,  1.35s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 90/581 [02:02<11:03,  1.35s/it, training_loss=0.344]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 91/581 [02:02<11:01,  1.35s/it, training_loss=0.344]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 91/581 [02:03<11:01,  1.35s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 92/581 [02:03<11:00,  1.35s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 92/581 [02:05<11:00,  1.35s/it, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 93/581 [02:05<10:59,  1.35s/it, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 93/581 [02:06<10:59,  1.35s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 94/581 [02:06<10:58,  1.35s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 94/581 [02:07<10:58,  1.35s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 95/581 [02:07<10:57,  1.35s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 95/581 [02:09<10:57,  1.35s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 96/581 [02:09<10:56,  1.35s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 96/581 [02:10<10:56,  1.35s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 97/581 [02:10<10:54,  1.35s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 97/581 [02:12<10:54,  1.35s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 98/581 [02:12<10:54,  1.36s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 98/581 [02:13<10:54,  1.36s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 99/581 [02:13<10:53,  1.36s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 99/581 [02:14<10:53,  1.36s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 100/581 [02:14<10:52,  1.36s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 100/581 [02:16<10:52,  1.36s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 101/581 [02:16<10:50,  1.36s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 101/581 [02:17<10:50,  1.36s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 102/581 [02:17<10:50,  1.36s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 102/581 [02:18<10:50,  1.36s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 103/581 [02:18<10:48,  1.36s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 103/581 [02:20<10:48,  1.36s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 104/581 [02:20<10:46,  1.36s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 104/581 [02:21<10:46,  1.36s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 105/581 [02:21<10:46,  1.36s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 105/581 [02:22<10:46,  1.36s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 106/581 [02:22<10:44,  1.36s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 106/581 [02:24<10:44,  1.36s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 107/581 [02:24<10:42,  1.36s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 107/581 [02:25<10:42,  1.36s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 108/581 [02:25<10:41,  1.36s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 108/581 [02:26<10:41,  1.36s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 109/581 [02:26<10:39,  1.36s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 109/581 [02:28<10:39,  1.36s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 110/581 [02:28<10:36,  1.35s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 110/581 [02:29<10:36,  1.35s/it, training_loss=0.395]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 111/581 [02:29<10:34,  1.35s/it, training_loss=0.395]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 111/581 [02:30<10:34,  1.35s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 112/581 [02:30<10:33,  1.35s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 112/581 [02:32<10:33,  1.35s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 113/581 [02:32<10:30,  1.35s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 113/581 [02:33<10:30,  1.35s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 114/581 [02:33<10:28,  1.35s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 114/581 [02:35<10:28,  1.35s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 115/581 [02:35<10:26,  1.35s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 115/581 [02:36<10:26,  1.35s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 116/581 [02:36<10:25,  1.35s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 116/581 [02:37<10:25,  1.35s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  20%|██        | 117/581 [02:37<10:22,  1.34s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  20%|██        | 117/581 [02:39<10:22,  1.34s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  20%|██        | 118/581 [02:39<10:21,  1.34s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  20%|██        | 118/581 [02:40<10:21,  1.34s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  20%|██        | 119/581 [02:40<10:20,  1.34s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  20%|██        | 119/581 [02:41<10:20,  1.34s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  21%|██        | 120/581 [02:41<10:19,  1.34s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  21%|██        | 120/581 [02:43<10:19,  1.34s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  21%|██        | 121/581 [02:43<10:18,  1.34s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  21%|██        | 121/581 [02:44<10:18,  1.34s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  21%|██        | 122/581 [02:44<10:16,  1.34s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  21%|██        | 122/581 [02:45<10:16,  1.34s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  21%|██        | 123/581 [02:45<10:14,  1.34s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  21%|██        | 123/581 [02:47<10:14,  1.34s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 124/581 [02:47<10:12,  1.34s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 124/581 [02:48<10:12,  1.34s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 125/581 [02:48<10:10,  1.34s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 125/581 [02:49<10:10,  1.34s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 126/581 [02:49<10:09,  1.34s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 126/581 [02:51<10:09,  1.34s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 127/581 [02:51<10:08,  1.34s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 127/581 [02:52<10:08,  1.34s/it, training_loss=0.455]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 128/581 [02:52<10:07,  1.34s/it, training_loss=0.455]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 128/581 [02:53<10:07,  1.34s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 129/581 [02:53<10:06,  1.34s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 129/581 [02:55<10:06,  1.34s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 130/581 [02:55<10:03,  1.34s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 130/581 [02:56<10:03,  1.34s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 131/581 [02:56<10:03,  1.34s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 131/581 [02:57<10:03,  1.34s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 132/581 [02:57<10:01,  1.34s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 132/581 [02:59<10:01,  1.34s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 133/581 [02:59<10:01,  1.34s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 133/581 [03:00<10:01,  1.34s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 134/581 [03:00<09:59,  1.34s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 134/581 [03:01<09:59,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 135/581 [03:01<09:59,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 135/581 [03:03<09:59,  1.34s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 136/581 [03:03<09:57,  1.34s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 136/581 [03:04<09:57,  1.34s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 137/581 [03:04<09:55,  1.34s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 137/581 [03:05<09:55,  1.34s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 138/581 [03:05<09:54,  1.34s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 138/581 [03:07<09:54,  1.34s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 139/581 [03:07<09:51,  1.34s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 139/581 [03:08<09:51,  1.34s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 140/581 [03:08<09:50,  1.34s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 140/581 [03:09<09:50,  1.34s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 141/581 [03:09<09:49,  1.34s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 141/581 [03:11<09:49,  1.34s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 142/581 [03:11<09:48,  1.34s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 142/581 [03:12<09:48,  1.34s/it, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 143/581 [03:12<09:47,  1.34s/it, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 143/581 [03:13<09:47,  1.34s/it, training_loss=0.377]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 144/581 [03:13<09:46,  1.34s/it, training_loss=0.377]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 144/581 [03:15<09:46,  1.34s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 145/581 [03:15<09:44,  1.34s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 145/581 [03:16<09:44,  1.34s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 146/581 [03:16<09:43,  1.34s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 146/581 [03:17<09:43,  1.34s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 147/581 [03:17<09:41,  1.34s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 147/581 [03:19<09:41,  1.34s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 148/581 [03:19<09:40,  1.34s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 148/581 [03:20<09:40,  1.34s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 149/581 [03:20<09:39,  1.34s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 149/581 [03:21<09:39,  1.34s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 150/581 [03:21<09:40,  1.35s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 150/581 [03:23<09:40,  1.35s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 151/581 [03:23<09:38,  1.35s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 151/581 [03:24<09:38,  1.35s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 152/581 [03:24<09:36,  1.34s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 152/581 [03:25<09:36,  1.34s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 153/581 [03:26<09:35,  1.35s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 153/581 [03:27<09:35,  1.35s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 154/581 [03:27<09:33,  1.34s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 154/581 [03:28<09:33,  1.34s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 155/581 [03:28<09:32,  1.34s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 155/581 [03:30<09:32,  1.34s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 156/581 [03:30<09:31,  1.34s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 156/581 [03:31<09:31,  1.34s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 157/581 [03:31<09:30,  1.35s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 157/581 [03:32<09:30,  1.35s/it, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 158/581 [03:32<09:29,  1.35s/it, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 158/581 [03:34<09:29,  1.35s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 159/581 [03:34<09:26,  1.34s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 159/581 [03:35<09:26,  1.34s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 160/581 [03:35<09:24,  1.34s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 160/581 [03:36<09:24,  1.34s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 161/581 [03:36<09:23,  1.34s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 161/581 [03:38<09:23,  1.34s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 162/581 [03:38<09:23,  1.34s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 162/581 [03:39<09:23,  1.34s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 163/581 [03:39<09:23,  1.35s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 163/581 [03:40<09:23,  1.35s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 164/581 [03:40<09:22,  1.35s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 164/581 [03:42<09:22,  1.35s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 165/581 [03:42<09:21,  1.35s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 165/581 [03:43<09:21,  1.35s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 166/581 [03:43<09:19,  1.35s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 166/581 [03:44<09:19,  1.35s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 167/581 [03:44<09:18,  1.35s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 167/581 [03:46<09:18,  1.35s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 168/581 [03:46<09:16,  1.35s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 168/581 [03:47<09:16,  1.35s/it, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 169/581 [03:47<09:16,  1.35s/it, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 169/581 [03:48<09:16,  1.35s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 170/581 [03:48<09:16,  1.35s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 170/581 [03:50<09:16,  1.35s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 171/581 [03:50<09:12,  1.35s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 171/581 [03:51<09:12,  1.35s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 172/581 [03:51<09:10,  1.34s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 172/581 [03:52<09:10,  1.34s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 173/581 [03:52<09:07,  1.34s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 173/581 [03:54<09:07,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 174/581 [03:54<09:08,  1.35s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 174/581 [03:55<09:08,  1.35s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  30%|███       | 175/581 [03:55<09:06,  1.35s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  30%|███       | 175/581 [03:56<09:06,  1.35s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  30%|███       | 176/581 [03:56<09:04,  1.34s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  30%|███       | 176/581 [03:58<09:04,  1.34s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  30%|███       | 177/581 [03:58<09:03,  1.35s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  30%|███       | 177/581 [03:59<09:03,  1.35s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  31%|███       | 178/581 [03:59<09:02,  1.35s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  31%|███       | 178/581 [04:01<09:02,  1.35s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  31%|███       | 179/581 [04:01<09:01,  1.35s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  31%|███       | 179/581 [04:02<09:01,  1.35s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  31%|███       | 180/581 [04:02<09:00,  1.35s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  31%|███       | 180/581 [04:03<09:00,  1.35s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  31%|███       | 181/581 [04:03<08:59,  1.35s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  31%|███       | 181/581 [04:05<08:59,  1.35s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 182/581 [04:05<08:58,  1.35s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 182/581 [04:06<08:58,  1.35s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 183/581 [04:06<08:55,  1.35s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 183/581 [04:07<08:55,  1.35s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 184/581 [04:07<08:55,  1.35s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 184/581 [04:09<08:55,  1.35s/it, training_loss=0.408]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 185/581 [04:09<08:53,  1.35s/it, training_loss=0.408]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 185/581 [04:10<08:53,  1.35s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 186/581 [04:10<08:51,  1.35s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 186/581 [04:11<08:51,  1.35s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 187/581 [04:11<08:50,  1.35s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 187/581 [04:13<08:50,  1.35s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 188/581 [04:13<08:49,  1.35s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 188/581 [04:14<08:49,  1.35s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 189/581 [04:14<08:49,  1.35s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 189/581 [04:15<08:49,  1.35s/it, training_loss=0.368]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 190/581 [04:15<08:47,  1.35s/it, training_loss=0.368]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 190/581 [04:17<08:47,  1.35s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 191/581 [04:17<08:45,  1.35s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 191/581 [04:18<08:45,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 192/581 [04:18<08:43,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 192/581 [04:19<08:43,  1.35s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 193/581 [04:19<08:43,  1.35s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 193/581 [04:21<08:43,  1.35s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 194/581 [04:21<08:42,  1.35s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 194/581 [04:22<08:42,  1.35s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 195/581 [04:22<08:41,  1.35s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 195/581 [04:23<08:41,  1.35s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 196/581 [04:23<08:39,  1.35s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 196/581 [04:25<08:39,  1.35s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 197/581 [04:25<08:38,  1.35s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 197/581 [04:26<08:38,  1.35s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 198/581 [04:26<08:37,  1.35s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 198/581 [04:27<08:37,  1.35s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 199/581 [04:27<08:34,  1.35s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 199/581 [04:29<08:34,  1.35s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 200/581 [04:29<08:34,  1.35s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 200/581 [04:30<08:34,  1.35s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 201/581 [04:30<08:33,  1.35s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 201/581 [04:32<08:33,  1.35s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 202/581 [04:32<08:30,  1.35s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 202/581 [04:33<08:30,  1.35s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 203/581 [04:33<08:29,  1.35s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 203/581 [04:34<08:29,  1.35s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 204/581 [04:34<08:26,  1.34s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 204/581 [04:36<08:26,  1.34s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 205/581 [04:36<08:25,  1.34s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 205/581 [04:37<08:25,  1.34s/it, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 206/581 [04:37<08:24,  1.35s/it, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 206/581 [04:38<08:24,  1.35s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 207/581 [04:38<08:23,  1.35s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 207/581 [04:40<08:23,  1.35s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 208/581 [04:40<08:21,  1.34s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 208/581 [04:41<08:21,  1.34s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 209/581 [04:41<08:20,  1.35s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 209/581 [04:42<08:20,  1.35s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 210/581 [04:42<08:20,  1.35s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 210/581 [04:44<08:20,  1.35s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 211/581 [04:44<08:20,  1.35s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 211/581 [04:45<08:20,  1.35s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 212/581 [04:45<08:17,  1.35s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 212/581 [04:46<08:17,  1.35s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 213/581 [04:46<08:16,  1.35s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 213/581 [04:48<08:16,  1.35s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 214/581 [04:48<08:14,  1.35s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 214/581 [04:49<08:14,  1.35s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 215/581 [04:49<08:11,  1.34s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 215/581 [04:50<08:11,  1.34s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 216/581 [04:50<08:09,  1.34s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 216/581 [04:52<08:09,  1.34s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 217/581 [04:52<08:08,  1.34s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 217/581 [04:53<08:08,  1.34s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 218/581 [04:53<08:07,  1.34s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 218/581 [04:54<08:07,  1.34s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 219/581 [04:54<08:05,  1.34s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 219/581 [04:56<08:05,  1.34s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 220/581 [04:56<08:06,  1.35s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 220/581 [04:57<08:06,  1.35s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 221/581 [04:57<08:03,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 221/581 [04:58<08:03,  1.34s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 222/581 [04:58<08:01,  1.34s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 222/581 [05:00<08:01,  1.34s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 223/581 [05:00<08:00,  1.34s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 223/581 [05:01<08:00,  1.34s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 224/581 [05:01<08:00,  1.35s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 224/581 [05:02<08:00,  1.35s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 225/581 [05:02<07:58,  1.34s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 225/581 [05:04<07:58,  1.34s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 226/581 [05:04<07:56,  1.34s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 226/581 [05:05<07:56,  1.34s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 227/581 [05:05<07:54,  1.34s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 227/581 [05:06<07:54,  1.34s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 228/581 [05:06<07:53,  1.34s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 228/581 [05:08<07:53,  1.34s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 229/581 [05:08<07:52,  1.34s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 229/581 [05:09<07:52,  1.34s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 230/581 [05:09<07:52,  1.35s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 230/581 [05:10<07:52,  1.35s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 231/581 [05:11<07:50,  1.34s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 231/581 [05:12<07:50,  1.34s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 232/581 [05:12<07:47,  1.34s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 232/581 [05:13<07:47,  1.34s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  40%|████      | 233/581 [05:13<07:46,  1.34s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  40%|████      | 233/581 [05:15<07:46,  1.34s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  40%|████      | 234/581 [05:15<07:44,  1.34s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  40%|████      | 234/581 [05:16<07:44,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  40%|████      | 235/581 [05:16<07:43,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  40%|████      | 235/581 [05:17<07:43,  1.34s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  41%|████      | 236/581 [05:17<07:42,  1.34s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  41%|████      | 236/581 [05:19<07:42,  1.34s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  41%|████      | 237/581 [05:19<07:40,  1.34s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  41%|████      | 237/581 [05:20<07:40,  1.34s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  41%|████      | 238/581 [05:20<07:39,  1.34s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  41%|████      | 238/581 [05:21<07:39,  1.34s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  41%|████      | 239/581 [05:21<07:38,  1.34s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  41%|████      | 239/581 [05:23<07:38,  1.34s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 240/581 [05:23<07:36,  1.34s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 240/581 [05:24<07:36,  1.34s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 241/581 [05:24<07:35,  1.34s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 241/581 [05:25<07:35,  1.34s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 242/581 [05:25<07:34,  1.34s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 242/581 [05:27<07:34,  1.34s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 243/581 [05:27<07:32,  1.34s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 243/581 [05:28<07:32,  1.34s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 244/581 [05:28<07:31,  1.34s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 244/581 [05:29<07:31,  1.34s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 245/581 [05:29<07:31,  1.34s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 245/581 [05:31<07:31,  1.34s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 246/581 [05:31<07:29,  1.34s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 246/581 [05:32<07:29,  1.34s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 247/581 [05:32<07:27,  1.34s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 247/581 [05:33<07:27,  1.34s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 248/581 [05:33<07:25,  1.34s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 248/581 [05:35<07:25,  1.34s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 249/581 [05:35<07:24,  1.34s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 249/581 [05:36<07:24,  1.34s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 250/581 [05:36<07:23,  1.34s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 250/581 [05:37<07:23,  1.34s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 251/581 [05:37<07:22,  1.34s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 251/581 [05:39<07:22,  1.34s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 252/581 [05:39<07:20,  1.34s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 252/581 [05:40<07:20,  1.34s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 253/581 [05:40<07:19,  1.34s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 253/581 [05:41<07:19,  1.34s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 254/581 [05:41<07:17,  1.34s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 254/581 [05:43<07:17,  1.34s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 255/581 [05:43<07:16,  1.34s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 255/581 [05:44<07:16,  1.34s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 256/581 [05:44<07:16,  1.34s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 256/581 [05:45<07:16,  1.34s/it, training_loss=0.399]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 257/581 [05:45<07:14,  1.34s/it, training_loss=0.399]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 257/581 [05:47<07:14,  1.34s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 258/581 [05:47<07:13,  1.34s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 258/581 [05:48<07:13,  1.34s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 259/581 [05:48<07:12,  1.34s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 259/581 [05:49<07:12,  1.34s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 260/581 [05:49<07:11,  1.34s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 260/581 [05:51<07:11,  1.34s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 261/581 [05:51<07:09,  1.34s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 261/581 [05:52<07:09,  1.34s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 262/581 [05:52<07:07,  1.34s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 262/581 [05:53<07:07,  1.34s/it, training_loss=0.385]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 263/581 [05:53<07:05,  1.34s/it, training_loss=0.385]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 263/581 [05:55<07:05,  1.34s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 264/581 [05:55<07:04,  1.34s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 264/581 [05:56<07:04,  1.34s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 265/581 [05:56<07:03,  1.34s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 265/581 [05:57<07:03,  1.34s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 266/581 [05:57<07:02,  1.34s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 266/581 [05:59<07:02,  1.34s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 267/581 [05:59<07:01,  1.34s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 267/581 [06:00<07:01,  1.34s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 268/581 [06:00<07:00,  1.34s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 268/581 [06:01<07:00,  1.34s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 269/581 [06:01<06:59,  1.34s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 269/581 [06:03<06:59,  1.34s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 270/581 [06:03<06:57,  1.34s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 270/581 [06:04<06:57,  1.34s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 271/581 [06:04<06:55,  1.34s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 271/581 [06:05<06:55,  1.34s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 272/581 [06:05<06:54,  1.34s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 272/581 [06:07<06:54,  1.34s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 273/581 [06:07<06:52,  1.34s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 273/581 [06:08<06:52,  1.34s/it, training_loss=0.390]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 274/581 [06:08<06:50,  1.34s/it, training_loss=0.390]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 274/581 [06:09<06:50,  1.34s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 275/581 [06:09<06:49,  1.34s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 275/581 [06:11<06:49,  1.34s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 276/581 [06:11<06:48,  1.34s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 276/581 [06:12<06:48,  1.34s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 277/581 [06:12<06:47,  1.34s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 277/581 [06:13<06:47,  1.34s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 278/581 [06:13<06:46,  1.34s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 278/581 [06:15<06:46,  1.34s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 279/581 [06:15<06:45,  1.34s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 279/581 [06:16<06:45,  1.34s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 280/581 [06:16<06:44,  1.34s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 280/581 [06:18<06:44,  1.34s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 281/581 [06:18<06:42,  1.34s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 281/581 [06:19<06:42,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 282/581 [06:19<06:42,  1.35s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 282/581 [06:20<06:42,  1.35s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 283/581 [06:20<06:40,  1.35s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 283/581 [06:22<06:40,  1.35s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 284/581 [06:22<06:38,  1.34s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 284/581 [06:23<06:38,  1.34s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 285/581 [06:23<06:37,  1.34s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 285/581 [06:24<06:37,  1.34s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 286/581 [06:24<06:35,  1.34s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 286/581 [06:26<06:35,  1.34s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 287/581 [06:26<06:33,  1.34s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 287/581 [06:27<06:33,  1.34s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 288/581 [06:27<06:33,  1.34s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 288/581 [06:28<06:33,  1.34s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 289/581 [06:28<06:32,  1.34s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 289/581 [06:30<06:32,  1.34s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 290/581 [06:30<06:31,  1.35s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 290/581 [06:31<06:31,  1.35s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  50%|█████     | 291/581 [06:31<06:29,  1.34s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  50%|█████     | 291/581 [06:32<06:29,  1.34s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  50%|█████     | 292/581 [06:32<06:27,  1.34s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  50%|█████     | 292/581 [06:34<06:27,  1.34s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  50%|█████     | 293/581 [06:34<06:26,  1.34s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  50%|█████     | 293/581 [06:35<06:26,  1.34s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  51%|█████     | 294/581 [06:35<06:24,  1.34s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  51%|█████     | 294/581 [06:36<06:24,  1.34s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  51%|█████     | 295/581 [06:36<06:25,  1.35s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  51%|█████     | 295/581 [06:38<06:25,  1.35s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  51%|█████     | 296/581 [06:38<06:22,  1.34s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  51%|█████     | 296/581 [06:39<06:22,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  51%|█████     | 297/581 [06:39<06:20,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  51%|█████     | 297/581 [06:40<06:20,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 298/581 [06:40<06:19,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 298/581 [06:42<06:19,  1.34s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 299/581 [06:42<06:18,  1.34s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 299/581 [06:43<06:18,  1.34s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 300/581 [06:43<06:16,  1.34s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 300/581 [06:44<06:16,  1.34s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 301/581 [06:44<06:16,  1.34s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 301/581 [06:46<06:16,  1.34s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 302/581 [06:46<06:15,  1.35s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 302/581 [06:47<06:15,  1.35s/it, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 303/581 [06:47<06:13,  1.35s/it, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 303/581 [06:48<06:13,  1.35s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 304/581 [06:48<06:13,  1.35s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 304/581 [06:50<06:13,  1.35s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 305/581 [06:50<06:12,  1.35s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 305/581 [06:51<06:12,  1.35s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 306/581 [06:51<06:09,  1.34s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 306/581 [06:52<06:09,  1.34s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 307/581 [06:52<06:07,  1.34s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 307/581 [06:54<06:07,  1.34s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 308/581 [06:54<06:05,  1.34s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 308/581 [06:55<06:05,  1.34s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 309/581 [06:55<06:04,  1.34s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 309/581 [06:56<06:04,  1.34s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 310/581 [06:56<06:04,  1.34s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 310/581 [06:58<06:04,  1.34s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 311/581 [06:58<06:03,  1.35s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 311/581 [06:59<06:03,  1.35s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 312/581 [06:59<06:01,  1.34s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 312/581 [07:01<06:01,  1.34s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 313/581 [07:01<06:00,  1.35s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 313/581 [07:02<06:00,  1.35s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 314/581 [07:02<05:59,  1.35s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 314/581 [07:03<05:59,  1.35s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 315/581 [07:03<05:57,  1.34s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 315/581 [07:05<05:57,  1.34s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 316/581 [07:05<05:55,  1.34s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 316/581 [07:06<05:55,  1.34s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 317/581 [07:06<05:54,  1.34s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 317/581 [07:07<05:54,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 318/581 [07:07<05:53,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 318/581 [07:09<05:53,  1.34s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 319/581 [07:09<05:52,  1.35s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 319/581 [07:10<05:52,  1.35s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 320/581 [07:10<05:51,  1.35s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 320/581 [07:11<05:51,  1.35s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 321/581 [07:11<05:50,  1.35s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 321/581 [07:13<05:50,  1.35s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 322/581 [07:13<05:49,  1.35s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 322/581 [07:14<05:49,  1.35s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 323/581 [07:14<05:47,  1.35s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 323/581 [07:15<05:47,  1.35s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 324/581 [07:15<05:45,  1.34s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 324/581 [07:17<05:45,  1.34s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 325/581 [07:17<05:43,  1.34s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 325/581 [07:18<05:43,  1.34s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 326/581 [07:18<05:41,  1.34s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 326/581 [07:19<05:41,  1.34s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 327/581 [07:19<05:40,  1.34s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 327/581 [07:21<05:40,  1.34s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 328/581 [07:21<05:40,  1.35s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 328/581 [07:22<05:40,  1.35s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 329/581 [07:22<05:39,  1.35s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 329/581 [07:23<05:39,  1.35s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 330/581 [07:23<05:38,  1.35s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 330/581 [07:25<05:38,  1.35s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 331/581 [07:25<05:36,  1.35s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 331/581 [07:26<05:36,  1.35s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 332/581 [07:26<05:34,  1.34s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 332/581 [07:27<05:34,  1.34s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 333/581 [07:27<05:34,  1.35s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 333/581 [07:29<05:34,  1.35s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 334/581 [07:29<05:32,  1.35s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 334/581 [07:30<05:32,  1.35s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 335/581 [07:30<05:31,  1.35s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 335/581 [07:31<05:31,  1.35s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 336/581 [07:31<05:29,  1.35s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 336/581 [07:33<05:29,  1.35s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 337/581 [07:33<05:28,  1.35s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 337/581 [07:34<05:28,  1.35s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 338/581 [07:34<05:26,  1.34s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 338/581 [07:36<05:26,  1.34s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 339/581 [07:36<05:26,  1.35s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 339/581 [07:37<05:26,  1.35s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 340/581 [07:37<05:24,  1.35s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 340/581 [07:38<05:24,  1.35s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 341/581 [07:38<05:23,  1.35s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 341/581 [07:40<05:23,  1.35s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 342/581 [07:40<05:22,  1.35s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 342/581 [07:41<05:22,  1.35s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 343/581 [07:41<05:20,  1.35s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 343/581 [07:42<05:20,  1.35s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 344/581 [07:42<05:18,  1.34s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 344/581 [07:44<05:18,  1.34s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 345/581 [07:44<05:17,  1.35s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 345/581 [07:45<05:17,  1.35s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 346/581 [07:45<05:16,  1.35s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 346/581 [07:46<05:16,  1.35s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 347/581 [07:46<05:15,  1.35s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 347/581 [07:48<05:15,  1.35s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 348/581 [07:48<05:14,  1.35s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 348/581 [07:49<05:14,  1.35s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  60%|██████    | 349/581 [07:49<05:12,  1.35s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  60%|██████    | 349/581 [07:50<05:12,  1.35s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  60%|██████    | 350/581 [07:50<05:11,  1.35s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  60%|██████    | 350/581 [07:52<05:11,  1.35s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  60%|██████    | 351/581 [07:52<05:09,  1.35s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  60%|██████    | 351/581 [07:53<05:09,  1.35s/it, training_loss=0.457]\u001b[A\n",
            "Epoch 1:  61%|██████    | 352/581 [07:53<05:08,  1.35s/it, training_loss=0.457]\u001b[A\n",
            "Epoch 1:  61%|██████    | 352/581 [07:54<05:08,  1.35s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  61%|██████    | 353/581 [07:54<05:07,  1.35s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  61%|██████    | 353/581 [07:56<05:07,  1.35s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  61%|██████    | 354/581 [07:56<05:07,  1.35s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  61%|██████    | 354/581 [07:57<05:07,  1.35s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  61%|██████    | 355/581 [07:57<05:05,  1.35s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  61%|██████    | 355/581 [07:58<05:05,  1.35s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 356/581 [07:58<05:03,  1.35s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 356/581 [08:00<05:03,  1.35s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 357/581 [08:00<05:01,  1.35s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 357/581 [08:01<05:01,  1.35s/it, training_loss=0.371]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 358/581 [08:01<04:59,  1.34s/it, training_loss=0.371]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 358/581 [08:02<04:59,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 359/581 [08:02<04:58,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 359/581 [08:04<04:58,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 360/581 [08:04<04:56,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 360/581 [08:05<04:56,  1.34s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 361/581 [08:05<04:55,  1.34s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 361/581 [08:06<04:55,  1.34s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 362/581 [08:06<04:52,  1.34s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 362/581 [08:08<04:52,  1.34s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 363/581 [08:08<04:51,  1.34s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 363/581 [08:09<04:51,  1.34s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 364/581 [08:09<04:50,  1.34s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 364/581 [08:10<04:50,  1.34s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 365/581 [08:10<04:49,  1.34s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 365/581 [08:12<04:49,  1.34s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 366/581 [08:12<04:49,  1.34s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 366/581 [08:13<04:49,  1.34s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 367/581 [08:13<04:47,  1.34s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 367/581 [08:15<04:47,  1.34s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 368/581 [08:15<04:46,  1.34s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 368/581 [08:16<04:46,  1.34s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 369/581 [08:16<04:44,  1.34s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 369/581 [08:17<04:44,  1.34s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 370/581 [08:17<04:43,  1.35s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 370/581 [08:19<04:43,  1.35s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 371/581 [08:19<04:42,  1.35s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 371/581 [08:20<04:42,  1.35s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 372/581 [08:20<04:40,  1.34s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 372/581 [08:21<04:40,  1.34s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 373/581 [08:21<04:38,  1.34s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 373/581 [08:23<04:38,  1.34s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 374/581 [08:23<04:38,  1.34s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 374/581 [08:24<04:38,  1.34s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 375/581 [08:24<04:37,  1.35s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 375/581 [08:25<04:37,  1.35s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 376/581 [08:25<04:35,  1.34s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 376/581 [08:27<04:35,  1.34s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 377/581 [08:27<04:33,  1.34s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 377/581 [08:28<04:33,  1.34s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 378/581 [08:28<04:31,  1.34s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 378/581 [08:29<04:31,  1.34s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 379/581 [08:29<04:30,  1.34s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 379/581 [08:31<04:30,  1.34s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 380/581 [08:31<04:29,  1.34s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 380/581 [08:32<04:29,  1.34s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 381/581 [08:32<04:27,  1.34s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 381/581 [08:33<04:27,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 382/581 [08:33<04:26,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 382/581 [08:35<04:26,  1.34s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 383/581 [08:35<04:25,  1.34s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 383/581 [08:36<04:25,  1.34s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 384/581 [08:36<04:23,  1.34s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 384/581 [08:37<04:23,  1.34s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 385/581 [08:37<04:22,  1.34s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 385/581 [08:39<04:22,  1.34s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 386/581 [08:39<04:20,  1.34s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 386/581 [08:40<04:20,  1.34s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 387/581 [08:40<04:20,  1.34s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 387/581 [08:41<04:20,  1.34s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 388/581 [08:41<04:19,  1.34s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 388/581 [08:43<04:19,  1.34s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 389/581 [08:43<04:18,  1.34s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 389/581 [08:44<04:18,  1.34s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 390/581 [08:44<04:16,  1.34s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 390/581 [08:45<04:16,  1.34s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 391/581 [08:45<04:15,  1.35s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 391/581 [08:47<04:15,  1.35s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 392/581 [08:47<04:14,  1.35s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 392/581 [08:48<04:14,  1.35s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 393/581 [08:48<04:12,  1.34s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 393/581 [08:49<04:12,  1.34s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 394/581 [08:49<04:11,  1.34s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 394/581 [08:51<04:11,  1.34s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 395/581 [08:51<04:10,  1.34s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 395/581 [08:52<04:10,  1.34s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 396/581 [08:52<04:08,  1.34s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 396/581 [08:53<04:08,  1.34s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 397/581 [08:53<04:07,  1.34s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 397/581 [08:55<04:07,  1.34s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 398/581 [08:55<04:05,  1.34s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 398/581 [08:56<04:05,  1.34s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 399/581 [08:56<04:05,  1.35s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 399/581 [08:57<04:05,  1.35s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 400/581 [08:58<04:04,  1.35s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 400/581 [08:59<04:04,  1.35s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 401/581 [08:59<04:03,  1.35s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 401/581 [09:00<04:03,  1.35s/it, training_loss=0.383]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 402/581 [09:00<04:00,  1.35s/it, training_loss=0.383]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 402/581 [09:02<04:00,  1.35s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 403/581 [09:02<04:00,  1.35s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 403/581 [09:03<04:00,  1.35s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 404/581 [09:03<03:58,  1.35s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 404/581 [09:04<03:58,  1.35s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 405/581 [09:04<03:57,  1.35s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 405/581 [09:06<03:57,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 406/581 [09:06<03:55,  1.34s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 406/581 [09:07<03:55,  1.34s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  70%|███████   | 407/581 [09:07<03:54,  1.34s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  70%|███████   | 407/581 [09:08<03:54,  1.34s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  70%|███████   | 408/581 [09:08<03:53,  1.35s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  70%|███████   | 408/581 [09:10<03:53,  1.35s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  70%|███████   | 409/581 [09:10<03:51,  1.35s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  70%|███████   | 409/581 [09:11<03:51,  1.35s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:  71%|███████   | 410/581 [09:11<03:50,  1.35s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:  71%|███████   | 410/581 [09:12<03:50,  1.35s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  71%|███████   | 411/581 [09:12<03:50,  1.35s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  71%|███████   | 411/581 [09:14<03:50,  1.35s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  71%|███████   | 412/581 [09:14<03:48,  1.35s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  71%|███████   | 412/581 [09:15<03:48,  1.35s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  71%|███████   | 413/581 [09:15<03:46,  1.35s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  71%|███████   | 413/581 [09:16<03:46,  1.35s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 414/581 [09:16<03:46,  1.35s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 414/581 [09:18<03:46,  1.35s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 415/581 [09:18<03:44,  1.35s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 415/581 [09:19<03:44,  1.35s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 416/581 [09:19<03:43,  1.35s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 416/581 [09:20<03:43,  1.35s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 417/581 [09:20<03:41,  1.35s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 417/581 [09:22<03:41,  1.35s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 418/581 [09:22<03:39,  1.35s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 418/581 [09:23<03:39,  1.35s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 419/581 [09:23<03:38,  1.35s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 419/581 [09:24<03:38,  1.35s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 420/581 [09:24<03:36,  1.35s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 420/581 [09:26<03:36,  1.35s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 421/581 [09:26<03:36,  1.35s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 421/581 [09:27<03:36,  1.35s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 422/581 [09:27<03:34,  1.35s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 422/581 [09:29<03:34,  1.35s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 423/581 [09:29<03:33,  1.35s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 423/581 [09:30<03:33,  1.35s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 424/581 [09:30<03:31,  1.35s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 424/581 [09:31<03:31,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 425/581 [09:31<03:30,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 425/581 [09:33<03:30,  1.35s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 426/581 [09:33<03:28,  1.34s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 426/581 [09:34<03:28,  1.34s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 427/581 [09:34<03:26,  1.34s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 427/581 [09:35<03:26,  1.34s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 428/581 [09:35<03:25,  1.34s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 428/581 [09:37<03:25,  1.34s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 429/581 [09:37<03:24,  1.35s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 429/581 [09:38<03:24,  1.35s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 430/581 [09:38<03:22,  1.34s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 430/581 [09:39<03:22,  1.34s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 431/581 [09:39<03:21,  1.35s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 431/581 [09:41<03:21,  1.35s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 432/581 [09:41<03:20,  1.35s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 432/581 [09:42<03:20,  1.35s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 433/581 [09:42<03:18,  1.34s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 433/581 [09:43<03:18,  1.34s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 434/581 [09:43<03:17,  1.35s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 434/581 [09:45<03:17,  1.35s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 435/581 [09:45<03:16,  1.35s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 435/581 [09:46<03:16,  1.35s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 436/581 [09:46<03:15,  1.35s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 436/581 [09:47<03:15,  1.35s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 437/581 [09:47<03:13,  1.34s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 437/581 [09:49<03:13,  1.34s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 438/581 [09:49<03:12,  1.34s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 438/581 [09:50<03:12,  1.34s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 439/581 [09:50<03:11,  1.35s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 439/581 [09:51<03:11,  1.35s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 440/581 [09:51<03:09,  1.34s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 440/581 [09:53<03:09,  1.34s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 441/581 [09:53<03:07,  1.34s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 441/581 [09:54<03:07,  1.34s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 442/581 [09:54<03:06,  1.34s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 442/581 [09:55<03:06,  1.34s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 443/581 [09:55<03:05,  1.34s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 443/581 [09:57<03:05,  1.34s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 444/581 [09:57<03:04,  1.34s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 444/581 [09:58<03:04,  1.34s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 445/581 [09:58<03:03,  1.35s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 445/581 [09:59<03:03,  1.35s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 446/581 [09:59<03:01,  1.35s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 446/581 [10:01<03:01,  1.35s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 447/581 [10:01<03:00,  1.35s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 447/581 [10:02<03:00,  1.35s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 448/581 [10:02<02:59,  1.35s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 448/581 [10:03<02:59,  1.35s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 449/581 [10:03<02:57,  1.34s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 449/581 [10:05<02:57,  1.34s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 450/581 [10:05<02:56,  1.35s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 450/581 [10:06<02:56,  1.35s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 451/581 [10:06<02:54,  1.34s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 451/581 [10:08<02:54,  1.34s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 452/581 [10:08<02:53,  1.34s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 452/581 [10:09<02:53,  1.34s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 453/581 [10:09<02:51,  1.34s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 453/581 [10:10<02:51,  1.34s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 454/581 [10:10<02:50,  1.34s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 454/581 [10:12<02:50,  1.34s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 455/581 [10:12<02:49,  1.34s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 455/581 [10:13<02:49,  1.34s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 456/581 [10:13<02:48,  1.35s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 456/581 [10:14<02:48,  1.35s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 457/581 [10:14<02:47,  1.35s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 457/581 [10:16<02:47,  1.35s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 458/581 [10:16<02:46,  1.35s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 458/581 [10:17<02:46,  1.35s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 459/581 [10:17<02:44,  1.35s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 459/581 [10:18<02:44,  1.35s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 460/581 [10:18<02:43,  1.35s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 460/581 [10:20<02:43,  1.35s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 461/581 [10:20<02:41,  1.35s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 461/581 [10:21<02:41,  1.35s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 462/581 [10:21<02:40,  1.35s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 462/581 [10:22<02:40,  1.35s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 463/581 [10:22<02:38,  1.35s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 463/581 [10:24<02:38,  1.35s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 464/581 [10:24<02:37,  1.35s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 464/581 [10:25<02:37,  1.35s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  80%|████████  | 465/581 [10:25<02:35,  1.34s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  80%|████████  | 465/581 [10:26<02:35,  1.34s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  80%|████████  | 466/581 [10:26<02:34,  1.34s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  80%|████████  | 466/581 [10:28<02:34,  1.34s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  80%|████████  | 467/581 [10:28<02:32,  1.34s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  80%|████████  | 467/581 [10:29<02:32,  1.34s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  81%|████████  | 468/581 [10:29<02:31,  1.34s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  81%|████████  | 468/581 [10:30<02:31,  1.34s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  81%|████████  | 469/581 [10:30<02:29,  1.34s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  81%|████████  | 469/581 [10:32<02:29,  1.34s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  81%|████████  | 470/581 [10:32<02:28,  1.34s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  81%|████████  | 470/581 [10:33<02:28,  1.34s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  81%|████████  | 471/581 [10:33<02:27,  1.34s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  81%|████████  | 471/581 [10:34<02:27,  1.34s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  81%|████████  | 472/581 [10:34<02:26,  1.35s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  81%|████████  | 472/581 [10:36<02:26,  1.35s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 473/581 [10:36<02:25,  1.35s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 473/581 [10:37<02:25,  1.35s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 474/581 [10:37<02:24,  1.35s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 474/581 [10:38<02:24,  1.35s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 475/581 [10:38<02:22,  1.35s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 475/581 [10:40<02:22,  1.35s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 476/581 [10:40<02:21,  1.34s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 476/581 [10:41<02:21,  1.34s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 477/581 [10:41<02:19,  1.34s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 477/581 [10:42<02:19,  1.34s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 478/581 [10:42<02:18,  1.34s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 478/581 [10:44<02:18,  1.34s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 479/581 [10:44<02:17,  1.35s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 479/581 [10:45<02:17,  1.35s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 480/581 [10:45<02:15,  1.35s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 480/581 [10:47<02:15,  1.35s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 481/581 [10:47<02:14,  1.35s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 481/581 [10:48<02:14,  1.35s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 482/581 [10:48<02:13,  1.35s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 482/581 [10:49<02:13,  1.35s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 483/581 [10:49<02:12,  1.35s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 483/581 [10:51<02:12,  1.35s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 484/581 [10:51<02:10,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 484/581 [10:52<02:10,  1.34s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 485/581 [10:52<02:08,  1.34s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 485/581 [10:53<02:08,  1.34s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 486/581 [10:53<02:07,  1.34s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 486/581 [10:55<02:07,  1.34s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 487/581 [10:55<02:06,  1.34s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 487/581 [10:56<02:06,  1.34s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 488/581 [10:56<02:04,  1.34s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 488/581 [10:57<02:04,  1.34s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 489/581 [10:57<02:03,  1.34s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 489/581 [10:59<02:03,  1.34s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 490/581 [10:59<02:02,  1.34s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 490/581 [11:00<02:02,  1.34s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 491/581 [11:00<02:00,  1.34s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 491/581 [11:01<02:00,  1.34s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 492/581 [11:01<01:59,  1.34s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 492/581 [11:03<01:59,  1.34s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 493/581 [11:03<01:58,  1.35s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 493/581 [11:04<01:58,  1.35s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 494/581 [11:04<01:57,  1.35s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 494/581 [11:05<01:57,  1.35s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 495/581 [11:05<01:55,  1.35s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 495/581 [11:07<01:55,  1.35s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 496/581 [11:07<01:54,  1.35s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 496/581 [11:08<01:54,  1.35s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 497/581 [11:08<01:53,  1.35s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 497/581 [11:09<01:53,  1.35s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 498/581 [11:09<01:51,  1.34s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 498/581 [11:11<01:51,  1.34s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 499/581 [11:11<01:50,  1.34s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 499/581 [11:12<01:50,  1.34s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 500/581 [11:12<01:49,  1.35s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 500/581 [11:13<01:49,  1.35s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 501/581 [11:13<01:47,  1.35s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 501/581 [11:15<01:47,  1.35s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 502/581 [11:15<01:46,  1.35s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 502/581 [11:16<01:46,  1.35s/it, training_loss=0.387]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 503/581 [11:16<01:45,  1.35s/it, training_loss=0.387]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 503/581 [11:17<01:45,  1.35s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 504/581 [11:17<01:43,  1.35s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 504/581 [11:19<01:43,  1.35s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 505/581 [11:19<01:42,  1.34s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 505/581 [11:20<01:42,  1.34s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 506/581 [11:20<01:40,  1.34s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 506/581 [11:22<01:40,  1.34s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 507/581 [11:22<01:39,  1.35s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 507/581 [11:23<01:39,  1.35s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 508/581 [11:23<01:38,  1.35s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 508/581 [11:24<01:38,  1.35s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 509/581 [11:24<01:36,  1.34s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 509/581 [11:26<01:36,  1.34s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 510/581 [11:26<01:35,  1.34s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 510/581 [11:27<01:35,  1.34s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 511/581 [11:27<01:34,  1.35s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 511/581 [11:28<01:34,  1.35s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 512/581 [11:28<01:33,  1.35s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 512/581 [11:30<01:33,  1.35s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 513/581 [11:30<01:31,  1.35s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 513/581 [11:31<01:31,  1.35s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 514/581 [11:31<01:30,  1.35s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 514/581 [11:32<01:30,  1.35s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 515/581 [11:32<01:28,  1.35s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 515/581 [11:34<01:28,  1.35s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 516/581 [11:34<01:27,  1.35s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 516/581 [11:35<01:27,  1.35s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 517/581 [11:35<01:26,  1.35s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 517/581 [11:36<01:26,  1.35s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 518/581 [11:36<01:24,  1.35s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 518/581 [11:38<01:24,  1.35s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 519/581 [11:38<01:23,  1.35s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 519/581 [11:39<01:23,  1.35s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 520/581 [11:39<01:22,  1.35s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 520/581 [11:40<01:22,  1.35s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 521/581 [11:40<01:20,  1.35s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 521/581 [11:42<01:20,  1.35s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 522/581 [11:42<01:19,  1.35s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 522/581 [11:43<01:19,  1.35s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 523/581 [11:43<01:18,  1.35s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 523/581 [11:44<01:18,  1.35s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 524/581 [11:44<01:16,  1.34s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 524/581 [11:46<01:16,  1.34s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 525/581 [11:46<01:15,  1.35s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 525/581 [11:47<01:15,  1.35s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 526/581 [11:47<01:14,  1.35s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 526/581 [11:48<01:14,  1.35s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 527/581 [11:48<01:12,  1.34s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 527/581 [11:50<01:12,  1.34s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 528/581 [11:50<01:11,  1.34s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 528/581 [11:51<01:11,  1.34s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 529/581 [11:51<01:09,  1.34s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 529/581 [11:52<01:09,  1.34s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 530/581 [11:52<01:08,  1.34s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 530/581 [11:54<01:08,  1.34s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 531/581 [11:54<01:07,  1.35s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 531/581 [11:55<01:07,  1.35s/it, training_loss=0.395]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 532/581 [11:55<01:06,  1.35s/it, training_loss=0.395]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 532/581 [11:57<01:06,  1.35s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 533/581 [11:57<01:04,  1.35s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 533/581 [11:58<01:04,  1.35s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 534/581 [11:58<01:03,  1.34s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 534/581 [11:59<01:03,  1.34s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 535/581 [11:59<01:01,  1.35s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 535/581 [12:01<01:01,  1.35s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 536/581 [12:01<01:00,  1.35s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 536/581 [12:02<01:00,  1.35s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 537/581 [12:02<00:59,  1.34s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 537/581 [12:03<00:59,  1.34s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 538/581 [12:03<00:57,  1.34s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 538/581 [12:05<00:57,  1.34s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 539/581 [12:05<00:56,  1.34s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 539/581 [12:06<00:56,  1.34s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 540/581 [12:06<00:54,  1.34s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 540/581 [12:07<00:54,  1.34s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 541/581 [12:07<00:53,  1.34s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 541/581 [12:09<00:53,  1.34s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 542/581 [12:09<00:52,  1.34s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 542/581 [12:10<00:52,  1.34s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 543/581 [12:10<00:50,  1.34s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 543/581 [12:11<00:50,  1.34s/it, training_loss=0.318]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 544/581 [12:11<00:49,  1.34s/it, training_loss=0.318]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 544/581 [12:13<00:49,  1.34s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 545/581 [12:13<00:48,  1.34s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 545/581 [12:14<00:48,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 546/581 [12:14<00:46,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 546/581 [12:15<00:46,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 547/581 [12:15<00:45,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 547/581 [12:17<00:45,  1.34s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 548/581 [12:17<00:44,  1.34s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 548/581 [12:18<00:44,  1.34s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 549/581 [12:18<00:42,  1.34s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 549/581 [12:19<00:42,  1.34s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 550/581 [12:19<00:41,  1.35s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 550/581 [12:21<00:41,  1.35s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 551/581 [12:21<00:40,  1.35s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 551/581 [12:22<00:40,  1.35s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 552/581 [12:22<00:39,  1.35s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 552/581 [12:23<00:39,  1.35s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 553/581 [12:23<00:37,  1.35s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 553/581 [12:25<00:37,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 554/581 [12:25<00:36,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 554/581 [12:26<00:36,  1.35s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 555/581 [12:26<00:35,  1.35s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 555/581 [12:27<00:35,  1.35s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 556/581 [12:27<00:33,  1.35s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 556/581 [12:29<00:33,  1.35s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 557/581 [12:29<00:32,  1.35s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 557/581 [12:30<00:32,  1.35s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 558/581 [12:30<00:31,  1.35s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 558/581 [12:31<00:31,  1.35s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 559/581 [12:31<00:29,  1.35s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 559/581 [12:33<00:29,  1.35s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 560/581 [12:33<00:28,  1.35s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 560/581 [12:34<00:28,  1.35s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 561/581 [12:34<00:26,  1.35s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 561/581 [12:36<00:26,  1.35s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 562/581 [12:36<00:25,  1.35s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 562/581 [12:37<00:25,  1.35s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 563/581 [12:37<00:24,  1.34s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 563/581 [12:38<00:24,  1.34s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 564/581 [12:38<00:22,  1.34s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 564/581 [12:40<00:22,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 565/581 [12:40<00:21,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 565/581 [12:41<00:21,  1.34s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 566/581 [12:41<00:20,  1.34s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 566/581 [12:42<00:20,  1.34s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 567/581 [12:42<00:18,  1.34s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 567/581 [12:44<00:18,  1.34s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 568/581 [12:44<00:17,  1.34s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 568/581 [12:45<00:17,  1.34s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 569/581 [12:45<00:16,  1.34s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 569/581 [12:46<00:16,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 570/581 [12:46<00:14,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 570/581 [12:48<00:14,  1.34s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 571/581 [12:48<00:13,  1.35s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 571/581 [12:49<00:13,  1.35s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 572/581 [12:49<00:12,  1.35s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 572/581 [12:50<00:12,  1.35s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 573/581 [12:50<00:10,  1.34s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 573/581 [12:52<00:10,  1.34s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 574/581 [12:52<00:09,  1.34s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 574/581 [12:53<00:09,  1.34s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 575/581 [12:53<00:08,  1.35s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 575/581 [12:54<00:08,  1.35s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 576/581 [12:54<00:06,  1.35s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 576/581 [12:56<00:06,  1.35s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 577/581 [12:56<00:05,  1.34s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 577/581 [12:57<00:05,  1.34s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 578/581 [12:57<00:04,  1.35s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 578/581 [12:58<00:04,  1.35s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 579/581 [12:58<00:02,  1.35s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 579/581 [13:00<00:02,  1.35s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 580/581 [13:00<00:01,  1.34s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 580/581 [13:00<00:01,  1.34s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 1: 100%|██████████| 581/581 [13:00<00:00,  1.13s/it, training_loss=0.265]\u001b[A\n",
            "  0%|          | 0/3 [13:05<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training loss: 0.7990635187716164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 1/3 [14:40<29:20, 880.35s/it]\n",
            "Epoch 2:   0%|          | 0/581 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.6049177723447072\n",
            "F1 Score (Weighted): 0.7734499204003901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2:   0%|          | 0/581 [00:01<?, ?it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:   0%|          | 1/581 [00:01<12:51,  1.33s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:   0%|          | 1/581 [00:02<12:51,  1.33s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 2:   0%|          | 2/581 [00:02<12:51,  1.33s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 2:   0%|          | 2/581 [00:04<12:51,  1.33s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:   1%|          | 3/581 [00:04<12:52,  1.34s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:   1%|          | 3/581 [00:05<12:52,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:   1%|          | 4/581 [00:05<12:54,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:   1%|          | 4/581 [00:06<12:54,  1.34s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:   1%|          | 5/581 [00:06<12:54,  1.34s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:   1%|          | 5/581 [00:08<12:54,  1.34s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:   1%|          | 6/581 [00:08<12:52,  1.34s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:   1%|          | 6/581 [00:09<12:52,  1.34s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:   1%|          | 7/581 [00:09<12:52,  1.35s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:   1%|          | 7/581 [00:10<12:52,  1.35s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 2:   1%|▏         | 8/581 [00:10<12:51,  1.35s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 2:   1%|▏         | 8/581 [00:12<12:51,  1.35s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:   2%|▏         | 9/581 [00:12<12:48,  1.34s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:   2%|▏         | 9/581 [00:13<12:48,  1.34s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:   2%|▏         | 10/581 [00:13<12:46,  1.34s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:   2%|▏         | 10/581 [00:14<12:46,  1.34s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:   2%|▏         | 11/581 [00:14<12:44,  1.34s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:   2%|▏         | 11/581 [00:16<12:44,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:   2%|▏         | 12/581 [00:16<12:42,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:   2%|▏         | 12/581 [00:17<12:42,  1.34s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 2:   2%|▏         | 13/581 [00:17<12:42,  1.34s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 2:   2%|▏         | 13/581 [00:18<12:42,  1.34s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:   2%|▏         | 14/581 [00:18<12:42,  1.35s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:   2%|▏         | 14/581 [00:20<12:42,  1.35s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:   3%|▎         | 15/581 [00:20<12:41,  1.35s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:   3%|▎         | 15/581 [00:21<12:41,  1.35s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:   3%|▎         | 16/581 [00:21<12:38,  1.34s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:   3%|▎         | 16/581 [00:22<12:38,  1.34s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:   3%|▎         | 17/581 [00:22<12:38,  1.34s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:   3%|▎         | 17/581 [00:24<12:38,  1.34s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:   3%|▎         | 18/581 [00:24<12:38,  1.35s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:   3%|▎         | 18/581 [00:25<12:38,  1.35s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:   3%|▎         | 19/581 [00:25<12:35,  1.34s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:   3%|▎         | 19/581 [00:26<12:35,  1.34s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:   3%|▎         | 20/581 [00:26<12:34,  1.35s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:   3%|▎         | 20/581 [00:28<12:34,  1.35s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:   4%|▎         | 21/581 [00:28<12:33,  1.35s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:   4%|▎         | 21/581 [00:29<12:33,  1.35s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:   4%|▍         | 22/581 [00:29<12:33,  1.35s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:   4%|▍         | 22/581 [00:30<12:33,  1.35s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:   4%|▍         | 23/581 [00:30<12:33,  1.35s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:   4%|▍         | 23/581 [00:32<12:33,  1.35s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:   4%|▍         | 24/581 [00:32<12:33,  1.35s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:   4%|▍         | 24/581 [00:33<12:33,  1.35s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:   4%|▍         | 25/581 [00:33<12:31,  1.35s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:   4%|▍         | 25/581 [00:34<12:31,  1.35s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 2:   4%|▍         | 26/581 [00:34<12:29,  1.35s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 2:   4%|▍         | 26/581 [00:36<12:29,  1.35s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:   5%|▍         | 27/581 [00:36<12:26,  1.35s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:   5%|▍         | 27/581 [00:37<12:26,  1.35s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:   5%|▍         | 28/581 [00:37<12:25,  1.35s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:   5%|▍         | 28/581 [00:39<12:25,  1.35s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:   5%|▍         | 29/581 [00:39<12:24,  1.35s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:   5%|▍         | 29/581 [00:40<12:24,  1.35s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 2:   5%|▌         | 30/581 [00:40<12:20,  1.34s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 2:   5%|▌         | 30/581 [00:41<12:20,  1.34s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:   5%|▌         | 31/581 [00:41<12:20,  1.35s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:   5%|▌         | 31/581 [00:43<12:20,  1.35s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:   6%|▌         | 32/581 [00:43<12:18,  1.35s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:   6%|▌         | 32/581 [00:44<12:18,  1.35s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:   6%|▌         | 33/581 [00:44<12:16,  1.34s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:   6%|▌         | 33/581 [00:45<12:16,  1.34s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:   6%|▌         | 34/581 [00:45<12:15,  1.34s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:   6%|▌         | 34/581 [00:47<12:15,  1.34s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:   6%|▌         | 35/581 [00:47<12:15,  1.35s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:   6%|▌         | 35/581 [00:48<12:15,  1.35s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:   6%|▌         | 36/581 [00:48<12:13,  1.35s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:   6%|▌         | 36/581 [00:49<12:13,  1.35s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 2:   6%|▋         | 37/581 [00:49<12:11,  1.34s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 2:   6%|▋         | 37/581 [00:51<12:11,  1.34s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:   7%|▋         | 38/581 [00:51<12:08,  1.34s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:   7%|▋         | 38/581 [00:52<12:08,  1.34s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:   7%|▋         | 39/581 [00:52<12:08,  1.34s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:   7%|▋         | 39/581 [00:53<12:08,  1.34s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:   7%|▋         | 40/581 [00:53<12:08,  1.35s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:   7%|▋         | 40/581 [00:55<12:08,  1.35s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:   7%|▋         | 41/581 [00:55<12:06,  1.35s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:   7%|▋         | 41/581 [00:56<12:06,  1.35s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:   7%|▋         | 42/581 [00:56<12:06,  1.35s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:   7%|▋         | 42/581 [00:57<12:06,  1.35s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 2:   7%|▋         | 43/581 [00:57<12:03,  1.34s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 2:   7%|▋         | 43/581 [00:59<12:03,  1.34s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:   8%|▊         | 44/581 [00:59<12:01,  1.34s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:   8%|▊         | 44/581 [01:00<12:01,  1.34s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:   8%|▊         | 45/581 [01:00<12:02,  1.35s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:   8%|▊         | 45/581 [01:01<12:02,  1.35s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:   8%|▊         | 46/581 [01:01<12:01,  1.35s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:   8%|▊         | 46/581 [01:03<12:01,  1.35s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 2:   8%|▊         | 47/581 [01:03<11:59,  1.35s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 2:   8%|▊         | 47/581 [01:04<11:59,  1.35s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 2:   8%|▊         | 48/581 [01:04<11:59,  1.35s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 2:   8%|▊         | 48/581 [01:05<11:59,  1.35s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:   8%|▊         | 49/581 [01:05<11:57,  1.35s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:   8%|▊         | 49/581 [01:07<11:57,  1.35s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:   9%|▊         | 50/581 [01:07<11:55,  1.35s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:   9%|▊         | 50/581 [01:08<11:55,  1.35s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:   9%|▉         | 51/581 [01:08<11:51,  1.34s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:   9%|▉         | 51/581 [01:09<11:51,  1.34s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:   9%|▉         | 52/581 [01:09<11:48,  1.34s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:   9%|▉         | 52/581 [01:11<11:48,  1.34s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:   9%|▉         | 53/581 [01:11<11:48,  1.34s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:   9%|▉         | 53/581 [01:12<11:48,  1.34s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:   9%|▉         | 54/581 [01:12<11:46,  1.34s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:   9%|▉         | 54/581 [01:13<11:46,  1.34s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:   9%|▉         | 55/581 [01:13<11:45,  1.34s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:   9%|▉         | 55/581 [01:15<11:45,  1.34s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  10%|▉         | 56/581 [01:15<11:45,  1.34s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  10%|▉         | 56/581 [01:16<11:45,  1.34s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  10%|▉         | 57/581 [01:16<11:45,  1.35s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  10%|▉         | 57/581 [01:18<11:45,  1.35s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 2:  10%|▉         | 58/581 [01:18<11:42,  1.34s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 2:  10%|▉         | 58/581 [01:19<11:42,  1.34s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 2:  10%|█         | 59/581 [01:19<11:42,  1.35s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 2:  10%|█         | 59/581 [01:20<11:42,  1.35s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  10%|█         | 60/581 [01:20<11:40,  1.34s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  10%|█         | 60/581 [01:22<11:40,  1.34s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  10%|█         | 61/581 [01:22<11:37,  1.34s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  10%|█         | 61/581 [01:23<11:37,  1.34s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  11%|█         | 62/581 [01:23<11:35,  1.34s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  11%|█         | 62/581 [01:24<11:35,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  11%|█         | 63/581 [01:24<11:33,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  11%|█         | 63/581 [01:26<11:33,  1.34s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  11%|█         | 64/581 [01:26<11:33,  1.34s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  11%|█         | 64/581 [01:27<11:33,  1.34s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  11%|█         | 65/581 [01:27<11:31,  1.34s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  11%|█         | 65/581 [01:28<11:31,  1.34s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 66/581 [01:28<11:29,  1.34s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 66/581 [01:30<11:29,  1.34s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 67/581 [01:30<11:27,  1.34s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 67/581 [01:31<11:27,  1.34s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 68/581 [01:31<11:26,  1.34s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 68/581 [01:32<11:26,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 69/581 [01:32<11:24,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 69/581 [01:34<11:24,  1.34s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 70/581 [01:34<11:24,  1.34s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 70/581 [01:35<11:24,  1.34s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 71/581 [01:35<11:23,  1.34s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 71/581 [01:36<11:23,  1.34s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 72/581 [01:36<11:21,  1.34s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 72/581 [01:38<11:21,  1.34s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 73/581 [01:38<11:18,  1.34s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 73/581 [01:39<11:18,  1.34s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 74/581 [01:39<11:17,  1.34s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 74/581 [01:40<11:17,  1.34s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 75/581 [01:40<11:17,  1.34s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 75/581 [01:42<11:17,  1.34s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 76/581 [01:42<11:16,  1.34s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 76/581 [01:43<11:16,  1.34s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 77/581 [01:43<11:15,  1.34s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 77/581 [01:44<11:15,  1.34s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 78/581 [01:44<11:14,  1.34s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 78/581 [01:46<11:14,  1.34s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 79/581 [01:46<11:14,  1.34s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 79/581 [01:47<11:14,  1.34s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 80/581 [01:47<11:14,  1.35s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 80/581 [01:48<11:14,  1.35s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 81/581 [01:48<11:11,  1.34s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 81/581 [01:50<11:11,  1.34s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 82/581 [01:50<11:09,  1.34s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 82/581 [01:51<11:09,  1.34s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 83/581 [01:51<11:07,  1.34s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 83/581 [01:52<11:07,  1.34s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 84/581 [01:52<11:06,  1.34s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 84/581 [01:54<11:06,  1.34s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 85/581 [01:54<11:06,  1.34s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 85/581 [01:55<11:06,  1.34s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 86/581 [01:55<11:04,  1.34s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 86/581 [01:56<11:04,  1.34s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 87/581 [01:56<11:04,  1.34s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 87/581 [01:58<11:04,  1.34s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 88/581 [01:58<11:02,  1.34s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 88/581 [01:59<11:02,  1.34s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 89/581 [01:59<11:01,  1.35s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 89/581 [02:00<11:01,  1.35s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 90/581 [02:00<10:59,  1.34s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 90/581 [02:02<10:59,  1.34s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 91/581 [02:02<10:56,  1.34s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 91/581 [02:03<10:56,  1.34s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 92/581 [02:03<10:54,  1.34s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 92/581 [02:04<10:54,  1.34s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 93/581 [02:04<10:53,  1.34s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 93/581 [02:06<10:53,  1.34s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 94/581 [02:06<10:53,  1.34s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 94/581 [02:07<10:53,  1.34s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 95/581 [02:07<10:52,  1.34s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 95/581 [02:08<10:52,  1.34s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 96/581 [02:08<10:50,  1.34s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 96/581 [02:10<10:50,  1.34s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 97/581 [02:10<10:49,  1.34s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 97/581 [02:11<10:49,  1.34s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 98/581 [02:11<10:47,  1.34s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 98/581 [02:12<10:47,  1.34s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 99/581 [02:13<10:46,  1.34s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 99/581 [02:14<10:46,  1.34s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 100/581 [02:14<10:44,  1.34s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 100/581 [02:15<10:44,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 101/581 [02:15<10:42,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 101/581 [02:17<10:42,  1.34s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 102/581 [02:17<10:41,  1.34s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 102/581 [02:18<10:41,  1.34s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 103/581 [02:18<10:40,  1.34s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 103/581 [02:19<10:40,  1.34s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 104/581 [02:19<10:39,  1.34s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 104/581 [02:21<10:39,  1.34s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 105/581 [02:21<10:37,  1.34s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 105/581 [02:22<10:37,  1.34s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 106/581 [02:22<10:35,  1.34s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 106/581 [02:23<10:35,  1.34s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 107/581 [02:23<10:34,  1.34s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 107/581 [02:25<10:34,  1.34s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 108/581 [02:25<10:35,  1.34s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 108/581 [02:26<10:35,  1.34s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 109/581 [02:26<10:34,  1.34s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 109/581 [02:27<10:34,  1.34s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 110/581 [02:27<10:32,  1.34s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 110/581 [02:29<10:32,  1.34s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 111/581 [02:29<10:32,  1.35s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 111/581 [02:30<10:32,  1.35s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 112/581 [02:30<10:31,  1.35s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 112/581 [02:31<10:31,  1.35s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 113/581 [02:31<10:30,  1.35s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 113/581 [02:33<10:30,  1.35s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 114/581 [02:33<10:28,  1.35s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 114/581 [02:34<10:28,  1.35s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 115/581 [02:34<10:27,  1.35s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 115/581 [02:35<10:27,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 116/581 [02:35<10:25,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 116/581 [02:37<10:25,  1.35s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  20%|██        | 117/581 [02:37<10:26,  1.35s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  20%|██        | 117/581 [02:38<10:26,  1.35s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  20%|██        | 118/581 [02:38<10:26,  1.35s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  20%|██        | 118/581 [02:39<10:26,  1.35s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  20%|██        | 119/581 [02:39<10:25,  1.35s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  20%|██        | 119/581 [02:41<10:25,  1.35s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  21%|██        | 120/581 [02:41<10:25,  1.36s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  21%|██        | 120/581 [02:42<10:25,  1.36s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  21%|██        | 121/581 [02:42<10:22,  1.35s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  21%|██        | 121/581 [02:43<10:22,  1.35s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  21%|██        | 122/581 [02:43<10:19,  1.35s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  21%|██        | 122/581 [02:45<10:19,  1.35s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  21%|██        | 123/581 [02:45<10:16,  1.35s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  21%|██        | 123/581 [02:46<10:16,  1.35s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 124/581 [02:46<10:13,  1.34s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 124/581 [02:47<10:13,  1.34s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 125/581 [02:47<10:12,  1.34s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 125/581 [02:49<10:12,  1.34s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 126/581 [02:49<10:10,  1.34s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 126/581 [02:50<10:10,  1.34s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 127/581 [02:50<10:08,  1.34s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 127/581 [02:51<10:08,  1.34s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 128/581 [02:51<10:08,  1.34s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 128/581 [02:53<10:08,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 129/581 [02:53<10:07,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 129/581 [02:54<10:07,  1.34s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 130/581 [02:54<10:05,  1.34s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 130/581 [02:56<10:05,  1.34s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 131/581 [02:56<10:04,  1.34s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 131/581 [02:57<10:04,  1.34s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 132/581 [02:57<10:04,  1.35s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 132/581 [02:58<10:04,  1.35s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 133/581 [02:58<10:03,  1.35s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 133/581 [03:00<10:03,  1.35s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 134/581 [03:00<10:02,  1.35s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 134/581 [03:01<10:02,  1.35s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 135/581 [03:01<09:59,  1.35s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 135/581 [03:02<09:59,  1.35s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 136/581 [03:02<09:59,  1.35s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 136/581 [03:04<09:59,  1.35s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 137/581 [03:04<09:57,  1.35s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 137/581 [03:05<09:57,  1.35s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 138/581 [03:05<09:56,  1.35s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 138/581 [03:06<09:56,  1.35s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 139/581 [03:06<09:53,  1.34s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 139/581 [03:08<09:53,  1.34s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 140/581 [03:08<09:53,  1.35s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 140/581 [03:09<09:53,  1.35s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 141/581 [03:09<09:51,  1.34s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 141/581 [03:10<09:51,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 142/581 [03:10<09:50,  1.35s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 142/581 [03:12<09:50,  1.35s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 143/581 [03:12<09:48,  1.34s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 143/581 [03:13<09:48,  1.34s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 144/581 [03:13<09:48,  1.35s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 144/581 [03:14<09:48,  1.35s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 145/581 [03:14<09:47,  1.35s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 145/581 [03:16<09:47,  1.35s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 146/581 [03:16<09:44,  1.34s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 146/581 [03:17<09:44,  1.34s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 147/581 [03:17<09:42,  1.34s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 147/581 [03:18<09:42,  1.34s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 148/581 [03:18<09:41,  1.34s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 148/581 [03:20<09:41,  1.34s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 149/581 [03:20<09:39,  1.34s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 149/581 [03:21<09:39,  1.34s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 150/581 [03:21<09:37,  1.34s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 150/581 [03:22<09:37,  1.34s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 151/581 [03:22<09:38,  1.35s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 151/581 [03:24<09:38,  1.35s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 152/581 [03:24<09:37,  1.35s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 152/581 [03:25<09:37,  1.35s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 153/581 [03:25<09:35,  1.34s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 153/581 [03:26<09:35,  1.34s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 154/581 [03:26<09:35,  1.35s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 154/581 [03:28<09:35,  1.35s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 155/581 [03:28<09:33,  1.35s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 155/581 [03:29<09:33,  1.35s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 156/581 [03:29<09:30,  1.34s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 156/581 [03:30<09:30,  1.34s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 157/581 [03:31<09:29,  1.34s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 157/581 [03:32<09:29,  1.34s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 158/581 [03:32<09:29,  1.35s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 158/581 [03:33<09:29,  1.35s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 159/581 [03:33<09:27,  1.35s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 159/581 [03:35<09:27,  1.35s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 160/581 [03:35<09:25,  1.34s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 160/581 [03:36<09:25,  1.34s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 161/581 [03:36<09:24,  1.34s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 161/581 [03:37<09:24,  1.34s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 162/581 [03:37<09:21,  1.34s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 162/581 [03:39<09:21,  1.34s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 163/581 [03:39<09:20,  1.34s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 163/581 [03:40<09:20,  1.34s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 164/581 [03:40<09:18,  1.34s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 164/581 [03:41<09:18,  1.34s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 165/581 [03:41<09:16,  1.34s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 165/581 [03:43<09:16,  1.34s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 166/581 [03:43<09:16,  1.34s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 166/581 [03:44<09:16,  1.34s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 167/581 [03:44<09:16,  1.35s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 167/581 [03:45<09:16,  1.35s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 168/581 [03:45<09:15,  1.34s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 168/581 [03:47<09:15,  1.34s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 169/581 [03:47<09:12,  1.34s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 169/581 [03:48<09:12,  1.34s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 170/581 [03:48<09:11,  1.34s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 170/581 [03:49<09:11,  1.34s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 171/581 [03:49<09:11,  1.34s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 171/581 [03:51<09:11,  1.34s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 172/581 [03:51<09:09,  1.34s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 172/581 [03:52<09:09,  1.34s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 173/581 [03:52<09:08,  1.34s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 173/581 [03:53<09:08,  1.34s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 174/581 [03:53<09:08,  1.35s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 174/581 [03:55<09:08,  1.35s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  30%|███       | 175/581 [03:55<09:06,  1.35s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  30%|███       | 175/581 [03:56<09:06,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  30%|███       | 176/581 [03:56<09:06,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  30%|███       | 176/581 [03:57<09:06,  1.35s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  30%|███       | 177/581 [03:57<09:05,  1.35s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  30%|███       | 177/581 [03:59<09:05,  1.35s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  31%|███       | 178/581 [03:59<09:04,  1.35s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  31%|███       | 178/581 [04:00<09:04,  1.35s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 2:  31%|███       | 179/581 [04:00<09:02,  1.35s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 2:  31%|███       | 179/581 [04:01<09:02,  1.35s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  31%|███       | 180/581 [04:01<09:01,  1.35s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  31%|███       | 180/581 [04:03<09:01,  1.35s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  31%|███       | 181/581 [04:03<08:59,  1.35s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  31%|███       | 181/581 [04:04<08:59,  1.35s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 182/581 [04:04<08:58,  1.35s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 182/581 [04:05<08:58,  1.35s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 183/581 [04:05<08:56,  1.35s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 183/581 [04:07<08:56,  1.35s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 184/581 [04:07<08:53,  1.34s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 184/581 [04:08<08:53,  1.34s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 185/581 [04:08<08:52,  1.34s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 185/581 [04:09<08:52,  1.34s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 186/581 [04:10<08:51,  1.34s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 186/581 [04:11<08:51,  1.34s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 187/581 [04:11<08:50,  1.35s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 187/581 [04:12<08:50,  1.35s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 188/581 [04:12<08:49,  1.35s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 188/581 [04:14<08:49,  1.35s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 189/581 [04:14<08:47,  1.35s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 189/581 [04:15<08:47,  1.35s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 190/581 [04:15<08:47,  1.35s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 190/581 [04:16<08:47,  1.35s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 191/581 [04:16<08:45,  1.35s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 191/581 [04:18<08:45,  1.35s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 192/581 [04:18<08:43,  1.35s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 192/581 [04:19<08:43,  1.35s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 193/581 [04:19<08:41,  1.34s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 193/581 [04:20<08:41,  1.34s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 194/581 [04:20<08:38,  1.34s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 194/581 [04:22<08:38,  1.34s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 195/581 [04:22<08:37,  1.34s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 195/581 [04:23<08:37,  1.34s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 196/581 [04:23<08:36,  1.34s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 196/581 [04:24<08:36,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 197/581 [04:24<08:35,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 197/581 [04:26<08:35,  1.34s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 198/581 [04:26<08:34,  1.34s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 198/581 [04:27<08:34,  1.34s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 199/581 [04:27<08:33,  1.34s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 199/581 [04:28<08:33,  1.34s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 200/581 [04:28<08:30,  1.34s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 200/581 [04:30<08:30,  1.34s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 201/581 [04:30<08:30,  1.34s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 201/581 [04:31<08:30,  1.34s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 202/581 [04:31<08:30,  1.35s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 202/581 [04:32<08:30,  1.35s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 203/581 [04:32<08:28,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 203/581 [04:34<08:28,  1.34s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 204/581 [04:34<08:27,  1.35s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 204/581 [04:35<08:27,  1.35s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 205/581 [04:35<08:26,  1.35s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 205/581 [04:36<08:26,  1.35s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 206/581 [04:36<08:23,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 206/581 [04:38<08:23,  1.34s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 207/581 [04:38<08:22,  1.34s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 207/581 [04:39<08:22,  1.34s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 208/581 [04:39<08:22,  1.35s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 208/581 [04:40<08:22,  1.35s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 209/581 [04:40<08:20,  1.35s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 209/581 [04:42<08:20,  1.35s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 210/581 [04:42<08:19,  1.35s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 210/581 [04:43<08:19,  1.35s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 211/581 [04:43<08:18,  1.35s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 211/581 [04:44<08:18,  1.35s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 212/581 [04:44<08:16,  1.34s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 212/581 [04:46<08:16,  1.34s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 213/581 [04:46<08:14,  1.34s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 213/581 [04:47<08:14,  1.34s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 214/581 [04:47<08:13,  1.34s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 214/581 [04:48<08:13,  1.34s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 215/581 [04:48<08:11,  1.34s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 215/581 [04:50<08:11,  1.34s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 216/581 [04:50<08:10,  1.34s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 216/581 [04:51<08:10,  1.34s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 217/581 [04:51<08:08,  1.34s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 217/581 [04:53<08:08,  1.34s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 218/581 [04:53<08:07,  1.34s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 218/581 [04:54<08:07,  1.34s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 219/581 [04:54<08:06,  1.34s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 219/581 [04:55<08:06,  1.34s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 220/581 [04:55<08:05,  1.34s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 220/581 [04:57<08:05,  1.34s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 221/581 [04:57<08:04,  1.34s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 221/581 [04:58<08:04,  1.34s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 222/581 [04:58<08:03,  1.35s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 222/581 [04:59<08:03,  1.35s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 223/581 [04:59<08:02,  1.35s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 223/581 [05:01<08:02,  1.35s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 224/581 [05:01<08:00,  1.35s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 224/581 [05:02<08:00,  1.35s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 225/581 [05:02<07:59,  1.35s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 225/581 [05:03<07:59,  1.35s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 226/581 [05:03<07:58,  1.35s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 226/581 [05:05<07:58,  1.35s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 227/581 [05:05<07:57,  1.35s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 227/581 [05:06<07:57,  1.35s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 228/581 [05:06<07:55,  1.35s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 228/581 [05:07<07:55,  1.35s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 229/581 [05:07<07:54,  1.35s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 229/581 [05:09<07:54,  1.35s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 230/581 [05:09<07:52,  1.34s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 230/581 [05:10<07:52,  1.34s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 231/581 [05:10<07:50,  1.34s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 231/581 [05:11<07:50,  1.34s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 232/581 [05:11<07:49,  1.34s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 232/581 [05:13<07:49,  1.34s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  40%|████      | 233/581 [05:13<07:49,  1.35s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  40%|████      | 233/581 [05:14<07:49,  1.35s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  40%|████      | 234/581 [05:14<07:48,  1.35s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  40%|████      | 234/581 [05:15<07:48,  1.35s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  40%|████      | 235/581 [05:15<07:46,  1.35s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  40%|████      | 235/581 [05:17<07:46,  1.35s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  41%|████      | 236/581 [05:17<07:44,  1.35s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  41%|████      | 236/581 [05:18<07:44,  1.35s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  41%|████      | 237/581 [05:18<07:42,  1.34s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  41%|████      | 237/581 [05:19<07:42,  1.34s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  41%|████      | 238/581 [05:19<07:41,  1.35s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  41%|████      | 238/581 [05:21<07:41,  1.35s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  41%|████      | 239/581 [05:21<07:40,  1.35s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  41%|████      | 239/581 [05:22<07:40,  1.35s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 240/581 [05:22<07:38,  1.34s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 240/581 [05:23<07:38,  1.34s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 241/581 [05:24<07:37,  1.35s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 241/581 [05:25<07:37,  1.35s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 242/581 [05:25<07:36,  1.35s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 242/581 [05:26<07:36,  1.35s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 243/581 [05:26<07:35,  1.35s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 243/581 [05:28<07:35,  1.35s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 244/581 [05:28<07:33,  1.34s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 244/581 [05:29<07:33,  1.34s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 245/581 [05:29<07:31,  1.34s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 245/581 [05:30<07:31,  1.34s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 246/581 [05:30<07:31,  1.35s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 246/581 [05:32<07:31,  1.35s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 247/581 [05:32<07:29,  1.35s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 247/581 [05:33<07:29,  1.35s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 248/581 [05:33<07:28,  1.35s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 248/581 [05:34<07:28,  1.35s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 249/581 [05:34<07:26,  1.35s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 249/581 [05:36<07:26,  1.35s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 250/581 [05:36<07:25,  1.35s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 250/581 [05:37<07:25,  1.35s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 251/581 [05:37<07:24,  1.35s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 251/581 [05:38<07:24,  1.35s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 252/581 [05:38<07:23,  1.35s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 252/581 [05:40<07:23,  1.35s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 253/581 [05:40<07:22,  1.35s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 253/581 [05:41<07:22,  1.35s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 254/581 [05:41<07:21,  1.35s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 254/581 [05:42<07:21,  1.35s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 255/581 [05:42<07:19,  1.35s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 255/581 [05:44<07:19,  1.35s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 256/581 [05:44<07:18,  1.35s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 256/581 [05:45<07:18,  1.35s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 257/581 [05:45<07:17,  1.35s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 257/581 [05:46<07:17,  1.35s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 258/581 [05:46<07:15,  1.35s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 258/581 [05:48<07:15,  1.35s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 259/581 [05:48<07:14,  1.35s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 259/581 [05:49<07:14,  1.35s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 260/581 [05:49<07:13,  1.35s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 260/581 [05:50<07:13,  1.35s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 261/581 [05:50<07:10,  1.35s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 261/581 [05:52<07:10,  1.35s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 262/581 [05:52<07:10,  1.35s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 262/581 [05:53<07:10,  1.35s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 263/581 [05:53<07:08,  1.35s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 263/581 [05:54<07:08,  1.35s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 264/581 [05:54<07:06,  1.35s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 264/581 [05:56<07:06,  1.35s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 265/581 [05:56<07:05,  1.35s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 265/581 [05:57<07:05,  1.35s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 266/581 [05:57<07:04,  1.35s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 266/581 [05:59<07:04,  1.35s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 267/581 [05:59<07:02,  1.34s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 267/581 [06:00<07:02,  1.34s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 268/581 [06:00<07:01,  1.35s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 268/581 [06:01<07:01,  1.35s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 269/581 [06:01<06:59,  1.34s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 269/581 [06:03<06:59,  1.34s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 270/581 [06:03<06:57,  1.34s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 270/581 [06:04<06:57,  1.34s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 271/581 [06:04<06:55,  1.34s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 271/581 [06:05<06:55,  1.34s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 272/581 [06:05<06:54,  1.34s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 272/581 [06:07<06:54,  1.34s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 273/581 [06:07<06:53,  1.34s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 273/581 [06:08<06:53,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 274/581 [06:08<06:51,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 274/581 [06:09<06:51,  1.34s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 275/581 [06:09<06:50,  1.34s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 275/581 [06:11<06:50,  1.34s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 276/581 [06:11<06:48,  1.34s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 276/581 [06:12<06:48,  1.34s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 277/581 [06:12<06:46,  1.34s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 277/581 [06:13<06:46,  1.34s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 278/581 [06:13<06:45,  1.34s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 278/581 [06:15<06:45,  1.34s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 279/581 [06:15<06:43,  1.34s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 279/581 [06:16<06:43,  1.34s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 280/581 [06:16<06:42,  1.34s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 280/581 [06:17<06:42,  1.34s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 281/581 [06:17<06:42,  1.34s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 281/581 [06:19<06:42,  1.34s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 282/581 [06:19<06:40,  1.34s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 282/581 [06:20<06:40,  1.34s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 283/581 [06:20<06:39,  1.34s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 283/581 [06:21<06:39,  1.34s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 284/581 [06:21<06:37,  1.34s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 284/581 [06:23<06:37,  1.34s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 285/581 [06:23<06:37,  1.34s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 285/581 [06:24<06:37,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 286/581 [06:24<06:35,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 286/581 [06:25<06:35,  1.34s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 287/581 [06:25<06:35,  1.34s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 287/581 [06:27<06:35,  1.34s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 288/581 [06:27<06:33,  1.34s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 288/581 [06:28<06:33,  1.34s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 289/581 [06:28<06:31,  1.34s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 289/581 [06:29<06:31,  1.34s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 290/581 [06:29<06:30,  1.34s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 290/581 [06:31<06:30,  1.34s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  50%|█████     | 291/581 [06:31<06:28,  1.34s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  50%|█████     | 291/581 [06:32<06:28,  1.34s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  50%|█████     | 292/581 [06:32<06:27,  1.34s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  50%|█████     | 292/581 [06:33<06:27,  1.34s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  50%|█████     | 293/581 [06:33<06:26,  1.34s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  50%|█████     | 293/581 [06:35<06:26,  1.34s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  51%|█████     | 294/581 [06:35<06:24,  1.34s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  51%|█████     | 294/581 [06:36<06:24,  1.34s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  51%|█████     | 295/581 [06:36<06:23,  1.34s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  51%|█████     | 295/581 [06:37<06:23,  1.34s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  51%|█████     | 296/581 [06:37<06:24,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  51%|█████     | 296/581 [06:39<06:24,  1.35s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  51%|█████     | 297/581 [06:39<06:23,  1.35s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  51%|█████     | 297/581 [06:40<06:23,  1.35s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 298/581 [06:40<06:21,  1.35s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 298/581 [06:41<06:21,  1.35s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 299/581 [06:41<06:18,  1.34s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 299/581 [06:43<06:18,  1.34s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 300/581 [06:43<06:16,  1.34s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 300/581 [06:44<06:16,  1.34s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 301/581 [06:44<06:15,  1.34s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 301/581 [06:45<06:15,  1.34s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 302/581 [06:45<06:14,  1.34s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 302/581 [06:47<06:14,  1.34s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 303/581 [06:47<06:14,  1.35s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 303/581 [06:48<06:14,  1.35s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 304/581 [06:48<06:12,  1.34s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 304/581 [06:50<06:12,  1.34s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 305/581 [06:50<06:11,  1.35s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 305/581 [06:51<06:11,  1.35s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 306/581 [06:51<06:09,  1.35s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 306/581 [06:52<06:09,  1.35s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 307/581 [06:52<06:08,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 307/581 [06:54<06:08,  1.34s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 308/581 [06:54<06:06,  1.34s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 308/581 [06:55<06:06,  1.34s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 309/581 [06:55<06:04,  1.34s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 309/581 [06:56<06:04,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 310/581 [06:56<06:04,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 310/581 [06:58<06:04,  1.34s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 311/581 [06:58<06:04,  1.35s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 311/581 [06:59<06:04,  1.35s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 312/581 [06:59<06:02,  1.35s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 312/581 [07:00<06:02,  1.35s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 313/581 [07:00<06:02,  1.35s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 313/581 [07:02<06:02,  1.35s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 314/581 [07:02<05:59,  1.35s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 314/581 [07:03<05:59,  1.35s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 315/581 [07:03<05:58,  1.35s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 315/581 [07:04<05:58,  1.35s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 316/581 [07:04<05:56,  1.35s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 316/581 [07:06<05:56,  1.35s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 317/581 [07:06<05:54,  1.34s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 317/581 [07:07<05:54,  1.34s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 318/581 [07:07<05:52,  1.34s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 318/581 [07:08<05:52,  1.34s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 319/581 [07:08<05:51,  1.34s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 319/581 [07:10<05:51,  1.34s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 320/581 [07:10<05:49,  1.34s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 320/581 [07:11<05:49,  1.34s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 321/581 [07:11<05:48,  1.34s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 321/581 [07:12<05:48,  1.34s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 322/581 [07:12<05:47,  1.34s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 322/581 [07:14<05:47,  1.34s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 323/581 [07:14<05:45,  1.34s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 323/581 [07:15<05:45,  1.34s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 324/581 [07:15<05:43,  1.34s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 324/581 [07:16<05:43,  1.34s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 325/581 [07:16<05:43,  1.34s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 325/581 [07:18<05:43,  1.34s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 326/581 [07:18<05:42,  1.34s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 326/581 [07:19<05:42,  1.34s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 327/581 [07:19<05:41,  1.34s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 327/581 [07:20<05:41,  1.34s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 328/581 [07:20<05:39,  1.34s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 328/581 [07:22<05:39,  1.34s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 329/581 [07:22<05:37,  1.34s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 329/581 [07:23<05:37,  1.34s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 330/581 [07:23<05:36,  1.34s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 330/581 [07:24<05:36,  1.34s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 331/581 [07:24<05:37,  1.35s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 331/581 [07:26<05:37,  1.35s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 332/581 [07:26<05:35,  1.35s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 332/581 [07:27<05:35,  1.35s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 333/581 [07:27<05:33,  1.35s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 333/581 [07:28<05:33,  1.35s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 334/581 [07:28<05:31,  1.34s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 334/581 [07:30<05:31,  1.34s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 335/581 [07:30<05:30,  1.34s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 335/581 [07:31<05:30,  1.34s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 336/581 [07:31<05:28,  1.34s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 336/581 [07:32<05:28,  1.34s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 337/581 [07:33<05:27,  1.34s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 337/581 [07:34<05:27,  1.34s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 338/581 [07:34<05:26,  1.34s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 338/581 [07:35<05:26,  1.34s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 339/581 [07:35<05:24,  1.34s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 339/581 [07:37<05:24,  1.34s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 340/581 [07:37<05:24,  1.35s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 340/581 [07:38<05:24,  1.35s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 341/581 [07:38<05:22,  1.35s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 341/581 [07:39<05:22,  1.35s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 342/581 [07:39<05:20,  1.34s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 342/581 [07:41<05:20,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 343/581 [07:41<05:19,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 343/581 [07:42<05:19,  1.34s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 344/581 [07:42<05:19,  1.35s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 344/581 [07:43<05:19,  1.35s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 345/581 [07:43<05:18,  1.35s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 345/581 [07:45<05:18,  1.35s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 346/581 [07:45<05:16,  1.35s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 346/581 [07:46<05:16,  1.35s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 347/581 [07:46<05:16,  1.35s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 347/581 [07:47<05:16,  1.35s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 348/581 [07:47<05:13,  1.35s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 348/581 [07:49<05:13,  1.35s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  60%|██████    | 349/581 [07:49<05:12,  1.35s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  60%|██████    | 349/581 [07:50<05:12,  1.35s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  60%|██████    | 350/581 [07:50<05:11,  1.35s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  60%|██████    | 350/581 [07:51<05:11,  1.35s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  60%|██████    | 351/581 [07:51<05:10,  1.35s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  60%|██████    | 351/581 [07:53<05:10,  1.35s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  61%|██████    | 352/581 [07:53<05:09,  1.35s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  61%|██████    | 352/581 [07:54<05:09,  1.35s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 2:  61%|██████    | 353/581 [07:54<05:08,  1.35s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 2:  61%|██████    | 353/581 [07:55<05:08,  1.35s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  61%|██████    | 354/581 [07:55<05:06,  1.35s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  61%|██████    | 354/581 [07:57<05:06,  1.35s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 2:  61%|██████    | 355/581 [07:57<05:05,  1.35s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 2:  61%|██████    | 355/581 [07:58<05:05,  1.35s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 356/581 [07:58<05:04,  1.35s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 356/581 [07:59<05:04,  1.35s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 357/581 [07:59<05:03,  1.35s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 357/581 [08:01<05:03,  1.35s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 358/581 [08:01<05:01,  1.35s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 358/581 [08:02<05:01,  1.35s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 359/581 [08:02<05:00,  1.35s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 359/581 [08:04<05:00,  1.35s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 360/581 [08:04<04:58,  1.35s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 360/581 [08:05<04:58,  1.35s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 361/581 [08:05<04:56,  1.35s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 361/581 [08:06<04:56,  1.35s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 362/581 [08:06<04:55,  1.35s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 362/581 [08:08<04:55,  1.35s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 363/581 [08:08<04:53,  1.35s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 363/581 [08:09<04:53,  1.35s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 364/581 [08:09<04:52,  1.35s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 364/581 [08:10<04:52,  1.35s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 365/581 [08:10<04:51,  1.35s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 365/581 [08:12<04:51,  1.35s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 366/581 [08:12<04:49,  1.34s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 366/581 [08:13<04:49,  1.34s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 367/581 [08:13<04:48,  1.35s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 367/581 [08:14<04:48,  1.35s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 368/581 [08:14<04:47,  1.35s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 368/581 [08:16<04:47,  1.35s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 369/581 [08:16<04:45,  1.35s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 369/581 [08:17<04:45,  1.35s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 370/581 [08:17<04:43,  1.34s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 370/581 [08:18<04:43,  1.34s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 371/581 [08:18<04:43,  1.35s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 371/581 [08:20<04:43,  1.35s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 372/581 [08:20<04:42,  1.35s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 372/581 [08:21<04:42,  1.35s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 373/581 [08:21<04:40,  1.35s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 373/581 [08:22<04:40,  1.35s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 374/581 [08:22<04:38,  1.34s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 374/581 [08:24<04:38,  1.34s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 375/581 [08:24<04:36,  1.34s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 375/581 [08:25<04:36,  1.34s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 376/581 [08:25<04:34,  1.34s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 376/581 [08:26<04:34,  1.34s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 377/581 [08:26<04:33,  1.34s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 377/581 [08:28<04:33,  1.34s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 378/581 [08:28<04:32,  1.34s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 378/581 [08:29<04:32,  1.34s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 379/581 [08:29<04:30,  1.34s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 379/581 [08:30<04:30,  1.34s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 380/581 [08:30<04:29,  1.34s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 380/581 [08:32<04:29,  1.34s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 381/581 [08:32<04:27,  1.34s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 381/581 [08:33<04:27,  1.34s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 382/581 [08:33<04:26,  1.34s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 382/581 [08:34<04:26,  1.34s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 383/581 [08:34<04:25,  1.34s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 383/581 [08:36<04:25,  1.34s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 384/581 [08:36<04:24,  1.34s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 384/581 [08:37<04:24,  1.34s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 385/581 [08:37<04:23,  1.34s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 385/581 [08:38<04:23,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 386/581 [08:38<04:21,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 386/581 [08:40<04:21,  1.34s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 387/581 [08:40<04:19,  1.34s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 387/581 [08:41<04:19,  1.34s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 388/581 [08:41<04:18,  1.34s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 388/581 [08:42<04:18,  1.34s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 389/581 [08:43<04:17,  1.34s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 389/581 [08:44<04:17,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 390/581 [08:44<04:16,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 390/581 [08:45<04:16,  1.34s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 391/581 [08:45<04:15,  1.35s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 391/581 [08:47<04:15,  1.35s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 392/581 [08:47<04:13,  1.34s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 392/581 [08:48<04:13,  1.34s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 393/581 [08:48<04:12,  1.34s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 393/581 [08:49<04:12,  1.34s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 394/581 [08:49<04:10,  1.34s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 394/581 [08:51<04:10,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 395/581 [08:51<04:09,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 395/581 [08:52<04:09,  1.34s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 396/581 [08:52<04:08,  1.34s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 396/581 [08:53<04:08,  1.34s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 397/581 [08:53<04:07,  1.35s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 397/581 [08:55<04:07,  1.35s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 398/581 [08:55<04:06,  1.35s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 398/581 [08:56<04:06,  1.35s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 399/581 [08:56<04:04,  1.34s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 399/581 [08:57<04:04,  1.34s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 400/581 [08:57<04:02,  1.34s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 400/581 [08:59<04:02,  1.34s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 401/581 [08:59<04:01,  1.34s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 401/581 [09:00<04:01,  1.34s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 402/581 [09:00<04:00,  1.34s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 402/581 [09:01<04:00,  1.34s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 403/581 [09:01<03:59,  1.34s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 403/581 [09:03<03:59,  1.34s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 404/581 [09:03<03:58,  1.35s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 404/581 [09:04<03:58,  1.35s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 405/581 [09:04<03:57,  1.35s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 405/581 [09:05<03:57,  1.35s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 406/581 [09:05<03:55,  1.35s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 406/581 [09:07<03:55,  1.35s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  70%|███████   | 407/581 [09:07<03:53,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  70%|███████   | 407/581 [09:08<03:53,  1.34s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  70%|███████   | 408/581 [09:08<03:52,  1.34s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  70%|███████   | 408/581 [09:09<03:52,  1.34s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  70%|███████   | 409/581 [09:09<03:50,  1.34s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  70%|███████   | 409/581 [09:11<03:50,  1.34s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  71%|███████   | 410/581 [09:11<03:49,  1.34s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  71%|███████   | 410/581 [09:12<03:49,  1.34s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  71%|███████   | 411/581 [09:12<03:47,  1.34s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  71%|███████   | 411/581 [09:13<03:47,  1.34s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  71%|███████   | 412/581 [09:13<03:46,  1.34s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  71%|███████   | 412/581 [09:15<03:46,  1.34s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  71%|███████   | 413/581 [09:15<03:45,  1.34s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  71%|███████   | 413/581 [09:16<03:45,  1.34s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 414/581 [09:16<03:44,  1.34s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 414/581 [09:17<03:44,  1.34s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 415/581 [09:17<03:42,  1.34s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 415/581 [09:19<03:42,  1.34s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 416/581 [09:19<03:41,  1.35s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 416/581 [09:20<03:41,  1.35s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 417/581 [09:20<03:41,  1.35s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 417/581 [09:21<03:41,  1.35s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 418/581 [09:21<03:39,  1.35s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 418/581 [09:23<03:39,  1.35s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 419/581 [09:23<03:37,  1.34s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 419/581 [09:24<03:37,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 420/581 [09:24<03:36,  1.35s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 420/581 [09:26<03:36,  1.35s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 421/581 [09:26<03:35,  1.34s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 421/581 [09:27<03:35,  1.34s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 422/581 [09:27<03:33,  1.34s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 422/581 [09:28<03:33,  1.34s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 423/581 [09:28<03:31,  1.34s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 423/581 [09:30<03:31,  1.34s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 424/581 [09:30<03:30,  1.34s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 424/581 [09:31<03:30,  1.34s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 425/581 [09:31<03:29,  1.34s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 425/581 [09:32<03:29,  1.34s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 426/581 [09:32<03:28,  1.35s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 426/581 [09:34<03:28,  1.35s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 427/581 [09:34<03:27,  1.34s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 427/581 [09:35<03:27,  1.34s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 428/581 [09:35<03:25,  1.35s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 428/581 [09:36<03:25,  1.35s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 429/581 [09:36<03:24,  1.35s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 429/581 [09:38<03:24,  1.35s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 430/581 [09:38<03:22,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 430/581 [09:39<03:22,  1.34s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 431/581 [09:39<03:22,  1.35s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 431/581 [09:40<03:22,  1.35s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 432/581 [09:40<03:20,  1.35s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 432/581 [09:42<03:20,  1.35s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 433/581 [09:42<03:19,  1.35s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 433/581 [09:43<03:19,  1.35s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 434/581 [09:43<03:18,  1.35s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 434/581 [09:44<03:18,  1.35s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 435/581 [09:44<03:17,  1.35s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 435/581 [09:46<03:17,  1.35s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 436/581 [09:46<03:15,  1.35s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 436/581 [09:47<03:15,  1.35s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 437/581 [09:47<03:14,  1.35s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 437/581 [09:48<03:14,  1.35s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 438/581 [09:48<03:12,  1.35s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 438/581 [09:50<03:12,  1.35s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 439/581 [09:50<03:11,  1.35s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 439/581 [09:51<03:11,  1.35s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 440/581 [09:51<03:09,  1.34s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 440/581 [09:52<03:09,  1.34s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 441/581 [09:52<03:08,  1.34s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 441/581 [09:54<03:08,  1.34s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 442/581 [09:54<03:07,  1.35s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 442/581 [09:55<03:07,  1.35s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 443/581 [09:55<03:06,  1.35s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 443/581 [09:56<03:06,  1.35s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 444/581 [09:56<03:04,  1.35s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 444/581 [09:58<03:04,  1.35s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 445/581 [09:58<03:02,  1.34s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 445/581 [09:59<03:02,  1.34s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 446/581 [09:59<03:01,  1.34s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 446/581 [10:00<03:01,  1.34s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 447/581 [10:01<03:00,  1.35s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 447/581 [10:02<03:00,  1.35s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 448/581 [10:02<02:59,  1.35s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 448/581 [10:03<02:59,  1.35s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 449/581 [10:03<02:57,  1.35s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 449/581 [10:05<02:57,  1.35s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 450/581 [10:05<02:56,  1.35s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 450/581 [10:06<02:56,  1.35s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 451/581 [10:06<02:55,  1.35s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 451/581 [10:07<02:55,  1.35s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 452/581 [10:07<02:53,  1.34s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 452/581 [10:09<02:53,  1.34s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 453/581 [10:09<02:51,  1.34s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 453/581 [10:10<02:51,  1.34s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 454/581 [10:10<02:50,  1.34s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 454/581 [10:11<02:50,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 455/581 [10:11<02:48,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 455/581 [10:13<02:48,  1.34s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 456/581 [10:13<02:47,  1.34s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 456/581 [10:14<02:47,  1.34s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 457/581 [10:14<02:46,  1.34s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 457/581 [10:15<02:46,  1.34s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 458/581 [10:15<02:45,  1.34s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 458/581 [10:17<02:45,  1.34s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 459/581 [10:17<02:44,  1.34s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 459/581 [10:18<02:44,  1.34s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 460/581 [10:18<02:42,  1.35s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 460/581 [10:19<02:42,  1.35s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 461/581 [10:19<02:41,  1.35s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 461/581 [10:21<02:41,  1.35s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 462/581 [10:21<02:39,  1.34s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 462/581 [10:22<02:39,  1.34s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 463/581 [10:22<02:38,  1.34s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 463/581 [10:23<02:38,  1.34s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 464/581 [10:23<02:36,  1.34s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 464/581 [10:25<02:36,  1.34s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  80%|████████  | 465/581 [10:25<02:35,  1.34s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  80%|████████  | 465/581 [10:26<02:35,  1.34s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  80%|████████  | 466/581 [10:26<02:34,  1.34s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  80%|████████  | 466/581 [10:27<02:34,  1.34s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  80%|████████  | 467/581 [10:27<02:32,  1.34s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  80%|████████  | 467/581 [10:29<02:32,  1.34s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  81%|████████  | 468/581 [10:29<02:31,  1.34s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  81%|████████  | 468/581 [10:30<02:31,  1.34s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  81%|████████  | 469/581 [10:30<02:30,  1.34s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  81%|████████  | 469/581 [10:31<02:30,  1.34s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  81%|████████  | 470/581 [10:31<02:28,  1.34s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  81%|████████  | 470/581 [10:33<02:28,  1.34s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  81%|████████  | 471/581 [10:33<02:27,  1.34s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  81%|████████  | 471/581 [10:34<02:27,  1.34s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  81%|████████  | 472/581 [10:34<02:26,  1.35s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  81%|████████  | 472/581 [10:35<02:26,  1.35s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 473/581 [10:35<02:25,  1.35s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 473/581 [10:37<02:25,  1.35s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 474/581 [10:37<02:23,  1.35s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 474/581 [10:38<02:23,  1.35s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 475/581 [10:38<02:22,  1.34s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 475/581 [10:39<02:22,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 476/581 [10:39<02:20,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 476/581 [10:41<02:20,  1.34s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 477/581 [10:41<02:19,  1.34s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 477/581 [10:42<02:19,  1.34s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 478/581 [10:42<02:18,  1.34s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 478/581 [10:43<02:18,  1.34s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 479/581 [10:43<02:16,  1.34s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 479/581 [10:45<02:16,  1.34s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 480/581 [10:45<02:15,  1.34s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 480/581 [10:46<02:15,  1.34s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 481/581 [10:46<02:13,  1.34s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 481/581 [10:47<02:13,  1.34s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 482/581 [10:47<02:12,  1.34s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 482/581 [10:49<02:12,  1.34s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 483/581 [10:49<02:11,  1.34s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 483/581 [10:50<02:11,  1.34s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 484/581 [10:50<02:09,  1.34s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 484/581 [10:51<02:09,  1.34s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 485/581 [10:52<02:08,  1.34s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 485/581 [10:53<02:08,  1.34s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 486/581 [10:53<02:07,  1.34s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 486/581 [10:54<02:07,  1.34s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 487/581 [10:54<02:05,  1.34s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 487/581 [10:56<02:05,  1.34s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 488/581 [10:56<02:04,  1.34s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 488/581 [10:57<02:04,  1.34s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 489/581 [10:57<02:03,  1.34s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 489/581 [10:58<02:03,  1.34s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 490/581 [10:58<02:01,  1.34s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 490/581 [11:00<02:01,  1.34s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 491/581 [11:00<02:00,  1.34s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 491/581 [11:01<02:00,  1.34s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 492/581 [11:01<01:59,  1.34s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 492/581 [11:02<01:59,  1.34s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 493/581 [11:02<01:57,  1.34s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 493/581 [11:04<01:57,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 494/581 [11:04<01:56,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 494/581 [11:05<01:56,  1.34s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 495/581 [11:05<01:55,  1.34s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 495/581 [11:06<01:55,  1.34s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 496/581 [11:06<01:53,  1.34s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 496/581 [11:08<01:53,  1.34s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 497/581 [11:08<01:52,  1.34s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 497/581 [11:09<01:52,  1.34s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 498/581 [11:09<01:51,  1.34s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 498/581 [11:10<01:51,  1.34s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 499/581 [11:10<01:50,  1.34s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 499/581 [11:12<01:50,  1.34s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 500/581 [11:12<01:48,  1.34s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 500/581 [11:13<01:48,  1.34s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 501/581 [11:13<01:47,  1.34s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 501/581 [11:14<01:47,  1.34s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 502/581 [11:14<01:45,  1.34s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 502/581 [11:16<01:45,  1.34s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 503/581 [11:16<01:44,  1.34s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 503/581 [11:17<01:44,  1.34s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 504/581 [11:17<01:43,  1.35s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 504/581 [11:18<01:43,  1.35s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 505/581 [11:18<01:42,  1.34s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 505/581 [11:20<01:42,  1.34s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 506/581 [11:20<01:40,  1.34s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 506/581 [11:21<01:40,  1.34s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 507/581 [11:21<01:39,  1.34s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 507/581 [11:22<01:39,  1.34s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 508/581 [11:22<01:37,  1.34s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 508/581 [11:24<01:37,  1.34s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 509/581 [11:24<01:36,  1.34s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 509/581 [11:25<01:36,  1.34s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 510/581 [11:25<01:35,  1.34s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 510/581 [11:26<01:35,  1.34s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 511/581 [11:26<01:33,  1.34s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 511/581 [11:28<01:33,  1.34s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 512/581 [11:28<01:32,  1.34s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 512/581 [11:29<01:32,  1.34s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 513/581 [11:29<01:31,  1.34s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 513/581 [11:30<01:31,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 514/581 [11:30<01:29,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 514/581 [11:32<01:29,  1.34s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 515/581 [11:32<01:28,  1.34s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 515/581 [11:33<01:28,  1.34s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 516/581 [11:33<01:27,  1.34s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 516/581 [11:34<01:27,  1.34s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 517/581 [11:34<01:25,  1.34s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 517/581 [11:36<01:25,  1.34s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 518/581 [11:36<01:24,  1.34s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 518/581 [11:37<01:24,  1.34s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 519/581 [11:37<01:23,  1.34s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 519/581 [11:38<01:23,  1.34s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 520/581 [11:38<01:21,  1.34s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 520/581 [11:40<01:21,  1.34s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 521/581 [11:40<01:20,  1.34s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 521/581 [11:41<01:20,  1.34s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 522/581 [11:41<01:18,  1.34s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 522/581 [11:42<01:18,  1.34s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 523/581 [11:42<01:17,  1.34s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 523/581 [11:44<01:17,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 524/581 [11:44<01:16,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 524/581 [11:45<01:16,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 525/581 [11:45<01:14,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 525/581 [11:46<01:14,  1.34s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 526/581 [11:46<01:13,  1.34s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 526/581 [11:48<01:13,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 527/581 [11:48<01:12,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 527/581 [11:49<01:12,  1.34s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 528/581 [11:49<01:11,  1.34s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 528/581 [11:51<01:11,  1.34s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 529/581 [11:51<01:09,  1.35s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 529/581 [11:52<01:09,  1.35s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 530/581 [11:52<01:08,  1.35s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 530/581 [11:53<01:08,  1.35s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 531/581 [11:53<01:07,  1.35s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 531/581 [11:55<01:07,  1.35s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 532/581 [11:55<01:05,  1.35s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 532/581 [11:56<01:05,  1.35s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 533/581 [11:56<01:04,  1.34s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 533/581 [11:57<01:04,  1.34s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 534/581 [11:57<01:03,  1.34s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 534/581 [11:59<01:03,  1.34s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 535/581 [11:59<01:01,  1.34s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 535/581 [12:00<01:01,  1.34s/it, training_loss=0.404]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 536/581 [12:00<01:00,  1.34s/it, training_loss=0.404]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 536/581 [12:01<01:00,  1.34s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 537/581 [12:01<00:58,  1.34s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 537/581 [12:03<00:58,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 538/581 [12:03<00:57,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 538/581 [12:04<00:57,  1.34s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 539/581 [12:04<00:56,  1.34s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 539/581 [12:05<00:56,  1.34s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 540/581 [12:05<00:54,  1.34s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 540/581 [12:07<00:54,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 541/581 [12:07<00:53,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 541/581 [12:08<00:53,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 542/581 [12:08<00:52,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 542/581 [12:09<00:52,  1.34s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 543/581 [12:09<00:50,  1.34s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 543/581 [12:11<00:50,  1.34s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 544/581 [12:11<00:49,  1.34s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 544/581 [12:12<00:49,  1.34s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 545/581 [12:12<00:48,  1.34s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 545/581 [12:13<00:48,  1.34s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 546/581 [12:13<00:46,  1.34s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 546/581 [12:15<00:46,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 547/581 [12:15<00:45,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 547/581 [12:16<00:45,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 548/581 [12:16<00:44,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 548/581 [12:17<00:44,  1.34s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 549/581 [12:17<00:42,  1.34s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 549/581 [12:19<00:42,  1.34s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 550/581 [12:19<00:41,  1.34s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 550/581 [12:20<00:41,  1.34s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 551/581 [12:20<00:40,  1.35s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 551/581 [12:21<00:40,  1.35s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 552/581 [12:21<00:39,  1.35s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 552/581 [12:23<00:39,  1.35s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 553/581 [12:23<00:37,  1.35s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 553/581 [12:24<00:37,  1.35s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 554/581 [12:24<00:36,  1.35s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 554/581 [12:25<00:36,  1.35s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 555/581 [12:25<00:35,  1.35s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 555/581 [12:27<00:35,  1.35s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 556/581 [12:27<00:33,  1.34s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 556/581 [12:28<00:33,  1.34s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 557/581 [12:28<00:32,  1.35s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 557/581 [12:29<00:32,  1.35s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 558/581 [12:29<00:30,  1.35s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 558/581 [12:31<00:30,  1.35s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 559/581 [12:31<00:29,  1.35s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 559/581 [12:32<00:29,  1.35s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 560/581 [12:32<00:28,  1.34s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 560/581 [12:33<00:28,  1.34s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 561/581 [12:34<00:26,  1.35s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 561/581 [12:35<00:26,  1.35s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 562/581 [12:35<00:25,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 562/581 [12:36<00:25,  1.34s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 563/581 [12:36<00:24,  1.35s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 563/581 [12:38<00:24,  1.35s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 564/581 [12:38<00:22,  1.35s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 564/581 [12:39<00:22,  1.35s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 565/581 [12:39<00:21,  1.35s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 565/581 [12:40<00:21,  1.35s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 566/581 [12:40<00:20,  1.35s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 566/581 [12:42<00:20,  1.35s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 567/581 [12:42<00:18,  1.35s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 567/581 [12:43<00:18,  1.35s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 568/581 [12:43<00:17,  1.35s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 568/581 [12:44<00:17,  1.35s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 569/581 [12:44<00:16,  1.35s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 569/581 [12:46<00:16,  1.35s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 570/581 [12:46<00:14,  1.34s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 570/581 [12:47<00:14,  1.34s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 571/581 [12:47<00:13,  1.34s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 571/581 [12:48<00:13,  1.34s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 572/581 [12:48<00:12,  1.34s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 572/581 [12:50<00:12,  1.34s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 573/581 [12:50<00:10,  1.34s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 573/581 [12:51<00:10,  1.34s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 574/581 [12:51<00:09,  1.34s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 574/581 [12:52<00:09,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 575/581 [12:52<00:08,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 575/581 [12:54<00:08,  1.34s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 576/581 [12:54<00:06,  1.34s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 576/581 [12:55<00:06,  1.34s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 577/581 [12:55<00:05,  1.34s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 577/581 [12:56<00:05,  1.34s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 578/581 [12:56<00:04,  1.34s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 578/581 [12:58<00:04,  1.34s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 579/581 [12:58<00:02,  1.35s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 579/581 [12:59<00:02,  1.35s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 580/581 [12:59<00:01,  1.35s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 580/581 [13:00<00:01,  1.35s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2: 100%|██████████| 581/581 [13:00<00:00,  1.13s/it, training_loss=0.217]\u001b[A\n",
            " 33%|███▎      | 1/3 [27:44<29:20, 880.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2\n",
            "Training loss: 0.5138655652688006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 2/3 [29:19<14:39, 879.86s/it]\n",
            "Epoch 3:   0%|          | 0/581 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5607187068185855\n",
            "F1 Score (Weighted): 0.8004421259400846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3:   0%|          | 0/581 [00:01<?, ?it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 3:   0%|          | 1/581 [00:01<12:53,  1.33s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 3:   0%|          | 1/581 [00:02<12:53,  1.33s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:   0%|          | 2/581 [00:02<12:52,  1.33s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:   0%|          | 2/581 [00:04<12:52,  1.33s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:   1%|          | 3/581 [00:04<12:54,  1.34s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:   1%|          | 3/581 [00:05<12:54,  1.34s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:   1%|          | 4/581 [00:05<12:53,  1.34s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:   1%|          | 4/581 [00:06<12:53,  1.34s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:   1%|          | 5/581 [00:06<12:52,  1.34s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:   1%|          | 5/581 [00:08<12:52,  1.34s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 3:   1%|          | 6/581 [00:08<12:53,  1.35s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 3:   1%|          | 6/581 [00:09<12:53,  1.35s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:   1%|          | 7/581 [00:09<12:51,  1.34s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:   1%|          | 7/581 [00:10<12:51,  1.34s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:   1%|▏         | 8/581 [00:10<12:51,  1.35s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:   1%|▏         | 8/581 [00:12<12:51,  1.35s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 3:   2%|▏         | 9/581 [00:12<12:50,  1.35s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 3:   2%|▏         | 9/581 [00:13<12:50,  1.35s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:   2%|▏         | 10/581 [00:13<12:48,  1.35s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:   2%|▏         | 10/581 [00:14<12:48,  1.35s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:   2%|▏         | 11/581 [00:14<12:47,  1.35s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:   2%|▏         | 11/581 [00:16<12:47,  1.35s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 3:   2%|▏         | 12/581 [00:16<12:47,  1.35s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 3:   2%|▏         | 12/581 [00:17<12:47,  1.35s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:   2%|▏         | 13/581 [00:17<12:45,  1.35s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:   2%|▏         | 13/581 [00:18<12:45,  1.35s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:   2%|▏         | 14/581 [00:18<12:46,  1.35s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:   2%|▏         | 14/581 [00:20<12:46,  1.35s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:   3%|▎         | 15/581 [00:20<12:43,  1.35s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:   3%|▎         | 15/581 [00:21<12:43,  1.35s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:   3%|▎         | 16/581 [00:21<12:43,  1.35s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:   3%|▎         | 16/581 [00:22<12:43,  1.35s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:   3%|▎         | 17/581 [00:22<12:41,  1.35s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:   3%|▎         | 17/581 [00:24<12:41,  1.35s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 3:   3%|▎         | 18/581 [00:24<12:40,  1.35s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 3:   3%|▎         | 18/581 [00:25<12:40,  1.35s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:   3%|▎         | 19/581 [00:25<12:38,  1.35s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:   3%|▎         | 19/581 [00:26<12:38,  1.35s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:   3%|▎         | 20/581 [00:26<12:36,  1.35s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:   3%|▎         | 20/581 [00:28<12:36,  1.35s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 3:   4%|▎         | 21/581 [00:28<12:33,  1.35s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 3:   4%|▎         | 21/581 [00:29<12:33,  1.35s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 3:   4%|▍         | 22/581 [00:29<12:30,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 3:   4%|▍         | 22/581 [00:30<12:30,  1.34s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:   4%|▍         | 23/581 [00:30<12:28,  1.34s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:   4%|▍         | 23/581 [00:32<12:28,  1.34s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 3:   4%|▍         | 24/581 [00:32<12:26,  1.34s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 3:   4%|▍         | 24/581 [00:33<12:26,  1.34s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:   4%|▍         | 25/581 [00:33<12:25,  1.34s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:   4%|▍         | 25/581 [00:34<12:25,  1.34s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:   4%|▍         | 26/581 [00:34<12:25,  1.34s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:   4%|▍         | 26/581 [00:36<12:25,  1.34s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 3:   5%|▍         | 27/581 [00:36<12:25,  1.34s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 3:   5%|▍         | 27/581 [00:37<12:25,  1.34s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:   5%|▍         | 28/581 [00:37<12:24,  1.35s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:   5%|▍         | 28/581 [00:39<12:24,  1.35s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:   5%|▍         | 29/581 [00:39<12:21,  1.34s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:   5%|▍         | 29/581 [00:40<12:21,  1.34s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:   5%|▌         | 30/581 [00:40<12:20,  1.34s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:   5%|▌         | 30/581 [00:41<12:20,  1.34s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:   5%|▌         | 31/581 [00:41<12:20,  1.35s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:   5%|▌         | 31/581 [00:43<12:20,  1.35s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 3:   6%|▌         | 32/581 [00:43<12:18,  1.34s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 3:   6%|▌         | 32/581 [00:44<12:18,  1.34s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 3:   6%|▌         | 33/581 [00:44<12:15,  1.34s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 3:   6%|▌         | 33/581 [00:45<12:15,  1.34s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 3:   6%|▌         | 34/581 [00:45<12:13,  1.34s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 3:   6%|▌         | 34/581 [00:47<12:13,  1.34s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 3:   6%|▌         | 35/581 [00:47<12:15,  1.35s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 3:   6%|▌         | 35/581 [00:48<12:15,  1.35s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:   6%|▌         | 36/581 [00:48<12:12,  1.34s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:   6%|▌         | 36/581 [00:49<12:12,  1.34s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:   6%|▋         | 37/581 [00:49<12:10,  1.34s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:   6%|▋         | 37/581 [00:51<12:10,  1.34s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:   7%|▋         | 38/581 [00:51<12:07,  1.34s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:   7%|▋         | 38/581 [00:52<12:07,  1.34s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:   7%|▋         | 39/581 [00:52<12:06,  1.34s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:   7%|▋         | 39/581 [00:53<12:06,  1.34s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:   7%|▋         | 40/581 [00:53<12:06,  1.34s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:   7%|▋         | 40/581 [00:55<12:06,  1.34s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:   7%|▋         | 41/581 [00:55<12:06,  1.35s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:   7%|▋         | 41/581 [00:56<12:06,  1.35s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:   7%|▋         | 42/581 [00:56<12:05,  1.35s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:   7%|▋         | 42/581 [00:57<12:05,  1.35s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:   7%|▋         | 43/581 [00:57<12:04,  1.35s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:   7%|▋         | 43/581 [00:59<12:04,  1.35s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:   8%|▊         | 44/581 [00:59<12:00,  1.34s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:   8%|▊         | 44/581 [01:00<12:00,  1.34s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 3:   8%|▊         | 45/581 [01:00<11:58,  1.34s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 3:   8%|▊         | 45/581 [01:01<11:58,  1.34s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:   8%|▊         | 46/581 [01:01<11:59,  1.35s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:   8%|▊         | 46/581 [01:03<11:59,  1.35s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:   8%|▊         | 47/581 [01:03<11:58,  1.35s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:   8%|▊         | 47/581 [01:04<11:58,  1.35s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:   8%|▊         | 48/581 [01:04<11:57,  1.35s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:   8%|▊         | 48/581 [01:05<11:57,  1.35s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:   8%|▊         | 49/581 [01:05<11:55,  1.34s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:   8%|▊         | 49/581 [01:07<11:55,  1.34s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:   9%|▊         | 50/581 [01:07<11:53,  1.34s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:   9%|▊         | 50/581 [01:08<11:53,  1.34s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 3:   9%|▉         | 51/581 [01:08<11:52,  1.34s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 3:   9%|▉         | 51/581 [01:09<11:52,  1.34s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:   9%|▉         | 52/581 [01:09<11:48,  1.34s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:   9%|▉         | 52/581 [01:11<11:48,  1.34s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:   9%|▉         | 53/581 [01:11<11:51,  1.35s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:   9%|▉         | 53/581 [01:12<11:51,  1.35s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:   9%|▉         | 54/581 [01:12<11:48,  1.35s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:   9%|▉         | 54/581 [01:13<11:48,  1.35s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 3:   9%|▉         | 55/581 [01:13<11:46,  1.34s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 3:   9%|▉         | 55/581 [01:15<11:46,  1.34s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  10%|▉         | 56/581 [01:15<11:46,  1.34s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  10%|▉         | 56/581 [01:16<11:46,  1.34s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  10%|▉         | 57/581 [01:16<11:45,  1.35s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  10%|▉         | 57/581 [01:18<11:45,  1.35s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  10%|▉         | 58/581 [01:18<11:45,  1.35s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  10%|▉         | 58/581 [01:19<11:45,  1.35s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  10%|█         | 59/581 [01:19<11:44,  1.35s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  10%|█         | 59/581 [01:20<11:44,  1.35s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  10%|█         | 60/581 [01:20<11:41,  1.35s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  10%|█         | 60/581 [01:22<11:41,  1.35s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  10%|█         | 61/581 [01:22<11:39,  1.34s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  10%|█         | 61/581 [01:23<11:39,  1.34s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  11%|█         | 62/581 [01:23<11:39,  1.35s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  11%|█         | 62/581 [01:24<11:39,  1.35s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  11%|█         | 63/581 [01:24<11:37,  1.35s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  11%|█         | 63/581 [01:26<11:37,  1.35s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 3:  11%|█         | 64/581 [01:26<11:36,  1.35s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 3:  11%|█         | 64/581 [01:27<11:36,  1.35s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  11%|█         | 65/581 [01:27<11:34,  1.35s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  11%|█         | 65/581 [01:28<11:34,  1.35s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 66/581 [01:28<11:32,  1.34s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 66/581 [01:30<11:32,  1.34s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 67/581 [01:30<11:30,  1.34s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 67/581 [01:31<11:30,  1.34s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 68/581 [01:31<11:30,  1.35s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 68/581 [01:32<11:30,  1.35s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 69/581 [01:32<11:29,  1.35s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 69/581 [01:34<11:29,  1.35s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 70/581 [01:34<11:27,  1.35s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 70/581 [01:35<11:27,  1.35s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 71/581 [01:35<11:26,  1.35s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 71/581 [01:36<11:26,  1.35s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 72/581 [01:36<11:25,  1.35s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 72/581 [01:38<11:25,  1.35s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 73/581 [01:38<11:22,  1.34s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 73/581 [01:39<11:22,  1.34s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 74/581 [01:39<11:20,  1.34s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 74/581 [01:40<11:20,  1.34s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 75/581 [01:40<11:21,  1.35s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 75/581 [01:42<11:21,  1.35s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 76/581 [01:42<11:19,  1.35s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 76/581 [01:43<11:19,  1.35s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 77/581 [01:43<11:18,  1.35s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 77/581 [01:44<11:18,  1.35s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 78/581 [01:44<11:16,  1.35s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 78/581 [01:46<11:16,  1.35s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 79/581 [01:46<11:16,  1.35s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 79/581 [01:47<11:16,  1.35s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 80/581 [01:47<11:15,  1.35s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 80/581 [01:48<11:15,  1.35s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 81/581 [01:48<11:14,  1.35s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 81/581 [01:50<11:14,  1.35s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 82/581 [01:50<11:13,  1.35s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 82/581 [01:51<11:13,  1.35s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 83/581 [01:51<11:10,  1.35s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 83/581 [01:53<11:10,  1.35s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 84/581 [01:53<11:10,  1.35s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 84/581 [01:54<11:10,  1.35s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 85/581 [01:54<11:07,  1.35s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 85/581 [01:55<11:07,  1.35s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 86/581 [01:55<11:05,  1.34s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 86/581 [01:57<11:05,  1.34s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 87/581 [01:57<11:05,  1.35s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 87/581 [01:58<11:05,  1.35s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 88/581 [01:58<11:04,  1.35s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 88/581 [01:59<11:04,  1.35s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 89/581 [01:59<11:00,  1.34s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 89/581 [02:01<11:00,  1.34s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 90/581 [02:01<11:00,  1.34s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 90/581 [02:02<11:00,  1.34s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 91/581 [02:02<10:59,  1.35s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 91/581 [02:03<10:59,  1.35s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 92/581 [02:03<10:55,  1.34s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 92/581 [02:05<10:55,  1.34s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 93/581 [02:05<10:54,  1.34s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 93/581 [02:06<10:54,  1.34s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 94/581 [02:06<10:52,  1.34s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 94/581 [02:07<10:52,  1.34s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 95/581 [02:07<10:52,  1.34s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 95/581 [02:09<10:52,  1.34s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 96/581 [02:09<10:53,  1.35s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 96/581 [02:10<10:53,  1.35s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 97/581 [02:10<10:53,  1.35s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 97/581 [02:11<10:53,  1.35s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 98/581 [02:11<10:53,  1.35s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 98/581 [02:13<10:53,  1.35s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 99/581 [02:13<10:50,  1.35s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 99/581 [02:14<10:50,  1.35s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 100/581 [02:14<10:49,  1.35s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 100/581 [02:15<10:49,  1.35s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 101/581 [02:15<10:47,  1.35s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 101/581 [02:17<10:47,  1.35s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 102/581 [02:17<10:44,  1.35s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 102/581 [02:18<10:44,  1.35s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 103/581 [02:18<10:44,  1.35s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 103/581 [02:19<10:44,  1.35s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 104/581 [02:19<10:41,  1.34s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 104/581 [02:21<10:41,  1.34s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 105/581 [02:21<10:39,  1.34s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 105/581 [02:22<10:39,  1.34s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 106/581 [02:22<10:37,  1.34s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 106/581 [02:23<10:37,  1.34s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 107/581 [02:23<10:35,  1.34s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 107/581 [02:25<10:35,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 108/581 [02:25<10:34,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 108/581 [02:26<10:34,  1.34s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 109/581 [02:26<10:34,  1.34s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 109/581 [02:27<10:34,  1.34s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 110/581 [02:27<10:33,  1.34s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 110/581 [02:29<10:33,  1.34s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 111/581 [02:29<10:30,  1.34s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 111/581 [02:30<10:30,  1.34s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 112/581 [02:30<10:28,  1.34s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 112/581 [02:31<10:28,  1.34s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 113/581 [02:31<10:26,  1.34s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 113/581 [02:33<10:26,  1.34s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 114/581 [02:33<10:26,  1.34s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 114/581 [02:34<10:26,  1.34s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 115/581 [02:34<10:26,  1.34s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 115/581 [02:36<10:26,  1.34s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 116/581 [02:36<10:24,  1.34s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 116/581 [02:37<10:24,  1.34s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 3:  20%|██        | 117/581 [02:37<10:23,  1.34s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 3:  20%|██        | 117/581 [02:38<10:23,  1.34s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  20%|██        | 118/581 [02:38<10:21,  1.34s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  20%|██        | 118/581 [02:40<10:21,  1.34s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  20%|██        | 119/581 [02:40<10:21,  1.35s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  20%|██        | 119/581 [02:41<10:21,  1.35s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  21%|██        | 120/581 [02:41<10:20,  1.35s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  21%|██        | 120/581 [02:42<10:20,  1.35s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  21%|██        | 121/581 [02:42<10:17,  1.34s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  21%|██        | 121/581 [02:44<10:17,  1.34s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  21%|██        | 122/581 [02:44<10:15,  1.34s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  21%|██        | 122/581 [02:45<10:15,  1.34s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  21%|██        | 123/581 [02:45<10:13,  1.34s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  21%|██        | 123/581 [02:46<10:13,  1.34s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 124/581 [02:46<10:12,  1.34s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 124/581 [02:48<10:12,  1.34s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 125/581 [02:48<10:11,  1.34s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 125/581 [02:49<10:11,  1.34s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 126/581 [02:49<10:09,  1.34s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 126/581 [02:50<10:09,  1.34s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 127/581 [02:50<10:07,  1.34s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 127/581 [02:52<10:07,  1.34s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 128/581 [02:52<10:06,  1.34s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 128/581 [02:53<10:06,  1.34s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 129/581 [02:53<10:06,  1.34s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 129/581 [02:54<10:06,  1.34s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 130/581 [02:54<10:03,  1.34s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 130/581 [02:56<10:03,  1.34s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 131/581 [02:56<10:02,  1.34s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 131/581 [02:57<10:02,  1.34s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 132/581 [02:57<10:02,  1.34s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 132/581 [02:58<10:02,  1.34s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 133/581 [02:58<09:59,  1.34s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 133/581 [03:00<09:59,  1.34s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 134/581 [03:00<09:58,  1.34s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 134/581 [03:01<09:58,  1.34s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 135/581 [03:01<09:57,  1.34s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 135/581 [03:02<09:57,  1.34s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 136/581 [03:02<09:58,  1.35s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 136/581 [03:04<09:58,  1.35s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 137/581 [03:04<09:57,  1.35s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 137/581 [03:05<09:57,  1.35s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 138/581 [03:05<09:55,  1.34s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 138/581 [03:06<09:55,  1.34s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 139/581 [03:06<09:53,  1.34s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 139/581 [03:08<09:53,  1.34s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 140/581 [03:08<09:51,  1.34s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 140/581 [03:09<09:51,  1.34s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 141/581 [03:09<09:51,  1.34s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 141/581 [03:10<09:51,  1.34s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 142/581 [03:10<09:49,  1.34s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 142/581 [03:12<09:49,  1.34s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 143/581 [03:12<09:47,  1.34s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 143/581 [03:13<09:47,  1.34s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 144/581 [03:13<09:45,  1.34s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 144/581 [03:14<09:45,  1.34s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 145/581 [03:14<09:43,  1.34s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 145/581 [03:16<09:43,  1.34s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 146/581 [03:16<09:44,  1.34s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 146/581 [03:17<09:44,  1.34s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 147/581 [03:17<09:41,  1.34s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 147/581 [03:18<09:41,  1.34s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 148/581 [03:18<09:40,  1.34s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 148/581 [03:20<09:40,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 149/581 [03:20<09:38,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 149/581 [03:21<09:38,  1.34s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 150/581 [03:21<09:37,  1.34s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 150/581 [03:22<09:37,  1.34s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 151/581 [03:22<09:36,  1.34s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 151/581 [03:24<09:36,  1.34s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 152/581 [03:24<09:34,  1.34s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 152/581 [03:25<09:34,  1.34s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 153/581 [03:25<09:34,  1.34s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 153/581 [03:27<09:34,  1.34s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 154/581 [03:27<09:33,  1.34s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 154/581 [03:28<09:33,  1.34s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 155/581 [03:28<09:32,  1.34s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 155/581 [03:29<09:32,  1.34s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 156/581 [03:29<09:30,  1.34s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 156/581 [03:31<09:30,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 157/581 [03:31<09:29,  1.34s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 157/581 [03:32<09:29,  1.34s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 158/581 [03:32<09:28,  1.35s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 158/581 [03:33<09:28,  1.35s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 159/581 [03:33<09:27,  1.35s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 159/581 [03:35<09:27,  1.35s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 160/581 [03:35<09:26,  1.35s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 160/581 [03:36<09:26,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 161/581 [03:36<09:24,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 161/581 [03:37<09:24,  1.35s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 162/581 [03:37<09:24,  1.35s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 162/581 [03:39<09:24,  1.35s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 163/581 [03:39<09:21,  1.34s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 163/581 [03:40<09:21,  1.34s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 164/581 [03:40<09:19,  1.34s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 164/581 [03:41<09:19,  1.34s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 165/581 [03:41<09:18,  1.34s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 165/581 [03:43<09:18,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 166/581 [03:43<09:17,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 166/581 [03:44<09:17,  1.34s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 167/581 [03:44<09:18,  1.35s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 167/581 [03:45<09:18,  1.35s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 168/581 [03:45<09:17,  1.35s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 168/581 [03:47<09:17,  1.35s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 169/581 [03:47<09:15,  1.35s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 169/581 [03:48<09:15,  1.35s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 170/581 [03:48<09:13,  1.35s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 170/581 [03:49<09:13,  1.35s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 171/581 [03:49<09:12,  1.35s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 171/581 [03:51<09:12,  1.35s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 172/581 [03:51<09:10,  1.35s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 172/581 [03:52<09:10,  1.35s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 173/581 [03:52<09:09,  1.35s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 173/581 [03:53<09:09,  1.35s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 174/581 [03:53<09:06,  1.34s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 174/581 [03:55<09:06,  1.34s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  30%|███       | 175/581 [03:55<09:05,  1.34s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  30%|███       | 175/581 [03:56<09:05,  1.34s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  30%|███       | 176/581 [03:56<09:04,  1.34s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  30%|███       | 176/581 [03:57<09:04,  1.34s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  30%|███       | 177/581 [03:57<09:03,  1.34s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  30%|███       | 177/581 [03:59<09:03,  1.34s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  31%|███       | 178/581 [03:59<09:01,  1.34s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  31%|███       | 178/581 [04:00<09:01,  1.34s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  31%|███       | 179/581 [04:00<09:00,  1.34s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  31%|███       | 179/581 [04:01<09:00,  1.34s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 3:  31%|███       | 180/581 [04:01<08:59,  1.34s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 3:  31%|███       | 180/581 [04:03<08:59,  1.34s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:  31%|███       | 181/581 [04:03<08:57,  1.34s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:  31%|███       | 181/581 [04:04<08:57,  1.34s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 182/581 [04:04<08:57,  1.35s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 182/581 [04:06<08:57,  1.35s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 183/581 [04:06<08:55,  1.35s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 183/581 [04:07<08:55,  1.35s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 184/581 [04:07<08:53,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 184/581 [04:08<08:53,  1.34s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 185/581 [04:08<08:53,  1.35s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 185/581 [04:10<08:53,  1.35s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 186/581 [04:10<08:52,  1.35s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 186/581 [04:11<08:52,  1.35s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 187/581 [04:11<08:50,  1.35s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 187/581 [04:12<08:50,  1.35s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 188/581 [04:12<08:49,  1.35s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 188/581 [04:14<08:49,  1.35s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 189/581 [04:14<08:47,  1.34s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 189/581 [04:15<08:47,  1.34s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 190/581 [04:15<08:45,  1.34s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 190/581 [04:16<08:45,  1.34s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 191/581 [04:16<08:45,  1.35s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 191/581 [04:18<08:45,  1.35s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 192/581 [04:18<08:44,  1.35s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 192/581 [04:19<08:44,  1.35s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 193/581 [04:19<08:42,  1.35s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 193/581 [04:20<08:42,  1.35s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 194/581 [04:20<08:41,  1.35s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 194/581 [04:22<08:41,  1.35s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 195/581 [04:22<08:39,  1.35s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 195/581 [04:23<08:39,  1.35s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 196/581 [04:23<08:39,  1.35s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 196/581 [04:24<08:39,  1.35s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 197/581 [04:24<08:39,  1.35s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 197/581 [04:26<08:39,  1.35s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 198/581 [04:26<08:36,  1.35s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 198/581 [04:27<08:36,  1.35s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 199/581 [04:27<08:35,  1.35s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 199/581 [04:28<08:35,  1.35s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 200/581 [04:28<08:34,  1.35s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 200/581 [04:30<08:34,  1.35s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 201/581 [04:30<08:31,  1.35s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 201/581 [04:31<08:31,  1.35s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 202/581 [04:31<08:29,  1.34s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 202/581 [04:32<08:29,  1.34s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 203/581 [04:32<08:29,  1.35s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 203/581 [04:34<08:29,  1.35s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 204/581 [04:34<08:27,  1.35s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 204/581 [04:35<08:27,  1.35s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 205/581 [04:35<08:24,  1.34s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 205/581 [04:36<08:24,  1.34s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 206/581 [04:36<08:22,  1.34s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 206/581 [04:38<08:22,  1.34s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 207/581 [04:38<08:21,  1.34s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 207/581 [04:39<08:21,  1.34s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 208/581 [04:39<08:20,  1.34s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 208/581 [04:40<08:20,  1.34s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 209/581 [04:41<08:18,  1.34s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 209/581 [04:42<08:18,  1.34s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 210/581 [04:42<08:16,  1.34s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 210/581 [04:43<08:16,  1.34s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 211/581 [04:43<08:15,  1.34s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 211/581 [04:45<08:15,  1.34s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 212/581 [04:45<08:15,  1.34s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 212/581 [04:46<08:15,  1.34s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 213/581 [04:46<08:15,  1.35s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 213/581 [04:47<08:15,  1.35s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 214/581 [04:47<08:14,  1.35s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 214/581 [04:49<08:14,  1.35s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 215/581 [04:49<08:13,  1.35s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 215/581 [04:50<08:13,  1.35s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 216/581 [04:50<08:10,  1.34s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 216/581 [04:51<08:10,  1.34s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 217/581 [04:51<08:08,  1.34s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 217/581 [04:53<08:08,  1.34s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 218/581 [04:53<08:06,  1.34s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 218/581 [04:54<08:06,  1.34s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 219/581 [04:54<08:04,  1.34s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 219/581 [04:55<08:04,  1.34s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 220/581 [04:55<08:03,  1.34s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 220/581 [04:57<08:03,  1.34s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 221/581 [04:57<08:02,  1.34s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 221/581 [04:58<08:02,  1.34s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 222/581 [04:58<08:02,  1.35s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 222/581 [04:59<08:02,  1.35s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 223/581 [04:59<08:01,  1.35s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 223/581 [05:01<08:01,  1.35s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 224/581 [05:01<08:00,  1.35s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 224/581 [05:02<08:00,  1.35s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 225/581 [05:02<07:59,  1.35s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 225/581 [05:03<07:59,  1.35s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 226/581 [05:03<07:56,  1.34s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 226/581 [05:05<07:56,  1.34s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 227/581 [05:05<07:54,  1.34s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 227/581 [05:06<07:54,  1.34s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 228/581 [05:06<07:55,  1.35s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 228/581 [05:07<07:55,  1.35s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 229/581 [05:07<07:54,  1.35s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 229/581 [05:09<07:54,  1.35s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 230/581 [05:09<07:53,  1.35s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 230/581 [05:10<07:53,  1.35s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 231/581 [05:10<07:52,  1.35s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 231/581 [05:11<07:52,  1.35s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 232/581 [05:11<07:49,  1.35s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 232/581 [05:13<07:49,  1.35s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  40%|████      | 233/581 [05:13<07:47,  1.34s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  40%|████      | 233/581 [05:14<07:47,  1.34s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  40%|████      | 234/581 [05:14<07:45,  1.34s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  40%|████      | 234/581 [05:15<07:45,  1.34s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  40%|████      | 235/581 [05:15<07:43,  1.34s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  40%|████      | 235/581 [05:17<07:43,  1.34s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  41%|████      | 236/581 [05:17<07:42,  1.34s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  41%|████      | 236/581 [05:18<07:42,  1.34s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  41%|████      | 237/581 [05:18<07:41,  1.34s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  41%|████      | 237/581 [05:19<07:41,  1.34s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 3:  41%|████      | 238/581 [05:19<07:39,  1.34s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 3:  41%|████      | 238/581 [05:21<07:39,  1.34s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  41%|████      | 239/581 [05:21<07:38,  1.34s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  41%|████      | 239/581 [05:22<07:38,  1.34s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 240/581 [05:22<07:37,  1.34s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 240/581 [05:23<07:37,  1.34s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 241/581 [05:23<07:35,  1.34s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 241/581 [05:25<07:35,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 242/581 [05:25<07:34,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 242/581 [05:26<07:34,  1.34s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 243/581 [05:26<07:32,  1.34s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 243/581 [05:27<07:32,  1.34s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 244/581 [05:27<07:31,  1.34s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 244/581 [05:29<07:31,  1.34s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 245/581 [05:29<07:30,  1.34s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 245/581 [05:30<07:30,  1.34s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 246/581 [05:30<07:30,  1.34s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 246/581 [05:32<07:30,  1.34s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 247/581 [05:32<07:30,  1.35s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 247/581 [05:33<07:30,  1.35s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 248/581 [05:33<07:29,  1.35s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 248/581 [05:34<07:29,  1.35s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 249/581 [05:34<07:26,  1.34s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 249/581 [05:36<07:26,  1.34s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 250/581 [05:36<07:25,  1.35s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 250/581 [05:37<07:25,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 251/581 [05:37<07:23,  1.34s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 251/581 [05:38<07:23,  1.34s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 252/581 [05:38<07:22,  1.34s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 252/581 [05:40<07:22,  1.34s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 253/581 [05:40<07:20,  1.34s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 253/581 [05:41<07:20,  1.34s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 254/581 [05:41<07:20,  1.35s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 254/581 [05:42<07:20,  1.35s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 255/581 [05:42<07:19,  1.35s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 255/581 [05:44<07:19,  1.35s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 256/581 [05:44<07:17,  1.35s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 256/581 [05:45<07:17,  1.35s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 257/581 [05:45<07:17,  1.35s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 257/581 [05:46<07:17,  1.35s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 258/581 [05:46<07:15,  1.35s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 258/581 [05:48<07:15,  1.35s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 259/581 [05:48<07:14,  1.35s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 259/581 [05:49<07:14,  1.35s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 260/581 [05:49<07:12,  1.35s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 260/581 [05:50<07:12,  1.35s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 261/581 [05:50<07:10,  1.34s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 261/581 [05:52<07:10,  1.34s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 262/581 [05:52<07:08,  1.34s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 262/581 [05:53<07:08,  1.34s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 263/581 [05:53<07:05,  1.34s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 263/581 [05:54<07:05,  1.34s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 264/581 [05:54<07:04,  1.34s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 264/581 [05:56<07:04,  1.34s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 265/581 [05:56<07:02,  1.34s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 265/581 [05:57<07:02,  1.34s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 266/581 [05:57<07:01,  1.34s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 266/581 [05:58<07:01,  1.34s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 267/581 [05:58<07:00,  1.34s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 267/581 [06:00<07:00,  1.34s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 268/581 [06:00<06:59,  1.34s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 268/581 [06:01<06:59,  1.34s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 269/581 [06:01<06:57,  1.34s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 269/581 [06:02<06:57,  1.34s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 270/581 [06:02<06:57,  1.34s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 270/581 [06:04<06:57,  1.34s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 271/581 [06:04<06:55,  1.34s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 271/581 [06:05<06:55,  1.34s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 272/581 [06:05<06:54,  1.34s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 272/581 [06:06<06:54,  1.34s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 273/581 [06:06<06:51,  1.34s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 273/581 [06:08<06:51,  1.34s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 274/581 [06:08<06:50,  1.34s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 274/581 [06:09<06:50,  1.34s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 275/581 [06:09<06:50,  1.34s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 275/581 [06:10<06:50,  1.34s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 276/581 [06:10<06:48,  1.34s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 276/581 [06:12<06:48,  1.34s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 277/581 [06:12<06:48,  1.34s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 277/581 [06:13<06:48,  1.34s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 278/581 [06:13<06:47,  1.34s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 278/581 [06:15<06:47,  1.34s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 279/581 [06:15<06:46,  1.34s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 279/581 [06:16<06:46,  1.34s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 280/581 [06:16<06:44,  1.35s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 280/581 [06:17<06:44,  1.35s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 281/581 [06:17<06:43,  1.35s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 281/581 [06:19<06:43,  1.35s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 282/581 [06:19<06:42,  1.34s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 282/581 [06:20<06:42,  1.34s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 283/581 [06:20<06:41,  1.35s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 283/581 [06:21<06:41,  1.35s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 284/581 [06:21<06:39,  1.35s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 284/581 [06:23<06:39,  1.35s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 285/581 [06:23<06:38,  1.35s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 285/581 [06:24<06:38,  1.35s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 286/581 [06:24<06:38,  1.35s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 286/581 [06:25<06:38,  1.35s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 287/581 [06:25<06:37,  1.35s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 287/581 [06:27<06:37,  1.35s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 288/581 [06:27<06:34,  1.35s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 288/581 [06:28<06:34,  1.35s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 289/581 [06:28<06:34,  1.35s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 289/581 [06:29<06:34,  1.35s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 290/581 [06:29<06:32,  1.35s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 290/581 [06:31<06:32,  1.35s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  50%|█████     | 291/581 [06:31<06:30,  1.35s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  50%|█████     | 291/581 [06:32<06:30,  1.35s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  50%|█████     | 292/581 [06:32<06:28,  1.34s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  50%|█████     | 292/581 [06:33<06:28,  1.34s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3:  50%|█████     | 293/581 [06:33<06:26,  1.34s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3:  50%|█████     | 293/581 [06:35<06:26,  1.34s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  51%|█████     | 294/581 [06:35<06:25,  1.34s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  51%|█████     | 294/581 [06:36<06:25,  1.34s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  51%|█████     | 295/581 [06:36<06:24,  1.34s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  51%|█████     | 295/581 [06:37<06:24,  1.34s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  51%|█████     | 296/581 [06:37<06:21,  1.34s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  51%|█████     | 296/581 [06:39<06:21,  1.34s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  51%|█████     | 297/581 [06:39<06:21,  1.34s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  51%|█████     | 297/581 [06:40<06:21,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 298/581 [06:40<06:19,  1.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 298/581 [06:41<06:19,  1.34s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 299/581 [06:41<06:18,  1.34s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 299/581 [06:43<06:18,  1.34s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 300/581 [06:43<06:17,  1.34s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 300/581 [06:44<06:17,  1.34s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 301/581 [06:44<06:15,  1.34s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 301/581 [06:45<06:15,  1.34s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 302/581 [06:45<06:14,  1.34s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 302/581 [06:47<06:14,  1.34s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 303/581 [06:47<06:12,  1.34s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 303/581 [06:48<06:12,  1.34s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 304/581 [06:48<06:12,  1.34s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 304/581 [06:49<06:12,  1.34s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 305/581 [06:49<06:11,  1.35s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 305/581 [06:51<06:11,  1.35s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 306/581 [06:51<06:10,  1.35s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 306/581 [06:52<06:10,  1.35s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 307/581 [06:52<06:09,  1.35s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 307/581 [06:54<06:09,  1.35s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 308/581 [06:54<06:08,  1.35s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 308/581 [06:55<06:08,  1.35s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 309/581 [06:55<06:06,  1.35s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 309/581 [06:56<06:06,  1.35s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 310/581 [06:56<06:04,  1.35s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 310/581 [06:58<06:04,  1.35s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 311/581 [06:58<06:03,  1.35s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 311/581 [06:59<06:03,  1.35s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 312/581 [06:59<06:02,  1.35s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 312/581 [07:00<06:02,  1.35s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 313/581 [07:00<05:59,  1.34s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 313/581 [07:02<05:59,  1.34s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 314/581 [07:02<05:58,  1.34s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 314/581 [07:03<05:58,  1.34s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 315/581 [07:03<05:58,  1.35s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 315/581 [07:04<05:58,  1.35s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 316/581 [07:04<05:57,  1.35s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 316/581 [07:06<05:57,  1.35s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 317/581 [07:06<05:56,  1.35s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 317/581 [07:07<05:56,  1.35s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 318/581 [07:07<05:53,  1.35s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 318/581 [07:08<05:53,  1.35s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 319/581 [07:08<05:53,  1.35s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 319/581 [07:10<05:53,  1.35s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 320/581 [07:10<05:51,  1.35s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 320/581 [07:11<05:51,  1.35s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 321/581 [07:11<05:49,  1.35s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 321/581 [07:12<05:49,  1.35s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 322/581 [07:12<05:48,  1.35s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 322/581 [07:14<05:48,  1.35s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 323/581 [07:14<05:47,  1.35s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 323/581 [07:15<05:47,  1.35s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 324/581 [07:15<05:45,  1.35s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 324/581 [07:16<05:45,  1.35s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 325/581 [07:16<05:45,  1.35s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 325/581 [07:18<05:45,  1.35s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 326/581 [07:18<05:44,  1.35s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 326/581 [07:19<05:44,  1.35s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 327/581 [07:19<05:42,  1.35s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 327/581 [07:20<05:42,  1.35s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 328/581 [07:20<05:41,  1.35s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 328/581 [07:22<05:41,  1.35s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 329/581 [07:22<05:40,  1.35s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 329/581 [07:23<05:40,  1.35s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 330/581 [07:23<05:37,  1.35s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 330/581 [07:25<05:37,  1.35s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 331/581 [07:25<05:37,  1.35s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 331/581 [07:26<05:37,  1.35s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 332/581 [07:26<05:35,  1.35s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 332/581 [07:27<05:35,  1.35s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 333/581 [07:27<05:33,  1.35s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 333/581 [07:29<05:33,  1.35s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 334/581 [07:29<05:32,  1.35s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 334/581 [07:30<05:32,  1.35s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 335/581 [07:30<05:31,  1.35s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 335/581 [07:31<05:31,  1.35s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 336/581 [07:31<05:29,  1.34s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 336/581 [07:33<05:29,  1.34s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 337/581 [07:33<05:29,  1.35s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 337/581 [07:34<05:29,  1.35s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 338/581 [07:34<05:26,  1.35s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 338/581 [07:35<05:26,  1.35s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 339/581 [07:35<05:25,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 339/581 [07:37<05:25,  1.34s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 340/581 [07:37<05:23,  1.34s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 340/581 [07:38<05:23,  1.34s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 341/581 [07:38<05:22,  1.34s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 341/581 [07:39<05:22,  1.34s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 342/581 [07:39<05:21,  1.34s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 342/581 [07:41<05:21,  1.34s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 343/581 [07:41<05:19,  1.34s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 343/581 [07:42<05:19,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 344/581 [07:42<05:17,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 344/581 [07:43<05:17,  1.34s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 345/581 [07:43<05:16,  1.34s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 345/581 [07:45<05:16,  1.34s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 346/581 [07:45<05:15,  1.34s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 346/581 [07:46<05:15,  1.34s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 347/581 [07:46<05:13,  1.34s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 347/581 [07:47<05:13,  1.34s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 348/581 [07:47<05:13,  1.35s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 348/581 [07:49<05:13,  1.35s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 3:  60%|██████    | 349/581 [07:49<05:13,  1.35s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 3:  60%|██████    | 349/581 [07:50<05:13,  1.35s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  60%|██████    | 350/581 [07:50<05:11,  1.35s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  60%|██████    | 350/581 [07:51<05:11,  1.35s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  60%|██████    | 351/581 [07:51<05:10,  1.35s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  60%|██████    | 351/581 [07:53<05:10,  1.35s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 3:  61%|██████    | 352/581 [07:53<05:08,  1.35s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 3:  61%|██████    | 352/581 [07:54<05:08,  1.35s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  61%|██████    | 353/581 [07:54<05:07,  1.35s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  61%|██████    | 353/581 [07:55<05:07,  1.35s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  61%|██████    | 354/581 [07:55<05:06,  1.35s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  61%|██████    | 354/581 [07:57<05:06,  1.35s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  61%|██████    | 355/581 [07:57<05:04,  1.35s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  61%|██████    | 355/581 [07:58<05:04,  1.35s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 356/581 [07:58<05:03,  1.35s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 356/581 [07:59<05:03,  1.35s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 357/581 [07:59<05:01,  1.35s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 357/581 [08:01<05:01,  1.35s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 358/581 [08:01<04:59,  1.34s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 358/581 [08:02<04:59,  1.34s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 359/581 [08:02<04:58,  1.35s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 359/581 [08:04<04:58,  1.35s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 360/581 [08:04<04:57,  1.35s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 360/581 [08:05<04:57,  1.35s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 361/581 [08:05<04:56,  1.35s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 361/581 [08:06<04:56,  1.35s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 362/581 [08:06<04:56,  1.35s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 362/581 [08:08<04:56,  1.35s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 363/581 [08:08<04:54,  1.35s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 363/581 [08:09<04:54,  1.35s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 364/581 [08:09<04:52,  1.35s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 364/581 [08:10<04:52,  1.35s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 365/581 [08:10<04:51,  1.35s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 365/581 [08:12<04:51,  1.35s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 366/581 [08:12<04:49,  1.35s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 366/581 [08:13<04:49,  1.35s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 367/581 [08:13<04:49,  1.35s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 367/581 [08:14<04:49,  1.35s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 368/581 [08:14<04:47,  1.35s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 368/581 [08:16<04:47,  1.35s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 369/581 [08:16<04:46,  1.35s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 369/581 [08:17<04:46,  1.35s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 370/581 [08:17<04:44,  1.35s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 370/581 [08:18<04:44,  1.35s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 371/581 [08:18<04:43,  1.35s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 371/581 [08:20<04:43,  1.35s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 372/581 [08:20<04:41,  1.35s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 372/581 [08:21<04:41,  1.35s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 373/581 [08:21<04:41,  1.35s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 373/581 [08:22<04:41,  1.35s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 374/581 [08:22<04:39,  1.35s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 374/581 [08:24<04:39,  1.35s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 375/581 [08:24<04:37,  1.35s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 375/581 [08:25<04:37,  1.35s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 376/581 [08:25<04:37,  1.35s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 376/581 [08:26<04:37,  1.35s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 377/581 [08:26<04:35,  1.35s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 377/581 [08:28<04:35,  1.35s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 378/581 [08:28<04:34,  1.35s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 378/581 [08:29<04:34,  1.35s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 379/581 [08:29<04:32,  1.35s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 379/581 [08:31<04:32,  1.35s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 380/581 [08:31<04:30,  1.35s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 380/581 [08:32<04:30,  1.35s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 381/581 [08:32<04:28,  1.34s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 381/581 [08:33<04:28,  1.34s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 382/581 [08:33<04:28,  1.35s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 382/581 [08:35<04:28,  1.35s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 383/581 [08:35<04:27,  1.35s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 383/581 [08:36<04:27,  1.35s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 384/581 [08:36<04:26,  1.35s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 384/581 [08:37<04:26,  1.35s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 385/581 [08:37<04:24,  1.35s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 385/581 [08:39<04:24,  1.35s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 386/581 [08:39<04:22,  1.35s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 386/581 [08:40<04:22,  1.35s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 387/581 [08:40<04:21,  1.35s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 387/581 [08:41<04:21,  1.35s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 388/581 [08:41<04:20,  1.35s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 388/581 [08:43<04:20,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 389/581 [08:43<04:18,  1.35s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 389/581 [08:44<04:18,  1.35s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 390/581 [08:44<04:17,  1.35s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 390/581 [08:45<04:17,  1.35s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 391/581 [08:45<04:16,  1.35s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 391/581 [08:47<04:16,  1.35s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 392/581 [08:47<04:14,  1.35s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 392/581 [08:48<04:14,  1.35s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 393/581 [08:48<04:13,  1.35s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 393/581 [08:49<04:13,  1.35s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 394/581 [08:49<04:12,  1.35s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 394/581 [08:51<04:12,  1.35s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 395/581 [08:51<04:10,  1.35s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 395/581 [08:52<04:10,  1.35s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 396/581 [08:52<04:09,  1.35s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 396/581 [08:53<04:09,  1.35s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 397/581 [08:53<04:07,  1.34s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 397/581 [08:55<04:07,  1.34s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 398/581 [08:55<04:06,  1.35s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 398/581 [08:56<04:06,  1.35s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 399/581 [08:56<04:05,  1.35s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 399/581 [08:57<04:05,  1.35s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 400/581 [08:58<04:04,  1.35s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 400/581 [08:59<04:04,  1.35s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 401/581 [08:59<04:02,  1.35s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 401/581 [09:00<04:02,  1.35s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 402/581 [09:00<04:01,  1.35s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 402/581 [09:02<04:01,  1.35s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 403/581 [09:02<03:59,  1.35s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 403/581 [09:03<03:59,  1.35s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 404/581 [09:03<03:58,  1.35s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 404/581 [09:04<03:58,  1.35s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 405/581 [09:04<03:57,  1.35s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 405/581 [09:06<03:57,  1.35s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 406/581 [09:06<03:56,  1.35s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 406/581 [09:07<03:56,  1.35s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  70%|███████   | 407/581 [09:07<03:54,  1.35s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  70%|███████   | 407/581 [09:08<03:54,  1.35s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 3:  70%|███████   | 408/581 [09:08<03:52,  1.35s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 3:  70%|███████   | 408/581 [09:10<03:52,  1.35s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  70%|███████   | 409/581 [09:10<03:52,  1.35s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  70%|███████   | 409/581 [09:11<03:52,  1.35s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  71%|███████   | 410/581 [09:11<03:50,  1.35s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  71%|███████   | 410/581 [09:12<03:50,  1.35s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  71%|███████   | 411/581 [09:12<03:48,  1.34s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  71%|███████   | 411/581 [09:14<03:48,  1.34s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  71%|███████   | 412/581 [09:14<03:47,  1.35s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  71%|███████   | 412/581 [09:15<03:47,  1.35s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:  71%|███████   | 413/581 [09:15<03:46,  1.35s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:  71%|███████   | 413/581 [09:16<03:46,  1.35s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 414/581 [09:16<03:44,  1.34s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 414/581 [09:18<03:44,  1.34s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 415/581 [09:18<03:42,  1.34s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 415/581 [09:19<03:42,  1.34s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 416/581 [09:19<03:41,  1.34s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 416/581 [09:20<03:41,  1.34s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 417/581 [09:20<03:39,  1.34s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 417/581 [09:22<03:39,  1.34s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 418/581 [09:22<03:39,  1.34s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 418/581 [09:23<03:39,  1.34s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 419/581 [09:23<03:37,  1.34s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 419/581 [09:24<03:37,  1.34s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 420/581 [09:24<03:36,  1.35s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 420/581 [09:26<03:36,  1.35s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 421/581 [09:26<03:35,  1.35s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 421/581 [09:27<03:35,  1.35s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 422/581 [09:27<03:33,  1.35s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 422/581 [09:28<03:33,  1.35s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 423/581 [09:28<03:32,  1.35s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 423/581 [09:30<03:32,  1.35s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 424/581 [09:30<03:31,  1.35s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 424/581 [09:31<03:31,  1.35s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 425/581 [09:31<03:30,  1.35s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 425/581 [09:32<03:30,  1.35s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 426/581 [09:32<03:28,  1.35s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 426/581 [09:34<03:28,  1.35s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 427/581 [09:34<03:26,  1.34s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 427/581 [09:35<03:26,  1.34s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 428/581 [09:35<03:25,  1.34s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 428/581 [09:36<03:25,  1.34s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 429/581 [09:37<03:23,  1.34s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 429/581 [09:38<03:23,  1.34s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 430/581 [09:38<03:22,  1.34s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 430/581 [09:39<03:22,  1.34s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 431/581 [09:39<03:21,  1.34s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 431/581 [09:41<03:21,  1.34s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 432/581 [09:41<03:20,  1.35s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 432/581 [09:42<03:20,  1.35s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 433/581 [09:42<03:19,  1.35s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 433/581 [09:43<03:19,  1.35s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 434/581 [09:43<03:17,  1.34s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 434/581 [09:45<03:17,  1.34s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 435/581 [09:45<03:16,  1.34s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 435/581 [09:46<03:16,  1.34s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 436/581 [09:46<03:14,  1.34s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 436/581 [09:47<03:14,  1.34s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 437/581 [09:47<03:13,  1.34s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 437/581 [09:49<03:13,  1.34s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 438/581 [09:49<03:12,  1.34s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 438/581 [09:50<03:12,  1.34s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 439/581 [09:50<03:10,  1.34s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 439/581 [09:51<03:10,  1.34s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 440/581 [09:51<03:09,  1.35s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 440/581 [09:53<03:09,  1.35s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 441/581 [09:53<03:08,  1.34s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 441/581 [09:54<03:08,  1.34s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 442/581 [09:54<03:06,  1.34s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 442/581 [09:55<03:06,  1.34s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 443/581 [09:55<03:05,  1.34s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 443/581 [09:57<03:05,  1.34s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 444/581 [09:57<03:04,  1.34s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 444/581 [09:58<03:04,  1.34s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 445/581 [09:58<03:02,  1.34s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 445/581 [09:59<03:02,  1.34s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 446/581 [09:59<03:01,  1.35s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 446/581 [10:01<03:01,  1.35s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 447/581 [10:01<03:00,  1.35s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 447/581 [10:02<03:00,  1.35s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 448/581 [10:02<02:59,  1.35s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 448/581 [10:03<02:59,  1.35s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 449/581 [10:03<02:57,  1.35s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 449/581 [10:05<02:57,  1.35s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 450/581 [10:05<02:56,  1.35s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 450/581 [10:06<02:56,  1.35s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 451/581 [10:06<02:54,  1.35s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 451/581 [10:07<02:54,  1.35s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 452/581 [10:07<02:53,  1.34s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 452/581 [10:09<02:53,  1.34s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 453/581 [10:09<02:51,  1.34s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 453/581 [10:10<02:51,  1.34s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 454/581 [10:10<02:50,  1.34s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 454/581 [10:11<02:50,  1.34s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 455/581 [10:11<02:49,  1.34s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 455/581 [10:13<02:49,  1.34s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 456/581 [10:13<02:48,  1.35s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 456/581 [10:14<02:48,  1.35s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 457/581 [10:14<02:46,  1.35s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 457/581 [10:15<02:46,  1.35s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 458/581 [10:16<02:45,  1.35s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 458/581 [10:17<02:45,  1.35s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 459/581 [10:17<02:44,  1.35s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 459/581 [10:18<02:44,  1.35s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 460/581 [10:18<02:42,  1.34s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 460/581 [10:20<02:42,  1.34s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 461/581 [10:20<02:40,  1.34s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 461/581 [10:21<02:40,  1.34s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 462/581 [10:21<02:39,  1.34s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 462/581 [10:22<02:39,  1.34s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 463/581 [10:22<02:38,  1.34s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 463/581 [10:24<02:38,  1.34s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 464/581 [10:24<02:36,  1.34s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 464/581 [10:25<02:36,  1.34s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  80%|████████  | 465/581 [10:25<02:35,  1.34s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  80%|████████  | 465/581 [10:26<02:35,  1.34s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:  80%|████████  | 466/581 [10:26<02:34,  1.34s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:  80%|████████  | 466/581 [10:28<02:34,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  80%|████████  | 467/581 [10:28<02:33,  1.34s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  80%|████████  | 467/581 [10:29<02:33,  1.34s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 3:  81%|████████  | 468/581 [10:29<02:31,  1.34s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 3:  81%|████████  | 468/581 [10:30<02:31,  1.34s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:  81%|████████  | 469/581 [10:30<02:30,  1.34s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:  81%|████████  | 469/581 [10:32<02:30,  1.34s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  81%|████████  | 470/581 [10:32<02:29,  1.35s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  81%|████████  | 470/581 [10:33<02:29,  1.35s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 3:  81%|████████  | 471/581 [10:33<02:27,  1.35s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 3:  81%|████████  | 471/581 [10:34<02:27,  1.35s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  81%|████████  | 472/581 [10:34<02:26,  1.35s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  81%|████████  | 472/581 [10:36<02:26,  1.35s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 473/581 [10:36<02:25,  1.35s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 473/581 [10:37<02:25,  1.35s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 474/581 [10:37<02:24,  1.35s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 474/581 [10:38<02:24,  1.35s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 475/581 [10:38<02:22,  1.35s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 475/581 [10:40<02:22,  1.35s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 476/581 [10:40<02:20,  1.34s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 476/581 [10:41<02:20,  1.34s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 477/581 [10:41<02:19,  1.34s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 477/581 [10:42<02:19,  1.34s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 478/581 [10:42<02:18,  1.34s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 478/581 [10:44<02:18,  1.34s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 479/581 [10:44<02:16,  1.34s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 479/581 [10:45<02:16,  1.34s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 480/581 [10:45<02:15,  1.34s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 480/581 [10:46<02:15,  1.34s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 481/581 [10:46<02:13,  1.34s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 481/581 [10:48<02:13,  1.34s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 482/581 [10:48<02:12,  1.34s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 482/581 [10:49<02:12,  1.34s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 483/581 [10:49<02:11,  1.34s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 483/581 [10:50<02:11,  1.34s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 484/581 [10:50<02:09,  1.34s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 484/581 [10:52<02:09,  1.34s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 485/581 [10:52<02:08,  1.34s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 485/581 [10:53<02:08,  1.34s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 486/581 [10:53<02:07,  1.34s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 486/581 [10:54<02:07,  1.34s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 487/581 [10:54<02:05,  1.34s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 487/581 [10:56<02:05,  1.34s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 488/581 [10:56<02:04,  1.34s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 488/581 [10:57<02:04,  1.34s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 489/581 [10:57<02:03,  1.34s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 489/581 [10:58<02:03,  1.34s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 490/581 [10:58<02:01,  1.34s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 490/581 [11:00<02:01,  1.34s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 491/581 [11:00<02:00,  1.34s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 491/581 [11:01<02:00,  1.34s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 492/581 [11:01<01:59,  1.34s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 492/581 [11:02<01:59,  1.34s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 493/581 [11:02<01:58,  1.34s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 493/581 [11:04<01:58,  1.34s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 494/581 [11:04<01:56,  1.34s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 494/581 [11:05<01:56,  1.34s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 495/581 [11:05<01:55,  1.34s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 495/581 [11:07<01:55,  1.34s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 496/581 [11:07<01:54,  1.34s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 496/581 [11:08<01:54,  1.34s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 497/581 [11:08<01:52,  1.34s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 497/581 [11:09<01:52,  1.34s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 498/581 [11:09<01:51,  1.34s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 498/581 [11:11<01:51,  1.34s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 499/581 [11:11<01:50,  1.34s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 499/581 [11:12<01:50,  1.34s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 500/581 [11:12<01:48,  1.34s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 500/581 [11:13<01:48,  1.34s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 501/581 [11:13<01:47,  1.34s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 501/581 [11:15<01:47,  1.34s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 502/581 [11:15<01:46,  1.34s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 502/581 [11:16<01:46,  1.34s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 503/581 [11:16<01:45,  1.35s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 503/581 [11:17<01:45,  1.35s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 504/581 [11:17<01:43,  1.35s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 504/581 [11:19<01:43,  1.35s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 505/581 [11:19<01:41,  1.34s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 505/581 [11:20<01:41,  1.34s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 506/581 [11:20<01:40,  1.34s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 506/581 [11:21<01:40,  1.34s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 507/581 [11:21<01:39,  1.35s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 507/581 [11:23<01:39,  1.35s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 508/581 [11:23<01:38,  1.34s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 508/581 [11:24<01:38,  1.34s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 509/581 [11:24<01:36,  1.34s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 509/581 [11:25<01:36,  1.34s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 510/581 [11:25<01:35,  1.34s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 510/581 [11:27<01:35,  1.34s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 511/581 [11:27<01:34,  1.35s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 511/581 [11:28<01:34,  1.35s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 512/581 [11:28<01:32,  1.35s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 512/581 [11:29<01:32,  1.35s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 513/581 [11:29<01:31,  1.34s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 513/581 [11:31<01:31,  1.34s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 514/581 [11:31<01:29,  1.34s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 514/581 [11:32<01:29,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 515/581 [11:32<01:28,  1.34s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 515/581 [11:33<01:28,  1.34s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 516/581 [11:33<01:27,  1.34s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 516/581 [11:35<01:27,  1.34s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 517/581 [11:35<01:26,  1.35s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 517/581 [11:36<01:26,  1.35s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 518/581 [11:36<01:24,  1.34s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 518/581 [11:37<01:24,  1.34s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 519/581 [11:37<01:23,  1.34s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 519/581 [11:39<01:23,  1.34s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 520/581 [11:39<01:21,  1.34s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 520/581 [11:40<01:21,  1.34s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 521/581 [11:40<01:20,  1.34s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 521/581 [11:41<01:20,  1.34s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 522/581 [11:41<01:19,  1.34s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 522/581 [11:43<01:19,  1.34s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 523/581 [11:43<01:17,  1.34s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 523/581 [11:44<01:17,  1.34s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 524/581 [11:44<01:16,  1.34s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 524/581 [11:45<01:16,  1.34s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 525/581 [11:45<01:14,  1.34s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 525/581 [11:47<01:14,  1.34s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 526/581 [11:47<01:13,  1.34s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 526/581 [11:48<01:13,  1.34s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 527/581 [11:48<01:12,  1.34s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 527/581 [11:49<01:12,  1.34s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 528/581 [11:49<01:11,  1.34s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 528/581 [11:51<01:11,  1.34s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 529/581 [11:51<01:09,  1.34s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 529/581 [11:52<01:09,  1.34s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 530/581 [11:52<01:08,  1.34s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 530/581 [11:53<01:08,  1.34s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 531/581 [11:53<01:07,  1.34s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 531/581 [11:55<01:07,  1.34s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 532/581 [11:55<01:05,  1.34s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 532/581 [11:56<01:05,  1.34s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 533/581 [11:56<01:04,  1.34s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 533/581 [11:58<01:04,  1.34s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 534/581 [11:58<01:03,  1.34s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 534/581 [11:59<01:03,  1.34s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 535/581 [11:59<01:01,  1.34s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 535/581 [12:00<01:01,  1.34s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 536/581 [12:00<01:00,  1.35s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 536/581 [12:02<01:00,  1.35s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 537/581 [12:02<00:59,  1.35s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 537/581 [12:03<00:59,  1.35s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 538/581 [12:03<00:57,  1.35s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 538/581 [12:04<00:57,  1.35s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 539/581 [12:04<00:56,  1.35s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 539/581 [12:06<00:56,  1.35s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 540/581 [12:06<00:55,  1.35s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 540/581 [12:07<00:55,  1.35s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 541/581 [12:07<00:53,  1.35s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 541/581 [12:08<00:53,  1.35s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 542/581 [12:08<00:52,  1.35s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 542/581 [12:10<00:52,  1.35s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 543/581 [12:10<00:51,  1.35s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 543/581 [12:11<00:51,  1.35s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 544/581 [12:11<00:49,  1.35s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 544/581 [12:12<00:49,  1.35s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 545/581 [12:12<00:48,  1.35s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 545/581 [12:14<00:48,  1.35s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 546/581 [12:14<00:47,  1.35s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 546/581 [12:15<00:47,  1.35s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 547/581 [12:15<00:45,  1.35s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 547/581 [12:16<00:45,  1.35s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 548/581 [12:16<00:44,  1.35s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 548/581 [12:18<00:44,  1.35s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 549/581 [12:18<00:43,  1.35s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 549/581 [12:19<00:43,  1.35s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 550/581 [12:19<00:41,  1.35s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 550/581 [12:20<00:41,  1.35s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 551/581 [12:20<00:40,  1.35s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 551/581 [12:22<00:40,  1.35s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 552/581 [12:22<00:39,  1.35s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 552/581 [12:23<00:39,  1.35s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 553/581 [12:23<00:37,  1.35s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 553/581 [12:24<00:37,  1.35s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 554/581 [12:24<00:36,  1.35s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 554/581 [12:26<00:36,  1.35s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 555/581 [12:26<00:34,  1.35s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 555/581 [12:27<00:34,  1.35s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 556/581 [12:27<00:33,  1.34s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 556/581 [12:28<00:33,  1.34s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 557/581 [12:29<00:32,  1.34s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 557/581 [12:30<00:32,  1.34s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 558/581 [12:30<00:30,  1.35s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 558/581 [12:31<00:30,  1.35s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 559/581 [12:31<00:29,  1.35s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 559/581 [12:33<00:29,  1.35s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 560/581 [12:33<00:28,  1.35s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 560/581 [12:34<00:28,  1.35s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 561/581 [12:34<00:26,  1.34s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 561/581 [12:35<00:26,  1.34s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 562/581 [12:35<00:25,  1.34s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 562/581 [12:37<00:25,  1.34s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 563/581 [12:37<00:24,  1.35s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 563/581 [12:38<00:24,  1.35s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 564/581 [12:38<00:22,  1.35s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 564/581 [12:39<00:22,  1.35s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 565/581 [12:39<00:21,  1.35s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 565/581 [12:41<00:21,  1.35s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 566/581 [12:41<00:20,  1.34s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 566/581 [12:42<00:20,  1.34s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 567/581 [12:42<00:18,  1.34s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 567/581 [12:43<00:18,  1.34s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 568/581 [12:43<00:17,  1.34s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 568/581 [12:45<00:17,  1.34s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 569/581 [12:45<00:16,  1.34s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 569/581 [12:46<00:16,  1.34s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 570/581 [12:46<00:14,  1.34s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 570/581 [12:47<00:14,  1.34s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 571/581 [12:47<00:13,  1.34s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 571/581 [12:49<00:13,  1.34s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 572/581 [12:49<00:12,  1.34s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 572/581 [12:50<00:12,  1.34s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 573/581 [12:50<00:10,  1.34s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 573/581 [12:51<00:10,  1.34s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 574/581 [12:51<00:09,  1.34s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 574/581 [12:53<00:09,  1.34s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 575/581 [12:53<00:08,  1.34s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 575/581 [12:54<00:08,  1.34s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 576/581 [12:54<00:06,  1.35s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 576/581 [12:55<00:06,  1.35s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 577/581 [12:55<00:05,  1.35s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 577/581 [12:57<00:05,  1.35s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 578/581 [12:57<00:04,  1.35s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 578/581 [12:58<00:04,  1.35s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 579/581 [12:58<00:02,  1.35s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 579/581 [12:59<00:02,  1.35s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 580/581 [12:59<00:01,  1.34s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 580/581 [13:00<00:01,  1.34s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 3: 100%|██████████| 581/581 [13:00<00:00,  1.13s/it, training_loss=0.042]\u001b[A\n",
            " 67%|██████▋   | 2/3 [42:21<14:39, 879.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3\n",
            "Training loss: 0.38296622688050114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [43:55<00:00, 878.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5796988621046862\n",
            "F1 Score (Weighted): 0.8045780593899449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w3LIWQKqF9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a1cac0-9ec3-4c6f-ff1d-aed1ccfb2cfb"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: Yes\n",
            "Accuracy: 2557/2901\n",
            "\n",
            "Class: No\n",
            "Accuracy: 1875/2166\n",
            "\n",
            "Class: In the middle, neither yes nor no\n",
            "Accuracy: 50/127\n",
            "\n",
            "Class: Probably yes / sometimes yes\n",
            "Accuracy: 86/249\n",
            "\n",
            "Class: Probably no\n",
            "Accuracy: 29/232\n",
            "\n",
            "Class: Yes, subject to some conditions\n",
            "Accuracy: 466/517\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rjF9G7VqFPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19cb4dc4-753c-4524-dbd0-22b3a8fd6032"
      },
      "source": [
        "print('Dev Accuracy:', end = ' ')\n",
        "flat_accuracy(predictions, true_vals)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dev Accuracy: "
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8176679586563308"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_bCLLiLqFDq"
      },
      "source": [
        "encoded_data_test = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='test'].YN_s.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=256, \n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_test = encoded_data_test['input_ids']\n",
        "attention_masks_test = encoded_data_test['attention_mask']\n",
        "labels_test = torch.tensor(df[df.data_type=='test'].strict.values)\n",
        "\n",
        "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "\n",
        "dataloader_test = DataLoader(dataset_test, \n",
        "                                   sampler=SequentialSampler(dataset_test), \n",
        "                                   batch_size=batch_size)\n",
        "\n",
        "test_loss, test_predictions, test_true_vals = evaluate(dataloader_test)\n",
        "test_f1 = f1_score_func(test_predictions, test_true_vals)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AegQA5eE-KqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70609fef-ed30-4828-8e1b-de9dbf0f961d"
      },
      "source": [
        "accuracy_per_class(test_predictions, test_true_vals)\n",
        "print('Test Accuracy:', end = ' ')\n",
        "flat_accuracy(test_predictions, test_true_vals)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: Yes\n",
            "Accuracy: 2583/2901\n",
            "\n",
            "Class: No\n",
            "Accuracy: 1890/2166\n",
            "\n",
            "Class: In the middle, neither yes nor no\n",
            "Accuracy: 44/128\n",
            "\n",
            "Class: Probably yes / sometimes yes\n",
            "Accuracy: 92/249\n",
            "\n",
            "Class: Probably no\n",
            "Accuracy: 38/232\n",
            "\n",
            "Class: Yes, subject to some conditions\n",
            "Accuracy: 468/516\n",
            "\n",
            "Test Accuracy: "
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8260658914728682"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S91mcLzu94KP"
      },
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": []
    }
  ]
}