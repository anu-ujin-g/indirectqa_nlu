{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "boolq_strict_matched",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7b2fe0ded0bc4949b1991c818fe4a19c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6995f770e5994f8b87b6871a35c74d0c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_94de30b3c325444e841916f4d82f976b",
              "IPY_MODEL_ad488fc0bcc74d98be7fb950e5bb987c"
            ]
          }
        },
        "6995f770e5994f8b87b6871a35c74d0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94de30b3c325444e841916f4d82f976b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_70531466576a435f8644e879d0d0eda9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d40fa5ab75a6464fa1350086eb86767a"
          }
        },
        "ad488fc0bcc74d98be7fb950e5bb987c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7f50f12b3000401ea21a5ae6db1c4173",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 2.19kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0803487ceb9e483a8cf1d4d272c11f4d"
          }
        },
        "70531466576a435f8644e879d0d0eda9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d40fa5ab75a6464fa1350086eb86767a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7f50f12b3000401ea21a5ae6db1c4173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0803487ceb9e483a8cf1d4d272c11f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "adf4dc80f5fc40c9b0afe2780e8db096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c5142405831940ea897aa21de9eca78e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_76c6e4e51961480c940727f5c32ddcb3",
              "IPY_MODEL_131ba1ee3075476d9842bc469ff6bd4a"
            ]
          }
        },
        "c5142405831940ea897aa21de9eca78e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76c6e4e51961480c940727f5c32ddcb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7af310eedcec4e2584c9ea80670c5411",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dafae8ec676642859a7f5fb0749766ee"
          }
        },
        "131ba1ee3075476d9842bc469ff6bd4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_55509cd84b7b43678db356df728a242b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 3.24MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0288c9ee76a74010af1ca6c88fac4d1d"
          }
        },
        "7af310eedcec4e2584c9ea80670c5411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dafae8ec676642859a7f5fb0749766ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55509cd84b7b43678db356df728a242b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0288c9ee76a74010af1ca6c88fac4d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f8f8202ccbb4e94bd8de6a78e4cb0f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0ca10cb3dbb6497baa33b6b73a865eac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6fa7ac28b3914d58b09defabc92a15ec",
              "IPY_MODEL_30c21c1a9f8d4d619d56d314427ccac8"
            ]
          }
        },
        "0ca10cb3dbb6497baa33b6b73a865eac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6fa7ac28b3914d58b09defabc92a15ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_21ab6bc4d9e64ba5b9dab82307e67760",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_174df6d4f7204360954b10f5444b1f0c"
          }
        },
        "30c21c1a9f8d4d619d56d314427ccac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2f37f0457dea4aaba23740e87b6a275f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:08&lt;00:00, 51.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_999cc193847f48b8877f9ec05965375d"
          }
        },
        "21ab6bc4d9e64ba5b9dab82307e67760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "174df6d4f7204360954b10f5444b1f0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f37f0457dea4aaba23740e87b6a275f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "999cc193847f48b8877f9ec05965375d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHPrujng28-7",
        "outputId": "2113e6c9-0c3a-46e8-c190-0f8a899cb31e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HkugCqiD-e9",
        "outputId": "08c8b33c-98a6-4213-b706-b17b7692e9b5"
      },
      "source": [
        "!pip install transformers==2.5.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\r\u001b[K     |▋                               | 10kB 25.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 33.0MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 23.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 27.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 23.2MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 19.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 17.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 17.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 16.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 16.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 245kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276kB 16.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 337kB 16.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 348kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 368kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399kB 16.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 430kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 440kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 450kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 460kB 16.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 471kB 16.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 481kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 491kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 16.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2.23.0)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/e3/5e49e9a83fb605aaa34a1c1173e607302fecae529428c28696fb18f1c2c9/tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 54.0MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 51.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 51.6MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/a5/892ed5d2959b1fdf4f8aaccf96b299e57dd7f06db7072592901fbaa36d79/boto3-1.17.54-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 56.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (1.19.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.15.0)\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/50/ac379fa31377f5d316cad8967db9f73c50cd61b80153269bfd7d8b964fc8/s3transfer-0.4.0-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.8MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.54\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/e1/59cc39d22d44e64e96186db87d6e670e2119822d16299e18d0500198abb4/botocore-1.20.54-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 46.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.54->boto3->transformers==2.5.1) (2.8.1)\n",
            "\u001b[31mERROR: botocore 1.20.54 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, jmespath, botocore, s3transfer, boto3, transformers\n",
            "Successfully installed boto3-1.17.54 botocore-1.20.54 jmespath-0.10.0 s3transfer-0.4.0 sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3IdDlBz3ZaK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "# from transformers import AutoTokenizer, BertTokenizer, EvalPrediction, BertPreTrainedModel, BertConfig, BertModel, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6PGzfGHq4kZ",
        "outputId": "9c05b4ce-ddb9-4843-b192-4e0b1505159c"
      },
      "source": [
        "cd '/content/drive/MyDrive/'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9_N6KwgmcXL"
      },
      "source": [
        "## Data pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzL4OXr_ZCZD"
      },
      "source": [
        "Strict-matched"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPj_AqIO4eeI"
      },
      "source": [
        "circa_og = pd.read_csv('NLU_Project/circa-data.tsv', sep='\\t', index_col='id')\n",
        "circa_s = circa_og.drop(circa_og.loc[circa_og['goldstandard1']=='Other'].index)\n",
        "circa_s = circa_s.drop(circa_s.loc[circa_s['goldstandard1'].isnull()].index)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW9QqMAjf7p-"
      },
      "source": [
        "YN_s = (circa_s['question-X'].map(str)+' '+circa_s['answer-Y']).apply(lambda row: row.strip())\n",
        "strict_labels = circa_s['goldstandard1'].unique()\n",
        "strict_label = circa_s['goldstandard1']\n",
        "strict_dict = {}\n",
        "for idx, label in enumerate(strict_labels):\n",
        "    strict_dict[label] = idx\n",
        "circa_s['strict'] = circa_s.goldstandard1.replace(strict_dict)\n",
        "strict = circa_s['strict']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXRa_O3WahTw",
        "outputId": "4ced4218-dacc-43a8-ffc0-c759540e335e"
      },
      "source": [
        "strict_dict"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'I am not sure how X will interpret Y’s answer': 6,\n",
              " 'In the middle, neither yes nor no': 2,\n",
              " 'No': 1,\n",
              " 'Probably no': 4,\n",
              " 'Probably yes / sometimes yes': 3,\n",
              " 'Yes': 0,\n",
              " 'Yes, subject to some conditions': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn0h950hmUU5"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSmxC4gJ4ZE9",
        "outputId": "6fbcebd7-c05f-4579-8100-e65a870c4d03"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeoL9QXBmXR9"
      },
      "source": [
        "### Strict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jinT4bf1Zyc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "7b2fe0ded0bc4949b1991c818fe4a19c",
            "6995f770e5994f8b87b6871a35c74d0c",
            "94de30b3c325444e841916f4d82f976b",
            "ad488fc0bcc74d98be7fb950e5bb987c",
            "70531466576a435f8644e879d0d0eda9",
            "d40fa5ab75a6464fa1350086eb86767a",
            "7f50f12b3000401ea21a5ae6db1c4173",
            "0803487ceb9e483a8cf1d4d272c11f4d",
            "adf4dc80f5fc40c9b0afe2780e8db096",
            "c5142405831940ea897aa21de9eca78e",
            "76c6e4e51961480c940727f5c32ddcb3",
            "131ba1ee3075476d9842bc469ff6bd4a",
            "7af310eedcec4e2584c9ea80670c5411",
            "dafae8ec676642859a7f5fb0749766ee",
            "55509cd84b7b43678db356df728a242b",
            "0288c9ee76a74010af1ca6c88fac4d1d",
            "4f8f8202ccbb4e94bd8de6a78e4cb0f7",
            "0ca10cb3dbb6497baa33b6b73a865eac",
            "6fa7ac28b3914d58b09defabc92a15ec",
            "30c21c1a9f8d4d619d56d314427ccac8",
            "21ab6bc4d9e64ba5b9dab82307e67760",
            "174df6d4f7204360954b10f5444b1f0c",
            "2f37f0457dea4aaba23740e87b6a275f",
            "999cc193847f48b8877f9ec05965375d"
          ]
        },
        "outputId": "d9286db5-a9c7-40a9-cd8c-3544ade4505b"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\") \n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "saved = torch.load('DS-GA 1012/boolq.pth')\n",
        "model.load_state_dict(saved['model'])\n",
        "# optimizer = model['optimizer']\n",
        "model.to(device) # Send the model to the GPU if we have one\n",
        "\n",
        "learning_rate = 3e-5\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b2fe0ded0bc4949b1991c818fe4a19c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "adf4dc80f5fc40c9b0afe2780e8db096",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f8f8202ccbb4e94bd8de6a78e4cb0f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BjmZLHa7Nne",
        "outputId": "a152fc28-5a8c-43bb-83ad-a835b3f84687"
      },
      "source": [
        "max_len = 0\n",
        "for entry in YN_s.values:\n",
        "    input_ids = tokenizer.encode(entry,  add_special_tokens=True)\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "print(max_len)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "Fv5cc_qyWPFS",
        "outputId": "486f520b-c2dd-4f6f-c68a-6267562b9ce7"
      },
      "source": [
        "df = pd.concat([YN_s, strict_label, strict], axis=1).rename(columns={0:'YN_s'})\n",
        "df"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YN_s</th>\n",
              "      <th>goldstandard1</th>\n",
              "      <th>strict</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Are you employed? I'm a veterinary technician.</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are you a fan of Korean food? I wouldn't say so</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Are you bringing any pets into the flat? I do ...</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Would you like to get some fresh air in your f...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Is your family still living in the neighborhoo...</td>\n",
              "      <td>In the middle, neither yes nor no</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34263</th>\n",
              "      <td>Do you like to drink? I am in AA.</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34264</th>\n",
              "      <td>Do you like pie? My favorite pie is pecan.</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34265</th>\n",
              "      <td>Want to go to a concert with me? I'd rather do...</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34266</th>\n",
              "      <td>Do you like hip/hop music? I can't dance to hi...</td>\n",
              "      <td>Probably no</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34267</th>\n",
              "      <td>Do you see yourself raising a family in New Yo...</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31021 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    YN_s  ... strict\n",
              "id                                                        ...       \n",
              "0         Are you employed? I'm a veterinary technician.  ...      0\n",
              "1        Are you a fan of Korean food? I wouldn't say so  ...      1\n",
              "2      Are you bringing any pets into the flat? I do ...  ...      1\n",
              "3      Would you like to get some fresh air in your f...  ...      0\n",
              "4      Is your family still living in the neighborhoo...  ...      2\n",
              "...                                                  ...  ...    ...\n",
              "34263                  Do you like to drink? I am in AA.  ...      1\n",
              "34264         Do you like pie? My favorite pie is pecan.  ...      0\n",
              "34265  Want to go to a concert with me? I'd rather do...  ...      1\n",
              "34266  Do you like hip/hop music? I can't dance to hi...  ...      4\n",
              "34267  Do you see yourself raising a family in New Yo...  ...      1\n",
              "\n",
              "[31021 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulXaXpJiVrcT"
      },
      "source": [
        "train_strict, val_strict, trainy_strict, valy_strict = train_test_split(df.index.values, df.strict.values, test_size=.4, stratify=df.strict.values)\n",
        "test_strict, dev_strict, testy_strict, devy_strict = train_test_split(val_strict, valy_strict, test_size=.5, stratify=valy_strict)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O06VmOd-VrWL"
      },
      "source": [
        "df['data_type'] = ['not_set']*df.shape[0]\n",
        "df.loc[train_strict,'data_type'] = 'train'\n",
        "df.loc[dev_strict,'data_type'] = 'dev'\n",
        "df.loc[test_strict,'data_type'] = 'test'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "roLxfOJAVdt_",
        "outputId": "b009d32d-be82-44c1-f726-13d262c8def3"
      },
      "source": [
        "df.groupby(['goldstandard1','strict','data_type']).count()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>YN_s</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goldstandard1</th>\n",
              "      <th>strict</th>\n",
              "      <th>data_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">I am not sure how X will interpret Y’s answer</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">6</th>\n",
              "      <th>dev</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">In the middle, neither yes nor no</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
              "      <th>dev</th>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">No</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
              "      <th>dev</th>\n",
              "      <td>2166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>2166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>6497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">Probably no</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">4</th>\n",
              "      <th>dev</th>\n",
              "      <td>232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">Probably yes / sometimes yes</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
              "      <th>dev</th>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">Yes</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
              "      <th>dev</th>\n",
              "      <td>2901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>2901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>8702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">Yes, subject to some conditions</th>\n",
              "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
              "      <th>dev</th>\n",
              "      <td>517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>1550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                YN_s\n",
              "goldstandard1                                 strict data_type      \n",
              "I am not sure how X will interpret Y’s answer 6      dev          12\n",
              "                                                     test         13\n",
              "                                                     train        38\n",
              "In the middle, neither yes nor no             2      dev         128\n",
              "                                                     test        127\n",
              "                                                     train       383\n",
              "No                                            1      dev        2166\n",
              "                                                     test       2166\n",
              "                                                     train      6497\n",
              "Probably no                                   4      dev         232\n",
              "                                                     test        232\n",
              "                                                     train       696\n",
              "Probably yes / sometimes yes                  3      dev         249\n",
              "                                                     test        249\n",
              "                                                     train       746\n",
              "Yes                                           0      dev        2901\n",
              "                                                     test       2901\n",
              "                                                     train      8702\n",
              "Yes, subject to some conditions               5      dev         517\n",
              "                                                     test        516\n",
              "                                                     train      1550"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCQzgsZpYb7k"
      },
      "source": [
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='train'].YN_s.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=256, \n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_dev = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='dev'].YN_s.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=256, \n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df[df.data_type=='train'].strict.values)\n",
        "\n",
        "input_ids_dev = encoded_data_dev['input_ids']\n",
        "attention_masks_dev = encoded_data_dev['attention_mask']\n",
        "labels_dev = torch.tensor(df[df.data_type=='dev'].strict.values)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITsWnPAoYb1B"
      },
      "source": [
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_dev = TensorDataset(input_ids_dev, attention_masks_dev, labels_dev)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxXgN_qkYboP",
        "outputId": "83c370e0-9e40-4309-8a59-61b3db5e4c04"
      },
      "source": [
        "len(dataset_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18612"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBGmxeLQYbh2",
        "outputId": "2874d7df-5992-4357-df66-dcabe7b7d4a6"
      },
      "source": [
        "model.classifier = torch.nn.Linear(model.classifier.in_features, 7)\n",
        "model.num_labels = 7\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
        "model.to(device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f4D3pbiYbd9"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, \n",
        "                              sampler=RandomSampler(dataset_train), \n",
        "                              batch_size=batch_size)\n",
        "\n",
        "dataloader_validation = DataLoader(dataset_dev, \n",
        "                                   sampler=SequentialSampler(dataset_dev), \n",
        "                                   batch_size=batch_size)\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = 1e-8)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9mezaQuZtMn"
      },
      "source": [
        "epochs = 3\n",
        "total_steps = len(dataloader_train) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3mrMRzuZtF5"
      },
      "source": [
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in strict_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)} = {len(y_preds[y_preds==label])/len(y_true)}\\n')\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98gXVUdIZs_F"
      },
      "source": [
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8O6SdezZs7E",
        "outputId": "5c30eb60-73a0-45ee-a59c-590fc076cfbb"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaOGmI3KZszz"
      },
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in dataloader_val:\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IquyMsgoZstF",
        "outputId": "d4e1f52c-0dad-4434-f78a-f67749b3c764"
      },
      "source": [
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    loss_train_total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        model.zero_grad()\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }       \n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "         \n",
        "        \n",
        "    torch.save(model.state_dict(), f'finetuned_BERT_strict_epoch_{epoch}.model')\n",
        "        \n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    dev_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
        "    dev_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {dev_loss}')\n",
        "    tqdm.write(f'F1 Score (Weighted): {dev_f1}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 0/582 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Epoch 1:   0%|          | 0/582 [00:01<?, ?it/s, training_loss=0.564]\u001b[A\n",
            "Epoch 1:   0%|          | 1/582 [00:01<14:50,  1.53s/it, training_loss=0.564]\u001b[A\n",
            "Epoch 1:   0%|          | 1/582 [00:02<14:50,  1.53s/it, training_loss=0.592]\u001b[A\n",
            "Epoch 1:   0%|          | 2/582 [00:02<14:00,  1.45s/it, training_loss=0.592]\u001b[A\n",
            "Epoch 1:   0%|          | 2/582 [00:04<14:00,  1.45s/it, training_loss=0.499]\u001b[A\n",
            "Epoch 1:   1%|          | 3/582 [00:04<13:22,  1.39s/it, training_loss=0.499]\u001b[A\n",
            "Epoch 1:   1%|          | 3/582 [00:05<13:22,  1.39s/it, training_loss=0.503]\u001b[A\n",
            "Epoch 1:   1%|          | 4/582 [00:05<12:57,  1.35s/it, training_loss=0.503]\u001b[A\n",
            "Epoch 1:   1%|          | 4/582 [00:06<12:57,  1.35s/it, training_loss=0.551]\u001b[A\n",
            "Epoch 1:   1%|          | 5/582 [00:06<12:38,  1.32s/it, training_loss=0.551]\u001b[A\n",
            "Epoch 1:   1%|          | 5/582 [00:07<12:38,  1.32s/it, training_loss=0.485]\u001b[A\n",
            "Epoch 1:   1%|          | 6/582 [00:07<12:27,  1.30s/it, training_loss=0.485]\u001b[A\n",
            "Epoch 1:   1%|          | 6/582 [00:09<12:27,  1.30s/it, training_loss=0.527]\u001b[A\n",
            "Epoch 1:   1%|          | 7/582 [00:09<12:18,  1.28s/it, training_loss=0.527]\u001b[A\n",
            "Epoch 1:   1%|          | 7/582 [00:10<12:18,  1.28s/it, training_loss=0.509]\u001b[A\n",
            "Epoch 1:   1%|▏         | 8/582 [00:10<12:10,  1.27s/it, training_loss=0.509]\u001b[A\n",
            "Epoch 1:   1%|▏         | 8/582 [00:11<12:10,  1.27s/it, training_loss=0.512]\u001b[A\n",
            "Epoch 1:   2%|▏         | 9/582 [00:11<12:07,  1.27s/it, training_loss=0.512]\u001b[A\n",
            "Epoch 1:   2%|▏         | 9/582 [00:12<12:07,  1.27s/it, training_loss=0.384]\u001b[A\n",
            "Epoch 1:   2%|▏         | 10/582 [00:12<12:05,  1.27s/it, training_loss=0.384]\u001b[A\n",
            "Epoch 1:   2%|▏         | 10/582 [00:14<12:05,  1.27s/it, training_loss=0.486]\u001b[A\n",
            "Epoch 1:   2%|▏         | 11/582 [00:14<12:02,  1.27s/it, training_loss=0.486]\u001b[A\n",
            "Epoch 1:   2%|▏         | 11/582 [00:15<12:02,  1.27s/it, training_loss=0.474]\u001b[A\n",
            "Epoch 1:   2%|▏         | 12/582 [00:15<11:59,  1.26s/it, training_loss=0.474]\u001b[A\n",
            "Epoch 1:   2%|▏         | 12/582 [00:16<11:59,  1.26s/it, training_loss=0.442]\u001b[A\n",
            "Epoch 1:   2%|▏         | 13/582 [00:16<11:58,  1.26s/it, training_loss=0.442]\u001b[A\n",
            "Epoch 1:   2%|▏         | 13/582 [00:17<11:58,  1.26s/it, training_loss=0.437]\u001b[A\n",
            "Epoch 1:   2%|▏         | 14/582 [00:17<11:57,  1.26s/it, training_loss=0.437]\u001b[A\n",
            "Epoch 1:   2%|▏         | 14/582 [00:19<11:57,  1.26s/it, training_loss=0.434]\u001b[A\n",
            "Epoch 1:   3%|▎         | 15/582 [00:19<11:56,  1.26s/it, training_loss=0.434]\u001b[A\n",
            "Epoch 1:   3%|▎         | 15/582 [00:20<11:56,  1.26s/it, training_loss=0.403]\u001b[A\n",
            "Epoch 1:   3%|▎         | 16/582 [00:20<11:55,  1.26s/it, training_loss=0.403]\u001b[A\n",
            "Epoch 1:   3%|▎         | 16/582 [00:21<11:55,  1.26s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:   3%|▎         | 17/582 [00:21<11:53,  1.26s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:   3%|▎         | 17/582 [00:22<11:53,  1.26s/it, training_loss=0.350]\u001b[A\n",
            "Epoch 1:   3%|▎         | 18/582 [00:22<11:53,  1.26s/it, training_loss=0.350]\u001b[A\n",
            "Epoch 1:   3%|▎         | 18/582 [00:24<11:53,  1.26s/it, training_loss=0.433]\u001b[A\n",
            "Epoch 1:   3%|▎         | 19/582 [00:24<11:54,  1.27s/it, training_loss=0.433]\u001b[A\n",
            "Epoch 1:   3%|▎         | 19/582 [00:25<11:54,  1.27s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:   3%|▎         | 20/582 [00:25<11:54,  1.27s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:   3%|▎         | 20/582 [00:26<11:54,  1.27s/it, training_loss=0.471]\u001b[A\n",
            "Epoch 1:   4%|▎         | 21/582 [00:26<11:53,  1.27s/it, training_loss=0.471]\u001b[A\n",
            "Epoch 1:   4%|▎         | 21/582 [00:28<11:53,  1.27s/it, training_loss=0.368]\u001b[A\n",
            "Epoch 1:   4%|▍         | 22/582 [00:28<11:54,  1.28s/it, training_loss=0.368]\u001b[A\n",
            "Epoch 1:   4%|▍         | 22/582 [00:29<11:54,  1.28s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 1:   4%|▍         | 23/582 [00:29<11:53,  1.28s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 1:   4%|▍         | 23/582 [00:30<11:53,  1.28s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:   4%|▍         | 24/582 [00:30<11:51,  1.28s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:   4%|▍         | 24/582 [00:31<11:51,  1.28s/it, training_loss=0.452]\u001b[A\n",
            "Epoch 1:   4%|▍         | 25/582 [00:31<11:52,  1.28s/it, training_loss=0.452]\u001b[A\n",
            "Epoch 1:   4%|▍         | 25/582 [00:33<11:52,  1.28s/it, training_loss=0.467]\u001b[A\n",
            "Epoch 1:   4%|▍         | 26/582 [00:33<11:52,  1.28s/it, training_loss=0.467]\u001b[A\n",
            "Epoch 1:   4%|▍         | 26/582 [00:34<11:52,  1.28s/it, training_loss=0.344]\u001b[A\n",
            "Epoch 1:   5%|▍         | 27/582 [00:34<11:50,  1.28s/it, training_loss=0.344]\u001b[A\n",
            "Epoch 1:   5%|▍         | 27/582 [00:35<11:50,  1.28s/it, training_loss=0.432]\u001b[A\n",
            "Epoch 1:   5%|▍         | 28/582 [00:35<11:51,  1.28s/it, training_loss=0.432]\u001b[A\n",
            "Epoch 1:   5%|▍         | 28/582 [00:36<11:51,  1.28s/it, training_loss=0.408]\u001b[A\n",
            "Epoch 1:   5%|▍         | 29/582 [00:36<11:49,  1.28s/it, training_loss=0.408]\u001b[A\n",
            "Epoch 1:   5%|▍         | 29/582 [00:38<11:49,  1.28s/it, training_loss=0.436]\u001b[A\n",
            "Epoch 1:   5%|▌         | 30/582 [00:38<11:48,  1.28s/it, training_loss=0.436]\u001b[A\n",
            "Epoch 1:   5%|▌         | 30/582 [00:39<11:48,  1.28s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:   5%|▌         | 31/582 [00:39<11:47,  1.28s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:   5%|▌         | 31/582 [00:40<11:47,  1.28s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 1:   5%|▌         | 32/582 [00:40<11:47,  1.29s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 1:   5%|▌         | 32/582 [00:42<11:47,  1.29s/it, training_loss=0.478]\u001b[A\n",
            "Epoch 1:   6%|▌         | 33/582 [00:42<11:46,  1.29s/it, training_loss=0.478]\u001b[A\n",
            "Epoch 1:   6%|▌         | 33/582 [00:43<11:46,  1.29s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:   6%|▌         | 34/582 [00:43<11:44,  1.29s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:   6%|▌         | 34/582 [00:44<11:44,  1.29s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:   6%|▌         | 35/582 [00:44<11:45,  1.29s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:   6%|▌         | 35/582 [00:46<11:45,  1.29s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:   6%|▌         | 36/582 [00:46<11:46,  1.29s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:   6%|▌         | 36/582 [00:47<11:46,  1.29s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 1:   6%|▋         | 37/582 [00:47<11:45,  1.29s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 1:   6%|▋         | 37/582 [00:48<11:45,  1.29s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:   7%|▋         | 38/582 [00:48<11:44,  1.30s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:   7%|▋         | 38/582 [00:49<11:44,  1.30s/it, training_loss=0.347]\u001b[A\n",
            "Epoch 1:   7%|▋         | 39/582 [00:49<11:43,  1.29s/it, training_loss=0.347]\u001b[A\n",
            "Epoch 1:   7%|▋         | 39/582 [00:51<11:43,  1.29s/it, training_loss=0.430]\u001b[A\n",
            "Epoch 1:   7%|▋         | 40/582 [00:51<11:45,  1.30s/it, training_loss=0.430]\u001b[A\n",
            "Epoch 1:   7%|▋         | 40/582 [00:52<11:45,  1.30s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 1:   7%|▋         | 41/582 [00:52<11:43,  1.30s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 1:   7%|▋         | 41/582 [00:53<11:43,  1.30s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:   7%|▋         | 42/582 [00:53<11:41,  1.30s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:   7%|▋         | 42/582 [00:55<11:41,  1.30s/it, training_loss=0.328]\u001b[A\n",
            "Epoch 1:   7%|▋         | 43/582 [00:55<11:40,  1.30s/it, training_loss=0.328]\u001b[A\n",
            "Epoch 1:   7%|▋         | 43/582 [00:56<11:40,  1.30s/it, training_loss=0.397]\u001b[A\n",
            "Epoch 1:   8%|▊         | 44/582 [00:56<11:41,  1.30s/it, training_loss=0.397]\u001b[A\n",
            "Epoch 1:   8%|▊         | 44/582 [00:57<11:41,  1.30s/it, training_loss=0.349]\u001b[A\n",
            "Epoch 1:   8%|▊         | 45/582 [00:57<11:40,  1.30s/it, training_loss=0.349]\u001b[A\n",
            "Epoch 1:   8%|▊         | 45/582 [00:59<11:40,  1.30s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:   8%|▊         | 46/582 [00:59<11:40,  1.31s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:   8%|▊         | 46/582 [01:00<11:40,  1.31s/it, training_loss=0.397]\u001b[A\n",
            "Epoch 1:   8%|▊         | 47/582 [01:00<11:39,  1.31s/it, training_loss=0.397]\u001b[A\n",
            "Epoch 1:   8%|▊         | 47/582 [01:01<11:39,  1.31s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 1:   8%|▊         | 48/582 [01:01<11:38,  1.31s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 1:   8%|▊         | 48/582 [01:02<11:38,  1.31s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 1:   8%|▊         | 49/582 [01:02<11:36,  1.31s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 1:   8%|▊         | 49/582 [01:04<11:36,  1.31s/it, training_loss=0.465]\u001b[A\n",
            "Epoch 1:   9%|▊         | 50/582 [01:04<11:36,  1.31s/it, training_loss=0.465]\u001b[A\n",
            "Epoch 1:   9%|▊         | 50/582 [01:05<11:36,  1.31s/it, training_loss=0.381]\u001b[A\n",
            "Epoch 1:   9%|▉         | 51/582 [01:05<11:35,  1.31s/it, training_loss=0.381]\u001b[A\n",
            "Epoch 1:   9%|▉         | 51/582 [01:06<11:35,  1.31s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:   9%|▉         | 52/582 [01:06<11:35,  1.31s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:   9%|▉         | 52/582 [01:08<11:35,  1.31s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:   9%|▉         | 53/582 [01:08<11:35,  1.31s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:   9%|▉         | 53/582 [01:09<11:35,  1.31s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:   9%|▉         | 54/582 [01:09<11:34,  1.32s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:   9%|▉         | 54/582 [01:10<11:34,  1.32s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 1:   9%|▉         | 55/582 [01:10<11:34,  1.32s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 1:   9%|▉         | 55/582 [01:12<11:34,  1.32s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  10%|▉         | 56/582 [01:12<11:35,  1.32s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  10%|▉         | 56/582 [01:13<11:35,  1.32s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  10%|▉         | 57/582 [01:13<11:35,  1.32s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  10%|▉         | 57/582 [01:14<11:35,  1.32s/it, training_loss=0.506]\u001b[A\n",
            "Epoch 1:  10%|▉         | 58/582 [01:14<11:33,  1.32s/it, training_loss=0.506]\u001b[A\n",
            "Epoch 1:  10%|▉         | 58/582 [01:16<11:33,  1.32s/it, training_loss=0.363]\u001b[A\n",
            "Epoch 1:  10%|█         | 59/582 [01:16<11:33,  1.33s/it, training_loss=0.363]\u001b[A\n",
            "Epoch 1:  10%|█         | 59/582 [01:17<11:33,  1.33s/it, training_loss=0.407]\u001b[A\n",
            "Epoch 1:  10%|█         | 60/582 [01:17<11:32,  1.33s/it, training_loss=0.407]\u001b[A\n",
            "Epoch 1:  10%|█         | 60/582 [01:18<11:32,  1.33s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  10%|█         | 61/582 [01:18<11:32,  1.33s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  10%|█         | 61/582 [01:20<11:32,  1.33s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  11%|█         | 62/582 [01:20<11:32,  1.33s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  11%|█         | 62/582 [01:21<11:32,  1.33s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  11%|█         | 63/582 [01:21<11:31,  1.33s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  11%|█         | 63/582 [01:22<11:31,  1.33s/it, training_loss=0.371]\u001b[A\n",
            "Epoch 1:  11%|█         | 64/582 [01:22<11:29,  1.33s/it, training_loss=0.371]\u001b[A\n",
            "Epoch 1:  11%|█         | 64/582 [01:24<11:29,  1.33s/it, training_loss=0.436]\u001b[A\n",
            "Epoch 1:  11%|█         | 65/582 [01:24<11:28,  1.33s/it, training_loss=0.436]\u001b[A\n",
            "Epoch 1:  11%|█         | 65/582 [01:25<11:28,  1.33s/it, training_loss=0.435]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 66/582 [01:25<11:27,  1.33s/it, training_loss=0.435]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 66/582 [01:26<11:27,  1.33s/it, training_loss=0.456]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 67/582 [01:26<11:27,  1.34s/it, training_loss=0.456]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 67/582 [01:28<11:27,  1.34s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 68/582 [01:28<11:27,  1.34s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 68/582 [01:29<11:27,  1.34s/it, training_loss=0.377]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 69/582 [01:29<11:27,  1.34s/it, training_loss=0.377]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 69/582 [01:30<11:27,  1.34s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 70/582 [01:30<11:25,  1.34s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 70/582 [01:32<11:25,  1.34s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 71/582 [01:32<11:24,  1.34s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 71/582 [01:33<11:24,  1.34s/it, training_loss=0.398]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 72/582 [01:33<11:26,  1.35s/it, training_loss=0.398]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 72/582 [01:34<11:26,  1.35s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 73/582 [01:34<11:26,  1.35s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 73/582 [01:36<11:26,  1.35s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 74/582 [01:36<11:24,  1.35s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 74/582 [01:37<11:24,  1.35s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 75/582 [01:37<11:22,  1.35s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 75/582 [01:38<11:22,  1.35s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 76/582 [01:39<11:22,  1.35s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 76/582 [01:40<11:22,  1.35s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 77/582 [01:40<11:21,  1.35s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 77/582 [01:41<11:21,  1.35s/it, training_loss=0.421]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 78/582 [01:41<11:18,  1.35s/it, training_loss=0.421]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 78/582 [01:43<11:18,  1.35s/it, training_loss=0.379]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 79/582 [01:43<11:18,  1.35s/it, training_loss=0.379]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 79/582 [01:44<11:18,  1.35s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 80/582 [01:44<11:17,  1.35s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 80/582 [01:45<11:17,  1.35s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 81/582 [01:45<11:15,  1.35s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 81/582 [01:47<11:15,  1.35s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 82/582 [01:47<11:12,  1.35s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 82/582 [01:48<11:12,  1.35s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 83/582 [01:48<11:12,  1.35s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 83/582 [01:49<11:12,  1.35s/it, training_loss=0.407]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 84/582 [01:49<11:11,  1.35s/it, training_loss=0.407]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 84/582 [01:51<11:11,  1.35s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 85/582 [01:51<11:18,  1.37s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 85/582 [01:52<11:18,  1.37s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 86/582 [01:52<11:16,  1.36s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 86/582 [01:53<11:16,  1.36s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 87/582 [01:53<11:12,  1.36s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 87/582 [01:55<11:12,  1.36s/it, training_loss=0.405]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 88/582 [01:55<11:09,  1.36s/it, training_loss=0.405]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 88/582 [01:56<11:09,  1.36s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 89/582 [01:56<11:09,  1.36s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 89/582 [01:57<11:09,  1.36s/it, training_loss=0.390]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 90/582 [01:57<11:08,  1.36s/it, training_loss=0.390]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 90/582 [01:59<11:08,  1.36s/it, training_loss=0.386]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 91/582 [01:59<11:07,  1.36s/it, training_loss=0.386]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 91/582 [02:00<11:07,  1.36s/it, training_loss=0.344]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 92/582 [02:00<11:04,  1.36s/it, training_loss=0.344]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 92/582 [02:02<11:04,  1.36s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 93/582 [02:02<11:03,  1.36s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 93/582 [02:03<11:03,  1.36s/it, training_loss=0.412]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 94/582 [02:03<11:03,  1.36s/it, training_loss=0.412]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 94/582 [02:04<11:03,  1.36s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 95/582 [02:04<11:02,  1.36s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 95/582 [02:06<11:02,  1.36s/it, training_loss=0.359]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 96/582 [02:06<11:02,  1.36s/it, training_loss=0.359]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 96/582 [02:07<11:02,  1.36s/it, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 97/582 [02:07<11:02,  1.37s/it, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 97/582 [02:08<11:02,  1.37s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 98/582 [02:08<11:01,  1.37s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 98/582 [02:10<11:01,  1.37s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 99/582 [02:10<11:00,  1.37s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 99/582 [02:11<11:00,  1.37s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 100/582 [02:11<10:58,  1.37s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 100/582 [02:12<10:58,  1.37s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 101/582 [02:12<10:58,  1.37s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 101/582 [02:14<10:58,  1.37s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 102/582 [02:14<10:56,  1.37s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 102/582 [02:15<10:56,  1.37s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 103/582 [02:15<10:54,  1.37s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 103/582 [02:17<10:54,  1.37s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 104/582 [02:17<10:55,  1.37s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 104/582 [02:18<10:55,  1.37s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 105/582 [02:18<10:54,  1.37s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 105/582 [02:19<10:54,  1.37s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 106/582 [02:19<10:53,  1.37s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 106/582 [02:21<10:53,  1.37s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 107/582 [02:21<10:51,  1.37s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 107/582 [02:22<10:51,  1.37s/it, training_loss=0.389]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 108/582 [02:22<10:50,  1.37s/it, training_loss=0.389]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 108/582 [02:23<10:50,  1.37s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 109/582 [02:23<10:50,  1.38s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 109/582 [02:25<10:50,  1.38s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 110/582 [02:25<10:49,  1.38s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 110/582 [02:26<10:49,  1.38s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 111/582 [02:26<10:49,  1.38s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 111/582 [02:28<10:49,  1.38s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 112/582 [02:28<10:47,  1.38s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 112/582 [02:29<10:47,  1.38s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 113/582 [02:29<10:46,  1.38s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 113/582 [02:30<10:46,  1.38s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 114/582 [02:30<10:45,  1.38s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 114/582 [02:32<10:45,  1.38s/it, training_loss=0.391]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 115/582 [02:32<10:43,  1.38s/it, training_loss=0.391]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 115/582 [02:33<10:43,  1.38s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 116/582 [02:33<10:42,  1.38s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 116/582 [02:35<10:42,  1.38s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  20%|██        | 117/582 [02:35<10:41,  1.38s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  20%|██        | 117/582 [02:36<10:41,  1.38s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  20%|██        | 118/582 [02:36<10:41,  1.38s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  20%|██        | 118/582 [02:37<10:41,  1.38s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  20%|██        | 119/582 [02:37<10:40,  1.38s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  20%|██        | 119/582 [02:39<10:40,  1.38s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  21%|██        | 120/582 [02:39<10:40,  1.39s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  21%|██        | 120/582 [02:40<10:40,  1.39s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  21%|██        | 121/582 [02:40<10:38,  1.39s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  21%|██        | 121/582 [02:41<10:38,  1.39s/it, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  21%|██        | 122/582 [02:41<10:37,  1.39s/it, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  21%|██        | 122/582 [02:43<10:37,  1.39s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  21%|██        | 123/582 [02:43<10:35,  1.38s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  21%|██        | 123/582 [02:44<10:35,  1.38s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 124/582 [02:44<10:34,  1.38s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 124/582 [02:46<10:34,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 125/582 [02:46<10:33,  1.39s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 125/582 [02:47<10:33,  1.39s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 126/582 [02:47<10:32,  1.39s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 126/582 [02:48<10:32,  1.39s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 127/582 [02:48<10:32,  1.39s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 127/582 [02:50<10:32,  1.39s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 128/582 [02:50<10:32,  1.39s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 128/582 [02:51<10:32,  1.39s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 129/582 [02:51<10:31,  1.39s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 129/582 [02:53<10:31,  1.39s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 130/582 [02:53<10:28,  1.39s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 130/582 [02:54<10:28,  1.39s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 131/582 [02:54<10:26,  1.39s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 131/582 [02:55<10:26,  1.39s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 132/582 [02:55<10:25,  1.39s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 132/582 [02:57<10:25,  1.39s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 133/582 [02:57<10:25,  1.39s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 133/582 [02:58<10:25,  1.39s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 134/582 [02:58<10:23,  1.39s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 134/582 [03:00<10:23,  1.39s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 135/582 [03:00<10:20,  1.39s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 135/582 [03:01<10:20,  1.39s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 136/582 [03:01<10:19,  1.39s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 136/582 [03:02<10:19,  1.39s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 137/582 [03:02<10:18,  1.39s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 137/582 [03:04<10:18,  1.39s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 138/582 [03:04<10:17,  1.39s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 138/582 [03:05<10:17,  1.39s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 139/582 [03:05<10:15,  1.39s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 139/582 [03:06<10:15,  1.39s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 140/582 [03:06<10:13,  1.39s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 140/582 [03:08<10:13,  1.39s/it, training_loss=0.433]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 141/582 [03:08<10:11,  1.39s/it, training_loss=0.433]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 141/582 [03:09<10:11,  1.39s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 142/582 [03:09<10:10,  1.39s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 142/582 [03:11<10:10,  1.39s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 143/582 [03:11<10:09,  1.39s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 143/582 [03:12<10:09,  1.39s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 144/582 [03:12<10:08,  1.39s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 144/582 [03:13<10:08,  1.39s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 145/582 [03:13<10:09,  1.39s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 145/582 [03:15<10:09,  1.39s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 146/582 [03:15<10:07,  1.39s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 146/582 [03:16<10:07,  1.39s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 147/582 [03:16<10:05,  1.39s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 147/582 [03:18<10:05,  1.39s/it, training_loss=0.349]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 148/582 [03:18<10:03,  1.39s/it, training_loss=0.349]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 148/582 [03:19<10:03,  1.39s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 149/582 [03:19<10:00,  1.39s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 149/582 [03:20<10:00,  1.39s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 150/582 [03:20<09:59,  1.39s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 150/582 [03:22<09:59,  1.39s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 151/582 [03:22<09:58,  1.39s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 151/582 [03:23<09:58,  1.39s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 152/582 [03:23<09:56,  1.39s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 152/582 [03:25<09:56,  1.39s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 153/582 [03:25<09:53,  1.38s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 153/582 [03:26<09:53,  1.38s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 154/582 [03:26<09:52,  1.38s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 154/582 [03:27<09:52,  1.38s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 155/582 [03:27<09:50,  1.38s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 155/582 [03:29<09:50,  1.38s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 156/582 [03:29<09:48,  1.38s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 156/582 [03:30<09:48,  1.38s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 157/582 [03:30<09:46,  1.38s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 157/582 [03:31<09:46,  1.38s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 158/582 [03:31<09:45,  1.38s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 158/582 [03:33<09:45,  1.38s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 159/582 [03:33<09:44,  1.38s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 159/582 [03:34<09:44,  1.38s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 160/582 [03:34<09:42,  1.38s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 160/582 [03:36<09:42,  1.38s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 161/582 [03:36<09:41,  1.38s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 161/582 [03:37<09:41,  1.38s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 162/582 [03:37<09:39,  1.38s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 162/582 [03:38<09:39,  1.38s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 163/582 [03:38<09:38,  1.38s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 163/582 [03:40<09:38,  1.38s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 164/582 [03:40<09:37,  1.38s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 164/582 [03:41<09:37,  1.38s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 165/582 [03:41<09:37,  1.38s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 165/582 [03:42<09:37,  1.38s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 166/582 [03:42<09:34,  1.38s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 166/582 [03:44<09:34,  1.38s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 167/582 [03:44<09:33,  1.38s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 167/582 [03:45<09:33,  1.38s/it, training_loss=0.378]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 168/582 [03:45<09:32,  1.38s/it, training_loss=0.378]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 168/582 [03:47<09:32,  1.38s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 169/582 [03:47<09:30,  1.38s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 169/582 [03:48<09:30,  1.38s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 170/582 [03:48<09:28,  1.38s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 170/582 [03:49<09:28,  1.38s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 171/582 [03:49<09:27,  1.38s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 171/582 [03:51<09:27,  1.38s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 172/582 [03:51<09:26,  1.38s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 172/582 [03:52<09:26,  1.38s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 173/582 [03:52<09:24,  1.38s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 173/582 [03:53<09:24,  1.38s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 174/582 [03:54<09:22,  1.38s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 174/582 [03:55<09:22,  1.38s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  30%|███       | 175/582 [03:55<09:21,  1.38s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  30%|███       | 175/582 [03:56<09:21,  1.38s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  30%|███       | 176/582 [03:56<09:20,  1.38s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  30%|███       | 176/582 [03:58<09:20,  1.38s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  30%|███       | 177/582 [03:58<09:18,  1.38s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  30%|███       | 177/582 [03:59<09:18,  1.38s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  31%|███       | 178/582 [03:59<09:18,  1.38s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  31%|███       | 178/582 [04:00<09:18,  1.38s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  31%|███       | 179/582 [04:00<09:15,  1.38s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  31%|███       | 179/582 [04:02<09:15,  1.38s/it, training_loss=0.373]\u001b[A\n",
            "Epoch 1:  31%|███       | 180/582 [04:02<09:14,  1.38s/it, training_loss=0.373]\u001b[A\n",
            "Epoch 1:  31%|███       | 180/582 [04:03<09:14,  1.38s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  31%|███       | 181/582 [04:03<09:12,  1.38s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  31%|███       | 181/582 [04:05<09:12,  1.38s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 182/582 [04:05<09:11,  1.38s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 182/582 [04:06<09:11,  1.38s/it, training_loss=0.391]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 183/582 [04:06<09:10,  1.38s/it, training_loss=0.391]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 183/582 [04:07<09:10,  1.38s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 184/582 [04:07<09:10,  1.38s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 184/582 [04:09<09:10,  1.38s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 185/582 [04:09<09:10,  1.39s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 185/582 [04:10<09:10,  1.39s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 186/582 [04:10<09:07,  1.38s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 186/582 [04:11<09:07,  1.38s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 187/582 [04:11<09:06,  1.38s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 187/582 [04:13<09:06,  1.38s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 188/582 [04:13<09:04,  1.38s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 188/582 [04:14<09:04,  1.38s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 189/582 [04:14<09:03,  1.38s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 189/582 [04:16<09:03,  1.38s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 190/582 [04:16<09:01,  1.38s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 190/582 [04:17<09:01,  1.38s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 191/582 [04:17<08:59,  1.38s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 191/582 [04:18<08:59,  1.38s/it, training_loss=0.397]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 192/582 [04:18<08:58,  1.38s/it, training_loss=0.397]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 192/582 [04:20<08:58,  1.38s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 193/582 [04:20<08:56,  1.38s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 193/582 [04:21<08:56,  1.38s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 194/582 [04:21<08:55,  1.38s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 194/582 [04:22<08:55,  1.38s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 195/582 [04:23<08:52,  1.38s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 195/582 [04:24<08:52,  1.38s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 196/582 [04:24<08:51,  1.38s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 196/582 [04:25<08:51,  1.38s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 197/582 [04:25<08:51,  1.38s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 197/582 [04:27<08:51,  1.38s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 198/582 [04:27<08:50,  1.38s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 198/582 [04:28<08:50,  1.38s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 199/582 [04:28<08:49,  1.38s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 199/582 [04:29<08:49,  1.38s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 200/582 [04:29<08:48,  1.38s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 200/582 [04:31<08:48,  1.38s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 201/582 [04:31<08:46,  1.38s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 201/582 [04:32<08:46,  1.38s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 202/582 [04:32<08:45,  1.38s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 202/582 [04:34<08:45,  1.38s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 203/582 [04:34<08:43,  1.38s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 203/582 [04:35<08:43,  1.38s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 204/582 [04:35<08:41,  1.38s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 204/582 [04:36<08:41,  1.38s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 205/582 [04:36<08:40,  1.38s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 205/582 [04:38<08:40,  1.38s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 206/582 [04:38<08:38,  1.38s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 206/582 [04:39<08:38,  1.38s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 207/582 [04:39<08:36,  1.38s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 207/582 [04:40<08:36,  1.38s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 208/582 [04:40<08:36,  1.38s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 208/582 [04:42<08:36,  1.38s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 209/582 [04:42<08:34,  1.38s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 209/582 [04:43<08:34,  1.38s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 210/582 [04:43<08:33,  1.38s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 210/582 [04:45<08:33,  1.38s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 211/582 [04:45<08:33,  1.38s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 211/582 [04:46<08:33,  1.38s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 212/582 [04:46<08:33,  1.39s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 212/582 [04:47<08:33,  1.39s/it, training_loss=0.427]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 213/582 [04:47<08:31,  1.39s/it, training_loss=0.427]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 213/582 [04:49<08:31,  1.39s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 214/582 [04:49<08:29,  1.39s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 214/582 [04:50<08:29,  1.39s/it, training_loss=0.367]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 215/582 [04:50<08:28,  1.39s/it, training_loss=0.367]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 215/582 [04:52<08:28,  1.39s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 216/582 [04:52<08:25,  1.38s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 216/582 [04:53<08:25,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 217/582 [04:53<08:24,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 217/582 [04:54<08:24,  1.38s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 218/582 [04:54<08:22,  1.38s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 218/582 [04:56<08:22,  1.38s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 219/582 [04:56<08:21,  1.38s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 219/582 [04:57<08:21,  1.38s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 220/582 [04:57<08:20,  1.38s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 220/582 [04:58<08:20,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 221/582 [04:58<08:19,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 221/582 [05:00<08:19,  1.38s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 222/582 [05:00<08:16,  1.38s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 222/582 [05:01<08:16,  1.38s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 223/582 [05:01<08:15,  1.38s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 223/582 [05:03<08:15,  1.38s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 224/582 [05:03<08:13,  1.38s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 224/582 [05:04<08:13,  1.38s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 225/582 [05:04<08:12,  1.38s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 225/582 [05:05<08:12,  1.38s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 226/582 [05:05<08:11,  1.38s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 226/582 [05:07<08:11,  1.38s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 227/582 [05:07<08:10,  1.38s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 227/582 [05:08<08:10,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 228/582 [05:08<08:09,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 228/582 [05:09<08:09,  1.38s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 229/582 [05:09<08:06,  1.38s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 229/582 [05:11<08:06,  1.38s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 230/582 [05:11<08:05,  1.38s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 230/582 [05:12<08:05,  1.38s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 231/582 [05:12<08:04,  1.38s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 231/582 [05:14<08:04,  1.38s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 232/582 [05:14<08:03,  1.38s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 232/582 [05:15<08:03,  1.38s/it, training_loss=0.367]\u001b[A\n",
            "Epoch 1:  40%|████      | 233/582 [05:15<08:02,  1.38s/it, training_loss=0.367]\u001b[A\n",
            "Epoch 1:  40%|████      | 233/582 [05:16<08:02,  1.38s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  40%|████      | 234/582 [05:16<08:00,  1.38s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  40%|████      | 234/582 [05:18<08:00,  1.38s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  40%|████      | 235/582 [05:18<07:59,  1.38s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  40%|████      | 235/582 [05:19<07:59,  1.38s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  41%|████      | 236/582 [05:19<07:58,  1.38s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  41%|████      | 236/582 [05:21<07:58,  1.38s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  41%|████      | 237/582 [05:21<07:56,  1.38s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  41%|████      | 237/582 [05:22<07:56,  1.38s/it, training_loss=0.379]\u001b[A\n",
            "Epoch 1:  41%|████      | 238/582 [05:22<07:54,  1.38s/it, training_loss=0.379]\u001b[A\n",
            "Epoch 1:  41%|████      | 238/582 [05:23<07:54,  1.38s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  41%|████      | 239/582 [05:23<07:53,  1.38s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  41%|████      | 239/582 [05:25<07:53,  1.38s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  41%|████      | 240/582 [05:25<07:51,  1.38s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  41%|████      | 240/582 [05:26<07:51,  1.38s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 241/582 [05:26<07:50,  1.38s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 241/582 [05:27<07:50,  1.38s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 242/582 [05:27<07:48,  1.38s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 242/582 [05:29<07:48,  1.38s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 243/582 [05:29<07:47,  1.38s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 243/582 [05:30<07:47,  1.38s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 244/582 [05:30<07:45,  1.38s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 244/582 [05:32<07:45,  1.38s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 245/582 [05:32<07:44,  1.38s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 245/582 [05:33<07:44,  1.38s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 246/582 [05:33<07:43,  1.38s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 246/582 [05:34<07:43,  1.38s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 247/582 [05:34<07:41,  1.38s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 247/582 [05:36<07:41,  1.38s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 248/582 [05:36<07:41,  1.38s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 248/582 [05:37<07:41,  1.38s/it, training_loss=0.349]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 249/582 [05:37<07:41,  1.39s/it, training_loss=0.349]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 249/582 [05:38<07:41,  1.39s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 250/582 [05:38<07:39,  1.38s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 250/582 [05:40<07:39,  1.38s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 251/582 [05:40<07:37,  1.38s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 251/582 [05:41<07:37,  1.38s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 252/582 [05:41<07:34,  1.38s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 252/582 [05:43<07:34,  1.38s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 253/582 [05:43<07:33,  1.38s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 253/582 [05:44<07:33,  1.38s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 254/582 [05:44<07:32,  1.38s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 254/582 [05:45<07:32,  1.38s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 255/582 [05:45<07:31,  1.38s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 255/582 [05:47<07:31,  1.38s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 256/582 [05:47<07:30,  1.38s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 256/582 [05:48<07:30,  1.38s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 257/582 [05:48<07:28,  1.38s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 257/582 [05:50<07:28,  1.38s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 258/582 [05:50<07:26,  1.38s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 258/582 [05:51<07:26,  1.38s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 259/582 [05:51<07:26,  1.38s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 259/582 [05:52<07:26,  1.38s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 260/582 [05:52<07:25,  1.38s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 260/582 [05:54<07:25,  1.38s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 261/582 [05:54<07:23,  1.38s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 261/582 [05:55<07:23,  1.38s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 262/582 [05:55<07:21,  1.38s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 262/582 [05:56<07:21,  1.38s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 263/582 [05:56<07:19,  1.38s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 263/582 [05:58<07:19,  1.38s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 264/582 [05:58<07:18,  1.38s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 264/582 [05:59<07:18,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 265/582 [05:59<07:18,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 265/582 [06:01<07:18,  1.38s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 266/582 [06:01<07:15,  1.38s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 266/582 [06:02<07:15,  1.38s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 267/582 [06:02<07:14,  1.38s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 267/582 [06:03<07:14,  1.38s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 268/582 [06:03<07:13,  1.38s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 268/582 [06:05<07:13,  1.38s/it, training_loss=0.369]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 269/582 [06:05<07:12,  1.38s/it, training_loss=0.369]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 269/582 [06:06<07:12,  1.38s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 270/582 [06:06<07:10,  1.38s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 270/582 [06:07<07:10,  1.38s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 271/582 [06:07<07:08,  1.38s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 271/582 [06:09<07:08,  1.38s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 272/582 [06:09<07:07,  1.38s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 272/582 [06:10<07:07,  1.38s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 273/582 [06:10<07:07,  1.38s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 273/582 [06:12<07:07,  1.38s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 274/582 [06:12<07:06,  1.38s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 274/582 [06:13<07:06,  1.38s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 275/582 [06:13<07:05,  1.38s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 275/582 [06:14<07:05,  1.38s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 276/582 [06:14<07:03,  1.38s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 276/582 [06:16<07:03,  1.38s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 277/582 [06:16<07:00,  1.38s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 277/582 [06:17<07:00,  1.38s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 278/582 [06:17<06:59,  1.38s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 278/582 [06:19<06:59,  1.38s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 279/582 [06:19<06:58,  1.38s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 279/582 [06:20<06:58,  1.38s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 280/582 [06:20<06:56,  1.38s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 280/582 [06:21<06:56,  1.38s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 281/582 [06:21<06:55,  1.38s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 281/582 [06:23<06:55,  1.38s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 282/582 [06:23<06:53,  1.38s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 282/582 [06:24<06:53,  1.38s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 283/582 [06:24<06:53,  1.38s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 283/582 [06:25<06:53,  1.38s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 284/582 [06:25<06:51,  1.38s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 284/582 [06:27<06:51,  1.38s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 285/582 [06:27<06:50,  1.38s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 285/582 [06:28<06:50,  1.38s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 286/582 [06:28<06:49,  1.38s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 286/582 [06:30<06:49,  1.38s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 287/582 [06:30<06:49,  1.39s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 287/582 [06:31<06:49,  1.39s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 288/582 [06:31<06:47,  1.39s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 288/582 [06:32<06:47,  1.39s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 289/582 [06:32<06:45,  1.38s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 289/582 [06:34<06:45,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 290/582 [06:34<06:43,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 290/582 [06:35<06:43,  1.38s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  50%|█████     | 291/582 [06:35<06:42,  1.38s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  50%|█████     | 291/582 [06:36<06:42,  1.38s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  50%|█████     | 292/582 [06:36<06:40,  1.38s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  50%|█████     | 292/582 [06:38<06:40,  1.38s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 1:  50%|█████     | 293/582 [06:38<06:39,  1.38s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 1:  50%|█████     | 293/582 [06:39<06:39,  1.38s/it, training_loss=0.415]\u001b[A\n",
            "Epoch 1:  51%|█████     | 294/582 [06:39<06:38,  1.38s/it, training_loss=0.415]\u001b[A\n",
            "Epoch 1:  51%|█████     | 294/582 [06:41<06:38,  1.38s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  51%|█████     | 295/582 [06:41<06:37,  1.39s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  51%|█████     | 295/582 [06:42<06:37,  1.39s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  51%|█████     | 296/582 [06:42<06:35,  1.38s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  51%|█████     | 296/582 [06:43<06:35,  1.38s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  51%|█████     | 297/582 [06:43<06:34,  1.38s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  51%|█████     | 297/582 [06:45<06:34,  1.38s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  51%|█████     | 298/582 [06:45<06:33,  1.38s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  51%|█████     | 298/582 [06:46<06:33,  1.38s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 299/582 [06:46<06:31,  1.39s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 299/582 [06:48<06:31,  1.39s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 300/582 [06:48<06:31,  1.39s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 300/582 [06:49<06:31,  1.39s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 301/582 [06:49<06:29,  1.39s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 301/582 [06:50<06:29,  1.39s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 302/582 [06:50<06:28,  1.39s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 302/582 [06:52<06:28,  1.39s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 303/582 [06:52<06:27,  1.39s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 303/582 [06:53<06:27,  1.39s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 304/582 [06:53<06:25,  1.39s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 304/582 [06:54<06:25,  1.39s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 305/582 [06:54<06:23,  1.39s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 305/582 [06:56<06:23,  1.39s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 306/582 [06:56<06:21,  1.38s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 306/582 [06:57<06:21,  1.38s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 307/582 [06:57<06:20,  1.38s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 307/582 [06:59<06:20,  1.38s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 308/582 [06:59<06:18,  1.38s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 308/582 [07:00<06:18,  1.38s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 309/582 [07:00<06:16,  1.38s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 309/582 [07:01<06:16,  1.38s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 310/582 [07:01<06:15,  1.38s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 310/582 [07:03<06:15,  1.38s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 311/582 [07:03<06:14,  1.38s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 311/582 [07:04<06:14,  1.38s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 312/582 [07:04<06:13,  1.38s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 312/582 [07:06<06:13,  1.38s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 313/582 [07:06<06:12,  1.39s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 313/582 [07:07<06:12,  1.39s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 314/582 [07:07<06:10,  1.38s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 314/582 [07:08<06:10,  1.38s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 315/582 [07:08<06:08,  1.38s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 315/582 [07:10<06:08,  1.38s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 316/582 [07:10<06:07,  1.38s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 316/582 [07:11<06:07,  1.38s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 317/582 [07:11<06:06,  1.38s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 317/582 [07:12<06:06,  1.38s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 318/582 [07:12<06:04,  1.38s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 318/582 [07:14<06:04,  1.38s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 319/582 [07:14<06:02,  1.38s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 319/582 [07:15<06:02,  1.38s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 320/582 [07:15<06:01,  1.38s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 320/582 [07:17<06:01,  1.38s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 321/582 [07:17<06:00,  1.38s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 321/582 [07:18<06:00,  1.38s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 322/582 [07:18<05:59,  1.38s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 322/582 [07:19<05:59,  1.38s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 323/582 [07:19<05:59,  1.39s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 323/582 [07:21<05:59,  1.39s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 324/582 [07:21<05:57,  1.39s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 324/582 [07:22<05:57,  1.39s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 325/582 [07:22<05:56,  1.39s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 325/582 [07:24<05:56,  1.39s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 326/582 [07:24<05:54,  1.39s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 326/582 [07:25<05:54,  1.39s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 327/582 [07:25<05:52,  1.38s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 327/582 [07:26<05:52,  1.38s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 328/582 [07:26<05:51,  1.39s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 328/582 [07:28<05:51,  1.39s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 329/582 [07:28<05:50,  1.39s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 329/582 [07:29<05:50,  1.39s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 330/582 [07:29<05:48,  1.38s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 330/582 [07:30<05:48,  1.38s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 331/582 [07:30<05:47,  1.39s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 331/582 [07:32<05:47,  1.39s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 332/582 [07:32<05:46,  1.39s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 332/582 [07:33<05:46,  1.39s/it, training_loss=0.328]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 333/582 [07:33<05:46,  1.39s/it, training_loss=0.328]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 333/582 [07:35<05:46,  1.39s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 334/582 [07:35<05:44,  1.39s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 334/582 [07:36<05:44,  1.39s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 335/582 [07:36<05:43,  1.39s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 335/582 [07:37<05:43,  1.39s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 336/582 [07:37<05:41,  1.39s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 336/582 [07:39<05:41,  1.39s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 337/582 [07:39<05:39,  1.39s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 337/582 [07:40<05:39,  1.39s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 338/582 [07:40<05:37,  1.39s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 338/582 [07:42<05:37,  1.39s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 339/582 [07:42<05:36,  1.38s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 339/582 [07:43<05:36,  1.38s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 340/582 [07:43<05:34,  1.38s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 340/582 [07:44<05:34,  1.38s/it, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 341/582 [07:44<05:33,  1.38s/it, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 341/582 [07:46<05:33,  1.38s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 342/582 [07:46<05:31,  1.38s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 342/582 [07:47<05:31,  1.38s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 343/582 [07:47<05:29,  1.38s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 343/582 [07:48<05:29,  1.38s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 344/582 [07:48<05:28,  1.38s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 344/582 [07:50<05:28,  1.38s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 345/582 [07:50<05:27,  1.38s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 345/582 [07:51<05:27,  1.38s/it, training_loss=0.373]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 346/582 [07:51<05:26,  1.38s/it, training_loss=0.373]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 346/582 [07:53<05:26,  1.38s/it, training_loss=0.373]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 347/582 [07:53<05:24,  1.38s/it, training_loss=0.373]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 347/582 [07:54<05:24,  1.38s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 348/582 [07:54<05:23,  1.38s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 348/582 [07:55<05:23,  1.38s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 349/582 [07:55<05:22,  1.38s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 349/582 [07:57<05:22,  1.38s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  60%|██████    | 350/582 [07:57<05:21,  1.39s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  60%|██████    | 350/582 [07:58<05:21,  1.39s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  60%|██████    | 351/582 [07:58<05:20,  1.39s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  60%|██████    | 351/582 [08:00<05:20,  1.39s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  60%|██████    | 352/582 [08:00<05:19,  1.39s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  60%|██████    | 352/582 [08:01<05:19,  1.39s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  61%|██████    | 353/582 [08:01<05:17,  1.39s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  61%|██████    | 353/582 [08:02<05:17,  1.39s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  61%|██████    | 354/582 [08:02<05:16,  1.39s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  61%|██████    | 354/582 [08:04<05:16,  1.39s/it, training_loss=0.448]\u001b[A\n",
            "Epoch 1:  61%|██████    | 355/582 [08:04<05:15,  1.39s/it, training_loss=0.448]\u001b[A\n",
            "Epoch 1:  61%|██████    | 355/582 [08:05<05:15,  1.39s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  61%|██████    | 356/582 [08:05<05:13,  1.39s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  61%|██████    | 356/582 [08:06<05:13,  1.39s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 357/582 [08:06<05:12,  1.39s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 357/582 [08:08<05:12,  1.39s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 358/582 [08:08<05:10,  1.39s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 358/582 [08:09<05:10,  1.39s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 359/582 [08:09<05:09,  1.39s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 359/582 [08:11<05:09,  1.39s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 360/582 [08:11<05:07,  1.39s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 360/582 [08:12<05:07,  1.39s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 361/582 [08:12<05:06,  1.39s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 361/582 [08:13<05:06,  1.39s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 362/582 [08:13<05:04,  1.38s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 362/582 [08:15<05:04,  1.38s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 363/582 [08:15<05:02,  1.38s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 363/582 [08:16<05:02,  1.38s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 364/582 [08:16<05:01,  1.38s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 364/582 [08:18<05:01,  1.38s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 365/582 [08:18<05:00,  1.38s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 365/582 [08:19<05:00,  1.38s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 366/582 [08:19<04:59,  1.39s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 366/582 [08:20<04:59,  1.39s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 367/582 [08:20<04:58,  1.39s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 367/582 [08:22<04:58,  1.39s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 368/582 [08:22<04:57,  1.39s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 368/582 [08:23<04:57,  1.39s/it, training_loss=0.368]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 369/582 [08:23<04:55,  1.39s/it, training_loss=0.368]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 369/582 [08:24<04:55,  1.39s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 370/582 [08:25<04:53,  1.39s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 370/582 [08:26<04:53,  1.39s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 371/582 [08:26<04:51,  1.38s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 371/582 [08:27<04:51,  1.38s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 372/582 [08:27<04:50,  1.38s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 372/582 [08:29<04:50,  1.38s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 373/582 [08:29<04:48,  1.38s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 373/582 [08:30<04:48,  1.38s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 374/582 [08:30<04:48,  1.39s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 374/582 [08:31<04:48,  1.39s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 375/582 [08:31<04:46,  1.38s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 375/582 [08:33<04:46,  1.38s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 376/582 [08:33<04:44,  1.38s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 376/582 [08:34<04:44,  1.38s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 377/582 [08:34<04:44,  1.39s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 377/582 [08:36<04:44,  1.39s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 378/582 [08:36<04:42,  1.39s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 378/582 [08:37<04:42,  1.39s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 379/582 [08:37<04:41,  1.38s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 379/582 [08:38<04:41,  1.38s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 380/582 [08:38<04:39,  1.39s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 380/582 [08:40<04:39,  1.39s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 381/582 [08:40<04:38,  1.39s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 381/582 [08:41<04:38,  1.39s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 382/582 [08:41<04:36,  1.38s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 382/582 [08:42<04:36,  1.38s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 383/582 [08:42<04:35,  1.38s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 383/582 [08:44<04:35,  1.38s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 384/582 [08:44<04:33,  1.38s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 384/582 [08:45<04:33,  1.38s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 385/582 [08:45<04:32,  1.38s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 385/582 [08:47<04:32,  1.38s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 386/582 [08:47<04:31,  1.38s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 386/582 [08:48<04:31,  1.38s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 387/582 [08:48<04:30,  1.38s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 387/582 [08:49<04:30,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 388/582 [08:49<04:28,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 388/582 [08:51<04:28,  1.38s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 389/582 [08:51<04:26,  1.38s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 389/582 [08:52<04:26,  1.38s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 390/582 [08:52<04:25,  1.38s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 390/582 [08:54<04:25,  1.38s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 391/582 [08:54<04:23,  1.38s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 391/582 [08:55<04:23,  1.38s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 392/582 [08:55<04:22,  1.38s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 392/582 [08:56<04:22,  1.38s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 393/582 [08:56<04:20,  1.38s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 393/582 [08:58<04:20,  1.38s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 394/582 [08:58<04:20,  1.38s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 394/582 [08:59<04:20,  1.38s/it, training_loss=0.364]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 395/582 [08:59<04:18,  1.38s/it, training_loss=0.364]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 395/582 [09:00<04:18,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 396/582 [09:00<04:17,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 396/582 [09:02<04:17,  1.38s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 397/582 [09:02<04:15,  1.38s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 397/582 [09:03<04:15,  1.38s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 398/582 [09:03<04:14,  1.38s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 398/582 [09:05<04:14,  1.38s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 399/582 [09:05<04:12,  1.38s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 399/582 [09:06<04:12,  1.38s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 400/582 [09:06<04:11,  1.38s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 400/582 [09:07<04:11,  1.38s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 401/582 [09:07<04:09,  1.38s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 401/582 [09:09<04:09,  1.38s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 402/582 [09:09<04:08,  1.38s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 402/582 [09:10<04:08,  1.38s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 403/582 [09:10<04:07,  1.38s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 403/582 [09:12<04:07,  1.38s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 404/582 [09:12<04:06,  1.38s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 404/582 [09:13<04:06,  1.38s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 405/582 [09:13<04:04,  1.38s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 405/582 [09:14<04:04,  1.38s/it, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 406/582 [09:14<04:03,  1.38s/it, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 406/582 [09:16<04:03,  1.38s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 407/582 [09:16<04:01,  1.38s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 407/582 [09:17<04:01,  1.38s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  70%|███████   | 408/582 [09:17<03:59,  1.38s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  70%|███████   | 408/582 [09:18<03:59,  1.38s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  70%|███████   | 409/582 [09:18<03:58,  1.38s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  70%|███████   | 409/582 [09:20<03:58,  1.38s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  70%|███████   | 410/582 [09:20<03:57,  1.38s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  70%|███████   | 410/582 [09:21<03:57,  1.38s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  71%|███████   | 411/582 [09:21<03:56,  1.38s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  71%|███████   | 411/582 [09:23<03:56,  1.38s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  71%|███████   | 412/582 [09:23<03:54,  1.38s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  71%|███████   | 412/582 [09:24<03:54,  1.38s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  71%|███████   | 413/582 [09:24<03:52,  1.38s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  71%|███████   | 413/582 [09:25<03:52,  1.38s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  71%|███████   | 414/582 [09:25<03:51,  1.38s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  71%|███████   | 414/582 [09:27<03:51,  1.38s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 415/582 [09:27<03:50,  1.38s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 415/582 [09:28<03:50,  1.38s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 416/582 [09:28<03:48,  1.38s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 416/582 [09:29<03:48,  1.38s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 417/582 [09:29<03:47,  1.38s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 417/582 [09:31<03:47,  1.38s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 418/582 [09:31<03:46,  1.38s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 418/582 [09:32<03:46,  1.38s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 419/582 [09:32<03:45,  1.38s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 419/582 [09:34<03:45,  1.38s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 420/582 [09:34<03:43,  1.38s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 420/582 [09:35<03:43,  1.38s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 421/582 [09:35<03:42,  1.38s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 421/582 [09:36<03:42,  1.38s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 422/582 [09:36<03:40,  1.38s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 422/582 [09:38<03:40,  1.38s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 423/582 [09:38<03:39,  1.38s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 423/582 [09:39<03:39,  1.38s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 424/582 [09:39<03:37,  1.38s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 424/582 [09:40<03:37,  1.38s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 425/582 [09:41<03:36,  1.38s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 425/582 [09:42<03:36,  1.38s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 426/582 [09:42<03:35,  1.38s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 426/582 [09:43<03:35,  1.38s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 427/582 [09:43<03:34,  1.38s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 427/582 [09:45<03:34,  1.38s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 428/582 [09:45<03:33,  1.38s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 428/582 [09:46<03:33,  1.38s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 429/582 [09:46<03:31,  1.39s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 429/582 [09:47<03:31,  1.39s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 430/582 [09:47<03:30,  1.39s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 430/582 [09:49<03:30,  1.39s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 431/582 [09:49<03:28,  1.38s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 431/582 [09:50<03:28,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 432/582 [09:50<03:27,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 432/582 [09:52<03:27,  1.38s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 433/582 [09:52<03:25,  1.38s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 433/582 [09:53<03:25,  1.38s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 434/582 [09:53<03:24,  1.38s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 434/582 [09:54<03:24,  1.38s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 435/582 [09:54<03:23,  1.39s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 435/582 [09:56<03:23,  1.39s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 436/582 [09:56<03:22,  1.39s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 436/582 [09:57<03:22,  1.39s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 437/582 [09:57<03:20,  1.38s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 437/582 [09:58<03:20,  1.38s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 438/582 [09:58<03:19,  1.38s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 438/582 [10:00<03:19,  1.38s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 439/582 [10:00<03:17,  1.38s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 439/582 [10:01<03:17,  1.38s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 440/582 [10:01<03:16,  1.38s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 440/582 [10:03<03:16,  1.38s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 441/582 [10:03<03:14,  1.38s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 441/582 [10:04<03:14,  1.38s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 442/582 [10:04<03:13,  1.38s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 442/582 [10:05<03:13,  1.38s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 443/582 [10:05<03:11,  1.38s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 443/582 [10:07<03:11,  1.38s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 444/582 [10:07<03:10,  1.38s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 444/582 [10:08<03:10,  1.38s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 445/582 [10:08<03:09,  1.38s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 445/582 [10:10<03:09,  1.38s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 446/582 [10:10<03:08,  1.38s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 446/582 [10:11<03:08,  1.38s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 447/582 [10:11<03:06,  1.38s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 447/582 [10:12<03:06,  1.38s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 448/582 [10:12<03:05,  1.38s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 448/582 [10:14<03:05,  1.38s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 449/582 [10:14<03:03,  1.38s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 449/582 [10:15<03:03,  1.38s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 450/582 [10:15<03:02,  1.38s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 450/582 [10:16<03:02,  1.38s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 451/582 [10:16<03:01,  1.38s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 451/582 [10:18<03:01,  1.38s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 452/582 [10:18<02:59,  1.38s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 452/582 [10:19<02:59,  1.38s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 453/582 [10:19<02:58,  1.39s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 453/582 [10:21<02:58,  1.39s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 454/582 [10:21<02:57,  1.38s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 454/582 [10:22<02:57,  1.38s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 455/582 [10:22<02:55,  1.38s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 455/582 [10:23<02:55,  1.38s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 456/582 [10:23<02:54,  1.39s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 456/582 [10:25<02:54,  1.39s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 457/582 [10:25<02:53,  1.39s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 457/582 [10:26<02:53,  1.39s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 458/582 [10:26<02:52,  1.39s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 458/582 [10:28<02:52,  1.39s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 459/582 [10:28<02:50,  1.39s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 459/582 [10:29<02:50,  1.39s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 460/582 [10:29<02:48,  1.38s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 460/582 [10:30<02:48,  1.38s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 461/582 [10:30<02:47,  1.38s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 461/582 [10:32<02:47,  1.38s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 462/582 [10:32<02:45,  1.38s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 462/582 [10:33<02:45,  1.38s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 463/582 [10:33<02:44,  1.38s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 463/582 [10:34<02:44,  1.38s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 464/582 [10:34<02:43,  1.38s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 464/582 [10:36<02:43,  1.38s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 465/582 [10:36<02:41,  1.38s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 465/582 [10:37<02:41,  1.38s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  80%|████████  | 466/582 [10:37<02:40,  1.39s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  80%|████████  | 466/582 [10:39<02:40,  1.39s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  80%|████████  | 467/582 [10:39<02:39,  1.39s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  80%|████████  | 467/582 [10:40<02:39,  1.39s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  80%|████████  | 468/582 [10:40<02:38,  1.39s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  80%|████████  | 468/582 [10:41<02:38,  1.39s/it, training_loss=0.318]\u001b[A\n",
            "Epoch 1:  81%|████████  | 469/582 [10:41<02:36,  1.39s/it, training_loss=0.318]\u001b[A\n",
            "Epoch 1:  81%|████████  | 469/582 [10:43<02:36,  1.39s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  81%|████████  | 470/582 [10:43<02:35,  1.39s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  81%|████████  | 470/582 [10:44<02:35,  1.39s/it, training_loss=0.408]\u001b[A\n",
            "Epoch 1:  81%|████████  | 471/582 [10:44<02:33,  1.39s/it, training_loss=0.408]\u001b[A\n",
            "Epoch 1:  81%|████████  | 471/582 [10:46<02:33,  1.39s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  81%|████████  | 472/582 [10:46<02:32,  1.38s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  81%|████████  | 472/582 [10:47<02:32,  1.38s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 473/582 [10:47<02:30,  1.38s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 473/582 [10:48<02:30,  1.38s/it, training_loss=0.365]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 474/582 [10:48<02:29,  1.38s/it, training_loss=0.365]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 474/582 [10:50<02:29,  1.38s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 475/582 [10:50<02:27,  1.38s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 475/582 [10:51<02:27,  1.38s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 476/582 [10:51<02:26,  1.38s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 476/582 [10:52<02:26,  1.38s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 477/582 [10:52<02:25,  1.39s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 477/582 [10:54<02:25,  1.39s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 478/582 [10:54<02:24,  1.39s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 478/582 [10:55<02:24,  1.39s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 479/582 [10:55<02:22,  1.39s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 479/582 [10:57<02:22,  1.39s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 480/582 [10:57<02:21,  1.39s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 480/582 [10:58<02:21,  1.39s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 481/582 [10:58<02:20,  1.39s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 481/582 [10:59<02:20,  1.39s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 482/582 [10:59<02:18,  1.38s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 482/582 [11:01<02:18,  1.38s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 483/582 [11:01<02:17,  1.38s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 483/582 [11:02<02:17,  1.38s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 484/582 [11:02<02:15,  1.39s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 484/582 [11:04<02:15,  1.39s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 485/582 [11:04<02:14,  1.38s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 485/582 [11:05<02:14,  1.38s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 486/582 [11:05<02:12,  1.38s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 486/582 [11:06<02:12,  1.38s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 487/582 [11:06<02:11,  1.38s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 487/582 [11:08<02:11,  1.38s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 488/582 [11:08<02:10,  1.38s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 488/582 [11:09<02:10,  1.38s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 489/582 [11:09<02:09,  1.39s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 489/582 [11:10<02:09,  1.39s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 490/582 [11:10<02:07,  1.39s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 490/582 [11:12<02:07,  1.39s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 491/582 [11:12<02:06,  1.39s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 491/582 [11:13<02:06,  1.39s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 492/582 [11:13<02:04,  1.38s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 492/582 [11:15<02:04,  1.38s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 493/582 [11:15<02:03,  1.39s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 493/582 [11:16<02:03,  1.39s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 494/582 [11:16<02:02,  1.39s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 494/582 [11:17<02:02,  1.39s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 495/582 [11:17<02:00,  1.39s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 495/582 [11:19<02:00,  1.39s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 496/582 [11:19<01:58,  1.38s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 496/582 [11:20<01:58,  1.38s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 497/582 [11:20<01:57,  1.38s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 497/582 [11:22<01:57,  1.38s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 498/582 [11:22<01:56,  1.38s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 498/582 [11:23<01:56,  1.38s/it, training_loss=0.371]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 499/582 [11:23<01:54,  1.38s/it, training_loss=0.371]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 499/582 [11:24<01:54,  1.38s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 500/582 [11:24<01:53,  1.38s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 500/582 [11:26<01:53,  1.38s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 501/582 [11:26<01:51,  1.38s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 501/582 [11:27<01:51,  1.38s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 502/582 [11:27<01:50,  1.38s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 502/582 [11:28<01:50,  1.38s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 503/582 [11:28<01:49,  1.38s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 503/582 [11:30<01:49,  1.38s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 504/582 [11:30<01:47,  1.38s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 504/582 [11:31<01:47,  1.38s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 505/582 [11:31<01:46,  1.38s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 505/582 [11:33<01:46,  1.38s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 506/582 [11:33<01:44,  1.38s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 506/582 [11:34<01:44,  1.38s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 507/582 [11:34<01:43,  1.38s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 507/582 [11:35<01:43,  1.38s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 508/582 [11:35<01:42,  1.38s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 508/582 [11:37<01:42,  1.38s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 509/582 [11:37<01:41,  1.39s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 509/582 [11:38<01:41,  1.39s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 510/582 [11:38<01:39,  1.38s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 510/582 [11:40<01:39,  1.38s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 511/582 [11:40<01:38,  1.38s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 511/582 [11:41<01:38,  1.38s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 512/582 [11:41<01:36,  1.39s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 512/582 [11:42<01:36,  1.39s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 513/582 [11:42<01:35,  1.39s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 513/582 [11:44<01:35,  1.39s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 514/582 [11:44<01:34,  1.38s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 514/582 [11:45<01:34,  1.38s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 515/582 [11:45<01:32,  1.39s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 515/582 [11:46<01:32,  1.39s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 516/582 [11:46<01:31,  1.39s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 516/582 [11:48<01:31,  1.39s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 517/582 [11:48<01:30,  1.39s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 517/582 [11:49<01:30,  1.39s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 518/582 [11:49<01:28,  1.39s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 518/582 [11:51<01:28,  1.39s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 519/582 [11:51<01:27,  1.39s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 519/582 [11:52<01:27,  1.39s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 520/582 [11:52<01:25,  1.39s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 520/582 [11:53<01:25,  1.39s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 521/582 [11:53<01:24,  1.39s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 521/582 [11:55<01:24,  1.39s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 522/582 [11:55<01:23,  1.39s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 522/582 [11:56<01:23,  1.39s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 523/582 [11:56<01:21,  1.39s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 523/582 [11:58<01:21,  1.39s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 524/582 [11:58<01:20,  1.39s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 524/582 [11:59<01:20,  1.39s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 525/582 [11:59<01:19,  1.39s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 525/582 [12:00<01:19,  1.39s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 526/582 [12:00<01:17,  1.39s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 526/582 [12:02<01:17,  1.39s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 527/582 [12:02<01:16,  1.38s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 527/582 [12:03<01:16,  1.38s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 528/582 [12:03<01:14,  1.38s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 528/582 [12:04<01:14,  1.38s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 529/582 [12:04<01:13,  1.38s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 529/582 [12:06<01:13,  1.38s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 530/582 [12:06<01:11,  1.38s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 530/582 [12:07<01:11,  1.38s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 531/582 [12:07<01:10,  1.38s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 531/582 [12:09<01:10,  1.38s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 532/582 [12:09<01:08,  1.38s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 532/582 [12:10<01:08,  1.38s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 533/582 [12:10<01:07,  1.38s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 533/582 [12:11<01:07,  1.38s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 534/582 [12:11<01:06,  1.38s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 534/582 [12:13<01:06,  1.38s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 535/582 [12:13<01:05,  1.38s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 535/582 [12:14<01:05,  1.38s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 536/582 [12:14<01:03,  1.38s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 536/582 [12:16<01:03,  1.38s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 537/582 [12:16<01:02,  1.38s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 537/582 [12:17<01:02,  1.38s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 538/582 [12:17<01:00,  1.38s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 538/582 [12:18<01:00,  1.38s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 539/582 [12:18<00:59,  1.38s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 539/582 [12:20<00:59,  1.38s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 540/582 [12:20<00:58,  1.38s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 540/582 [12:21<00:58,  1.38s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 541/582 [12:21<00:56,  1.39s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 541/582 [12:22<00:56,  1.39s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 542/582 [12:22<00:55,  1.39s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 542/582 [12:24<00:55,  1.39s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 543/582 [12:24<00:54,  1.39s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 543/582 [12:25<00:54,  1.39s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 544/582 [12:25<00:52,  1.39s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 544/582 [12:27<00:52,  1.39s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 545/582 [12:27<00:51,  1.39s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 545/582 [12:28<00:51,  1.39s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 546/582 [12:28<00:49,  1.39s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 546/582 [12:29<00:49,  1.39s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 547/582 [12:29<00:48,  1.39s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 547/582 [12:31<00:48,  1.39s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 548/582 [12:31<00:47,  1.39s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 548/582 [12:32<00:47,  1.39s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 549/582 [12:32<00:45,  1.39s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 549/582 [12:34<00:45,  1.39s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 550/582 [12:34<00:44,  1.39s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 550/582 [12:35<00:44,  1.39s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 551/582 [12:35<00:42,  1.39s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 551/582 [12:36<00:42,  1.39s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 552/582 [12:36<00:41,  1.38s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 552/582 [12:38<00:41,  1.38s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 553/582 [12:38<00:40,  1.38s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 553/582 [12:39<00:40,  1.38s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 554/582 [12:39<00:38,  1.38s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 554/582 [12:41<00:38,  1.38s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 555/582 [12:41<00:37,  1.38s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 555/582 [12:42<00:37,  1.38s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 556/582 [12:42<00:35,  1.38s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 556/582 [12:43<00:35,  1.38s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 557/582 [12:43<00:34,  1.38s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 557/582 [12:45<00:34,  1.38s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 558/582 [12:45<00:33,  1.39s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 558/582 [12:46<00:33,  1.39s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 559/582 [12:46<00:31,  1.39s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 559/582 [12:47<00:31,  1.39s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 560/582 [12:47<00:30,  1.39s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 560/582 [12:49<00:30,  1.39s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 561/582 [12:49<00:29,  1.39s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 561/582 [12:50<00:29,  1.39s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 562/582 [12:50<00:27,  1.39s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 562/582 [12:52<00:27,  1.39s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 563/582 [12:52<00:26,  1.39s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 563/582 [12:53<00:26,  1.39s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 564/582 [12:53<00:24,  1.39s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 564/582 [12:54<00:24,  1.39s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 565/582 [12:54<00:23,  1.39s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 565/582 [12:56<00:23,  1.39s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 566/582 [12:56<00:22,  1.39s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 566/582 [12:57<00:22,  1.39s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 567/582 [12:57<00:20,  1.39s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 567/582 [12:59<00:20,  1.39s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 568/582 [12:59<00:19,  1.38s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 568/582 [13:00<00:19,  1.38s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 569/582 [13:00<00:17,  1.38s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 569/582 [13:01<00:17,  1.38s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 570/582 [13:01<00:16,  1.38s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 570/582 [13:03<00:16,  1.38s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 571/582 [13:03<00:15,  1.38s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 571/582 [13:04<00:15,  1.38s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 572/582 [13:04<00:13,  1.38s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 572/582 [13:05<00:13,  1.38s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 573/582 [13:05<00:12,  1.38s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 573/582 [13:07<00:12,  1.38s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 574/582 [13:07<00:11,  1.38s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 574/582 [13:08<00:11,  1.38s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 575/582 [13:08<00:09,  1.38s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 575/582 [13:10<00:09,  1.38s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 576/582 [13:10<00:08,  1.38s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 576/582 [13:11<00:08,  1.38s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 577/582 [13:11<00:06,  1.38s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 577/582 [13:12<00:06,  1.38s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 578/582 [13:12<00:05,  1.38s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 578/582 [13:14<00:05,  1.38s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 579/582 [13:14<00:04,  1.38s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 579/582 [13:15<00:04,  1.38s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 580/582 [13:15<00:02,  1.38s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 580/582 [13:17<00:02,  1.38s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 581/582 [13:17<00:01,  1.38s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 581/582 [13:17<00:01,  1.38s/it, training_loss=0.317]\u001b[A\n",
            "Epoch 1: 100%|██████████| 582/582 [13:17<00:00,  1.23s/it, training_loss=0.317]\u001b[A\n",
            "  0%|          | 0/3 [13:24<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training loss: 0.7972609580484862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 1/3 [15:02<30:04, 902.32s/it]\n",
            "Epoch 2:   0%|          | 0/582 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.6589933294303638\n",
            "F1 Score (Weighted): 0.7698438166093962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2:   0%|          | 0/582 [00:01<?, ?it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:   0%|          | 1/582 [00:01<13:12,  1.36s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:   0%|          | 1/582 [00:02<13:12,  1.36s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:   0%|          | 2/582 [00:02<13:14,  1.37s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:   0%|          | 2/582 [00:04<13:14,  1.37s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 2:   1%|          | 3/582 [00:04<13:15,  1.37s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 2:   1%|          | 3/582 [00:05<13:15,  1.37s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:   1%|          | 4/582 [00:05<13:15,  1.38s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:   1%|          | 4/582 [00:06<13:15,  1.38s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:   1%|          | 5/582 [00:06<13:16,  1.38s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:   1%|          | 5/582 [00:08<13:16,  1.38s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 2:   1%|          | 6/582 [00:08<13:16,  1.38s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 2:   1%|          | 6/582 [00:09<13:16,  1.38s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:   1%|          | 7/582 [00:09<13:15,  1.38s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:   1%|          | 7/582 [00:11<13:15,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:   1%|▏         | 8/582 [00:11<13:11,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:   1%|▏         | 8/582 [00:12<13:11,  1.38s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:   2%|▏         | 9/582 [00:12<13:10,  1.38s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:   2%|▏         | 9/582 [00:13<13:10,  1.38s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:   2%|▏         | 10/582 [00:13<13:09,  1.38s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:   2%|▏         | 10/582 [00:15<13:09,  1.38s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:   2%|▏         | 11/582 [00:15<13:08,  1.38s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:   2%|▏         | 11/582 [00:16<13:08,  1.38s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:   2%|▏         | 12/582 [00:16<13:11,  1.39s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:   2%|▏         | 12/582 [00:17<13:11,  1.39s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:   2%|▏         | 13/582 [00:17<13:09,  1.39s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:   2%|▏         | 13/582 [00:19<13:09,  1.39s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:   2%|▏         | 14/582 [00:19<13:05,  1.38s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:   2%|▏         | 14/582 [00:20<13:05,  1.38s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 2:   3%|▎         | 15/582 [00:20<13:05,  1.39s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 2:   3%|▎         | 15/582 [00:22<13:05,  1.39s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 2:   3%|▎         | 16/582 [00:22<13:05,  1.39s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 2:   3%|▎         | 16/582 [00:23<13:05,  1.39s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:   3%|▎         | 17/582 [00:23<13:03,  1.39s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:   3%|▎         | 17/582 [00:24<13:03,  1.39s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:   3%|▎         | 18/582 [00:24<13:00,  1.38s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:   3%|▎         | 18/582 [00:26<13:00,  1.38s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 2:   3%|▎         | 19/582 [00:26<12:59,  1.38s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 2:   3%|▎         | 19/582 [00:27<12:59,  1.38s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 2:   3%|▎         | 20/582 [00:27<12:58,  1.39s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 2:   3%|▎         | 20/582 [00:29<12:58,  1.39s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 2:   4%|▎         | 21/582 [00:29<12:57,  1.39s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 2:   4%|▎         | 21/582 [00:30<12:57,  1.39s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:   4%|▍         | 22/582 [00:30<12:53,  1.38s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:   4%|▍         | 22/582 [00:31<12:53,  1.38s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 2:   4%|▍         | 23/582 [00:31<12:53,  1.38s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 2:   4%|▍         | 23/582 [00:33<12:53,  1.38s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:   4%|▍         | 24/582 [00:33<12:52,  1.38s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:   4%|▍         | 24/582 [00:34<12:52,  1.38s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:   4%|▍         | 25/582 [00:34<12:51,  1.39s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:   4%|▍         | 25/582 [00:35<12:51,  1.39s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:   4%|▍         | 26/582 [00:35<12:50,  1.39s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:   4%|▍         | 26/582 [00:37<12:50,  1.39s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:   5%|▍         | 27/582 [00:37<12:49,  1.39s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:   5%|▍         | 27/582 [00:38<12:49,  1.39s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 2:   5%|▍         | 28/582 [00:38<12:48,  1.39s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 2:   5%|▍         | 28/582 [00:40<12:48,  1.39s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:   5%|▍         | 29/582 [00:40<12:47,  1.39s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:   5%|▍         | 29/582 [00:41<12:47,  1.39s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:   5%|▌         | 30/582 [00:41<12:44,  1.38s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:   5%|▌         | 30/582 [00:42<12:44,  1.38s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:   5%|▌         | 31/582 [00:42<12:43,  1.39s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:   5%|▌         | 31/582 [00:44<12:43,  1.39s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:   5%|▌         | 32/582 [00:44<12:43,  1.39s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:   5%|▌         | 32/582 [00:45<12:43,  1.39s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:   6%|▌         | 33/582 [00:45<12:42,  1.39s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:   6%|▌         | 33/582 [00:47<12:42,  1.39s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:   6%|▌         | 34/582 [00:47<12:41,  1.39s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:   6%|▌         | 34/582 [00:48<12:41,  1.39s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:   6%|▌         | 35/582 [00:48<12:37,  1.38s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:   6%|▌         | 35/582 [00:49<12:37,  1.38s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:   6%|▌         | 36/582 [00:49<12:36,  1.39s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:   6%|▌         | 36/582 [00:51<12:36,  1.39s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:   6%|▋         | 37/582 [00:51<12:34,  1.38s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:   6%|▋         | 37/582 [00:52<12:34,  1.38s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 2:   7%|▋         | 38/582 [00:52<12:32,  1.38s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 2:   7%|▋         | 38/582 [00:53<12:32,  1.38s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:   7%|▋         | 39/582 [00:54<12:32,  1.39s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:   7%|▋         | 39/582 [00:55<12:32,  1.39s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:   7%|▋         | 40/582 [00:55<12:31,  1.39s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:   7%|▋         | 40/582 [00:56<12:31,  1.39s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 2:   7%|▋         | 41/582 [00:56<12:30,  1.39s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 2:   7%|▋         | 41/582 [00:58<12:30,  1.39s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:   7%|▋         | 42/582 [00:58<12:29,  1.39s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:   7%|▋         | 42/582 [00:59<12:29,  1.39s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:   7%|▋         | 43/582 [00:59<12:28,  1.39s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:   7%|▋         | 43/582 [01:00<12:28,  1.39s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:   8%|▊         | 44/582 [01:00<12:27,  1.39s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:   8%|▊         | 44/582 [01:02<12:27,  1.39s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:   8%|▊         | 45/582 [01:02<12:26,  1.39s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:   8%|▊         | 45/582 [01:03<12:26,  1.39s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 2:   8%|▊         | 46/582 [01:03<12:24,  1.39s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 2:   8%|▊         | 46/582 [01:05<12:24,  1.39s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:   8%|▊         | 47/582 [01:05<12:23,  1.39s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:   8%|▊         | 47/582 [01:06<12:23,  1.39s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 2:   8%|▊         | 48/582 [01:06<12:20,  1.39s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 2:   8%|▊         | 48/582 [01:07<12:20,  1.39s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 2:   8%|▊         | 49/582 [01:07<12:20,  1.39s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 2:   8%|▊         | 49/582 [01:09<12:20,  1.39s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:   9%|▊         | 50/582 [01:09<12:19,  1.39s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:   9%|▊         | 50/582 [01:10<12:19,  1.39s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 2:   9%|▉         | 51/582 [01:10<12:17,  1.39s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 2:   9%|▉         | 51/582 [01:12<12:17,  1.39s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:   9%|▉         | 52/582 [01:12<12:15,  1.39s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:   9%|▉         | 52/582 [01:13<12:15,  1.39s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:   9%|▉         | 53/582 [01:13<12:14,  1.39s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:   9%|▉         | 53/582 [01:14<12:14,  1.39s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:   9%|▉         | 54/582 [01:14<12:12,  1.39s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:   9%|▉         | 54/582 [01:16<12:12,  1.39s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 2:   9%|▉         | 55/582 [01:16<12:12,  1.39s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 2:   9%|▉         | 55/582 [01:17<12:12,  1.39s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 2:  10%|▉         | 56/582 [01:17<12:07,  1.38s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 2:  10%|▉         | 56/582 [01:18<12:07,  1.38s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 2:  10%|▉         | 57/582 [01:18<12:08,  1.39s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 2:  10%|▉         | 57/582 [01:20<12:08,  1.39s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  10%|▉         | 58/582 [01:20<12:08,  1.39s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  10%|▉         | 58/582 [01:21<12:08,  1.39s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  10%|█         | 59/582 [01:21<12:07,  1.39s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  10%|█         | 59/582 [01:23<12:07,  1.39s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  10%|█         | 60/582 [01:23<12:04,  1.39s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  10%|█         | 60/582 [01:24<12:04,  1.39s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  10%|█         | 61/582 [01:24<12:03,  1.39s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  10%|█         | 61/582 [01:25<12:03,  1.39s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  11%|█         | 62/582 [01:25<12:01,  1.39s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  11%|█         | 62/582 [01:27<12:01,  1.39s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  11%|█         | 63/582 [01:27<11:59,  1.39s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  11%|█         | 63/582 [01:28<11:59,  1.39s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  11%|█         | 64/582 [01:28<11:56,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  11%|█         | 64/582 [01:30<11:56,  1.38s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  11%|█         | 65/582 [01:30<11:55,  1.38s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  11%|█         | 65/582 [01:31<11:55,  1.38s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 66/582 [01:31<11:54,  1.38s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 66/582 [01:32<11:54,  1.38s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 67/582 [01:32<11:53,  1.38s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 67/582 [01:34<11:53,  1.38s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 68/582 [01:34<11:50,  1.38s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 68/582 [01:35<11:50,  1.38s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 69/582 [01:35<11:49,  1.38s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 69/582 [01:36<11:49,  1.38s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 70/582 [01:36<11:47,  1.38s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 70/582 [01:38<11:47,  1.38s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 71/582 [01:38<11:46,  1.38s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 71/582 [01:39<11:46,  1.38s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 72/582 [01:39<11:45,  1.38s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 72/582 [01:41<11:45,  1.38s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 73/582 [01:41<11:41,  1.38s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 73/582 [01:42<11:41,  1.38s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 74/582 [01:42<11:41,  1.38s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 74/582 [01:43<11:41,  1.38s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 75/582 [01:43<11:41,  1.38s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 75/582 [01:45<11:41,  1.38s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 76/582 [01:45<11:42,  1.39s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 76/582 [01:46<11:42,  1.39s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 77/582 [01:46<11:42,  1.39s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 77/582 [01:48<11:42,  1.39s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 78/582 [01:48<11:41,  1.39s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 78/582 [01:49<11:41,  1.39s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 79/582 [01:49<11:38,  1.39s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 79/582 [01:50<11:38,  1.39s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 80/582 [01:50<11:36,  1.39s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 80/582 [01:52<11:36,  1.39s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 81/582 [01:52<11:35,  1.39s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 81/582 [01:53<11:35,  1.39s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 82/582 [01:53<11:33,  1.39s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 82/582 [01:55<11:33,  1.39s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 83/582 [01:55<11:31,  1.39s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 83/582 [01:56<11:31,  1.39s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 84/582 [01:56<11:30,  1.39s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 84/582 [01:57<11:30,  1.39s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 85/582 [01:57<11:29,  1.39s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 85/582 [01:59<11:29,  1.39s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 86/582 [01:59<11:28,  1.39s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 86/582 [02:00<11:28,  1.39s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 87/582 [02:00<11:26,  1.39s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 87/582 [02:01<11:26,  1.39s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 88/582 [02:01<11:25,  1.39s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 88/582 [02:03<11:25,  1.39s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 89/582 [02:03<11:26,  1.39s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 89/582 [02:04<11:26,  1.39s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 90/582 [02:04<11:26,  1.40s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 90/582 [02:06<11:26,  1.40s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 91/582 [02:06<11:26,  1.40s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 91/582 [02:07<11:26,  1.40s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 92/582 [02:07<11:22,  1.39s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 92/582 [02:08<11:22,  1.39s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 93/582 [02:08<11:19,  1.39s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 93/582 [02:10<11:19,  1.39s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 94/582 [02:10<11:17,  1.39s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 94/582 [02:11<11:17,  1.39s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 95/582 [02:11<11:16,  1.39s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 95/582 [02:13<11:16,  1.39s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 96/582 [02:13<11:13,  1.39s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 96/582 [02:14<11:13,  1.39s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 97/582 [02:14<11:13,  1.39s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 97/582 [02:15<11:13,  1.39s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 98/582 [02:15<11:12,  1.39s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 98/582 [02:17<11:12,  1.39s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 99/582 [02:17<11:12,  1.39s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 99/582 [02:18<11:12,  1.39s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 100/582 [02:18<11:10,  1.39s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 100/582 [02:20<11:10,  1.39s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 101/582 [02:20<11:08,  1.39s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 101/582 [02:21<11:08,  1.39s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 102/582 [02:21<11:07,  1.39s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 102/582 [02:22<11:07,  1.39s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 103/582 [02:22<11:04,  1.39s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 103/582 [02:24<11:04,  1.39s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 104/582 [02:24<11:02,  1.39s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 104/582 [02:25<11:02,  1.39s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 105/582 [02:25<11:03,  1.39s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 105/582 [02:27<11:03,  1.39s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 106/582 [02:27<11:02,  1.39s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 106/582 [02:28<11:02,  1.39s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 107/582 [02:28<11:00,  1.39s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 107/582 [02:29<11:00,  1.39s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 108/582 [02:29<10:58,  1.39s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 108/582 [02:31<10:58,  1.39s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 109/582 [02:31<10:55,  1.39s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 109/582 [02:32<10:55,  1.39s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 110/582 [02:32<10:54,  1.39s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 110/582 [02:33<10:54,  1.39s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 111/582 [02:33<10:54,  1.39s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 111/582 [02:35<10:54,  1.39s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 112/582 [02:35<10:53,  1.39s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 112/582 [02:36<10:53,  1.39s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 113/582 [02:36<10:51,  1.39s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 113/582 [02:38<10:51,  1.39s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 114/582 [02:38<10:49,  1.39s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 114/582 [02:39<10:49,  1.39s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 115/582 [02:39<10:48,  1.39s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 115/582 [02:40<10:48,  1.39s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 116/582 [02:40<10:46,  1.39s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 116/582 [02:42<10:46,  1.39s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  20%|██        | 117/582 [02:42<10:45,  1.39s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  20%|██        | 117/582 [02:43<10:45,  1.39s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  20%|██        | 118/582 [02:43<10:43,  1.39s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  20%|██        | 118/582 [02:45<10:43,  1.39s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  20%|██        | 119/582 [02:45<10:41,  1.39s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  20%|██        | 119/582 [02:46<10:41,  1.39s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  21%|██        | 120/582 [02:46<10:39,  1.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  21%|██        | 120/582 [02:47<10:39,  1.38s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  21%|██        | 121/582 [02:47<10:37,  1.38s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  21%|██        | 121/582 [02:49<10:37,  1.38s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  21%|██        | 122/582 [02:49<10:37,  1.39s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  21%|██        | 122/582 [02:50<10:37,  1.39s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 2:  21%|██        | 123/582 [02:50<10:37,  1.39s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 2:  21%|██        | 123/582 [02:51<10:37,  1.39s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 124/582 [02:51<10:35,  1.39s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 124/582 [02:53<10:35,  1.39s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 125/582 [02:53<10:33,  1.39s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 125/582 [02:54<10:33,  1.39s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 126/582 [02:54<10:34,  1.39s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 126/582 [02:56<10:34,  1.39s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 127/582 [02:56<10:34,  1.39s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 127/582 [02:57<10:34,  1.39s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 128/582 [02:57<10:31,  1.39s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 128/582 [02:58<10:31,  1.39s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 129/582 [02:58<10:29,  1.39s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 129/582 [03:00<10:29,  1.39s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 130/582 [03:00<10:27,  1.39s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 130/582 [03:01<10:27,  1.39s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 131/582 [03:01<10:24,  1.39s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 131/582 [03:03<10:24,  1.39s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 132/582 [03:03<10:24,  1.39s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 132/582 [03:04<10:24,  1.39s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 133/582 [03:04<10:23,  1.39s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 133/582 [03:05<10:23,  1.39s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 134/582 [03:05<10:21,  1.39s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 134/582 [03:07<10:21,  1.39s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 135/582 [03:07<10:20,  1.39s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 135/582 [03:08<10:20,  1.39s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 136/582 [03:08<10:20,  1.39s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 136/582 [03:10<10:20,  1.39s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 137/582 [03:10<10:17,  1.39s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 137/582 [03:11<10:17,  1.39s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 138/582 [03:11<10:15,  1.39s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 138/582 [03:12<10:15,  1.39s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 139/582 [03:12<10:15,  1.39s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 139/582 [03:14<10:15,  1.39s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 140/582 [03:14<10:12,  1.39s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 140/582 [03:15<10:12,  1.39s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 141/582 [03:15<10:11,  1.39s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 141/582 [03:16<10:11,  1.39s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 142/582 [03:16<10:10,  1.39s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 142/582 [03:18<10:10,  1.39s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 143/582 [03:18<10:08,  1.39s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 143/582 [03:19<10:08,  1.39s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 144/582 [03:19<10:05,  1.38s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 144/582 [03:21<10:05,  1.38s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 145/582 [03:21<10:04,  1.38s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 145/582 [03:22<10:04,  1.38s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 146/582 [03:22<10:04,  1.39s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 146/582 [03:23<10:04,  1.39s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 147/582 [03:23<10:02,  1.39s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 147/582 [03:25<10:02,  1.39s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 148/582 [03:25<10:02,  1.39s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 148/582 [03:26<10:02,  1.39s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 149/582 [03:26<10:00,  1.39s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 149/582 [03:28<10:00,  1.39s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 150/582 [03:28<09:59,  1.39s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 150/582 [03:29<09:59,  1.39s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 151/582 [03:29<09:58,  1.39s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 151/582 [03:30<09:58,  1.39s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 152/582 [03:30<09:56,  1.39s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 152/582 [03:32<09:56,  1.39s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 153/582 [03:32<09:54,  1.39s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 153/582 [03:33<09:54,  1.39s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 154/582 [03:33<09:51,  1.38s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 154/582 [03:34<09:51,  1.38s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 155/582 [03:34<09:51,  1.38s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 155/582 [03:36<09:51,  1.38s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 156/582 [03:36<09:49,  1.38s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 156/582 [03:37<09:49,  1.38s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 157/582 [03:37<09:49,  1.39s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 157/582 [03:39<09:49,  1.39s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 158/582 [03:39<09:47,  1.39s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 158/582 [03:40<09:47,  1.39s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 159/582 [03:40<09:47,  1.39s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 159/582 [03:41<09:47,  1.39s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 160/582 [03:41<09:45,  1.39s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 160/582 [03:43<09:45,  1.39s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 161/582 [03:43<09:42,  1.38s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 161/582 [03:44<09:42,  1.38s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 162/582 [03:44<09:41,  1.39s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 162/582 [03:46<09:41,  1.39s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 163/582 [03:46<09:40,  1.39s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 163/582 [03:47<09:40,  1.39s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 164/582 [03:47<09:39,  1.39s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 164/582 [03:48<09:39,  1.39s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 165/582 [03:48<09:38,  1.39s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 165/582 [03:50<09:38,  1.39s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 166/582 [03:50<09:36,  1.39s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 166/582 [03:51<09:36,  1.39s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 167/582 [03:51<09:34,  1.38s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 167/582 [03:52<09:34,  1.38s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 168/582 [03:52<09:32,  1.38s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 168/582 [03:54<09:32,  1.38s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 169/582 [03:54<09:31,  1.38s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 169/582 [03:55<09:31,  1.38s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 170/582 [03:55<09:30,  1.38s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 170/582 [03:57<09:30,  1.38s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 171/582 [03:57<09:28,  1.38s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 171/582 [03:58<09:28,  1.38s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 172/582 [03:58<09:27,  1.38s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 172/582 [03:59<09:27,  1.38s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 173/582 [03:59<09:24,  1.38s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 173/582 [04:01<09:24,  1.38s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 174/582 [04:01<09:22,  1.38s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 174/582 [04:02<09:22,  1.38s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  30%|███       | 175/582 [04:02<09:21,  1.38s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  30%|███       | 175/582 [04:04<09:21,  1.38s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  30%|███       | 176/582 [04:04<09:20,  1.38s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  30%|███       | 176/582 [04:05<09:20,  1.38s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 2:  30%|███       | 177/582 [04:05<09:18,  1.38s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 2:  30%|███       | 177/582 [04:06<09:18,  1.38s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  31%|███       | 178/582 [04:06<09:17,  1.38s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  31%|███       | 178/582 [04:08<09:17,  1.38s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  31%|███       | 179/582 [04:08<09:16,  1.38s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  31%|███       | 179/582 [04:09<09:16,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  31%|███       | 180/582 [04:09<09:15,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  31%|███       | 180/582 [04:10<09:15,  1.38s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  31%|███       | 181/582 [04:10<09:14,  1.38s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  31%|███       | 181/582 [04:12<09:14,  1.38s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 182/582 [04:12<09:14,  1.39s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 182/582 [04:13<09:14,  1.39s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 183/582 [04:13<09:13,  1.39s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 183/582 [04:15<09:13,  1.39s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 184/582 [04:15<09:12,  1.39s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 184/582 [04:16<09:12,  1.39s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 185/582 [04:16<09:11,  1.39s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 185/582 [04:17<09:11,  1.39s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 186/582 [04:17<09:10,  1.39s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 186/582 [04:19<09:10,  1.39s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 187/582 [04:19<09:08,  1.39s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 187/582 [04:20<09:08,  1.39s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 188/582 [04:20<09:07,  1.39s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 188/582 [04:22<09:07,  1.39s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 189/582 [04:22<09:04,  1.39s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 189/582 [04:23<09:04,  1.39s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 190/582 [04:23<09:03,  1.39s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 190/582 [04:24<09:03,  1.39s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 191/582 [04:24<09:02,  1.39s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 191/582 [04:26<09:02,  1.39s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 192/582 [04:26<08:59,  1.38s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 192/582 [04:27<08:59,  1.38s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 193/582 [04:27<08:57,  1.38s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 193/582 [04:28<08:57,  1.38s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 194/582 [04:28<08:55,  1.38s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 194/582 [04:30<08:55,  1.38s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 195/582 [04:30<08:53,  1.38s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 195/582 [04:31<08:53,  1.38s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 196/582 [04:31<08:52,  1.38s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 196/582 [04:33<08:52,  1.38s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 197/582 [04:33<08:50,  1.38s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 197/582 [04:34<08:50,  1.38s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 198/582 [04:34<08:50,  1.38s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 198/582 [04:35<08:50,  1.38s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 199/582 [04:35<08:48,  1.38s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 199/582 [04:37<08:48,  1.38s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 200/582 [04:37<08:46,  1.38s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 200/582 [04:38<08:46,  1.38s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 201/582 [04:38<08:45,  1.38s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 201/582 [04:39<08:45,  1.38s/it, training_loss=0.383]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 202/582 [04:39<08:44,  1.38s/it, training_loss=0.383]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 202/582 [04:41<08:44,  1.38s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 203/582 [04:41<08:46,  1.39s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 203/582 [04:42<08:46,  1.39s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 204/582 [04:42<08:46,  1.39s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 204/582 [04:44<08:46,  1.39s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 205/582 [04:44<08:43,  1.39s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 205/582 [04:45<08:43,  1.39s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 206/582 [04:45<08:41,  1.39s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 206/582 [04:46<08:41,  1.39s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 207/582 [04:46<08:40,  1.39s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 207/582 [04:48<08:40,  1.39s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 208/582 [04:48<08:38,  1.39s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 208/582 [04:49<08:38,  1.39s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 209/582 [04:49<08:37,  1.39s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 209/582 [04:51<08:37,  1.39s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 210/582 [04:51<08:36,  1.39s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 210/582 [04:52<08:36,  1.39s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 211/582 [04:52<08:34,  1.39s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 211/582 [04:53<08:34,  1.39s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 212/582 [04:53<08:34,  1.39s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 212/582 [04:55<08:34,  1.39s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 213/582 [04:55<08:32,  1.39s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 213/582 [04:56<08:32,  1.39s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 214/582 [04:56<08:30,  1.39s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 214/582 [04:58<08:30,  1.39s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 215/582 [04:58<08:27,  1.38s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 215/582 [04:59<08:27,  1.38s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 216/582 [04:59<08:26,  1.38s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 216/582 [05:00<08:26,  1.38s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 217/582 [05:00<08:25,  1.38s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 217/582 [05:02<08:25,  1.38s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 218/582 [05:02<08:23,  1.38s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 218/582 [05:03<08:23,  1.38s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 219/582 [05:03<08:23,  1.39s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 219/582 [05:04<08:23,  1.39s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 220/582 [05:04<08:22,  1.39s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 220/582 [05:06<08:22,  1.39s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 221/582 [05:06<08:22,  1.39s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 221/582 [05:07<08:22,  1.39s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 222/582 [05:07<08:19,  1.39s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 222/582 [05:09<08:19,  1.39s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 223/582 [05:09<08:17,  1.39s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 223/582 [05:10<08:17,  1.39s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 224/582 [05:10<08:15,  1.38s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 224/582 [05:11<08:15,  1.38s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 225/582 [05:11<08:14,  1.39s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 225/582 [05:13<08:14,  1.39s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 226/582 [05:13<08:13,  1.39s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 226/582 [05:14<08:13,  1.39s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 227/582 [05:14<08:13,  1.39s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 227/582 [05:16<08:13,  1.39s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 228/582 [05:16<08:12,  1.39s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 228/582 [05:17<08:12,  1.39s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 229/582 [05:17<08:10,  1.39s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 229/582 [05:18<08:10,  1.39s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 230/582 [05:18<08:08,  1.39s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 230/582 [05:20<08:08,  1.39s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 231/582 [05:20<08:07,  1.39s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 231/582 [05:21<08:07,  1.39s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 232/582 [05:21<08:05,  1.39s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 232/582 [05:23<08:05,  1.39s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  40%|████      | 233/582 [05:23<08:03,  1.38s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  40%|████      | 233/582 [05:24<08:03,  1.38s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  40%|████      | 234/582 [05:24<08:01,  1.38s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  40%|████      | 234/582 [05:25<08:01,  1.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  40%|████      | 235/582 [05:25<07:59,  1.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  40%|████      | 235/582 [05:27<07:59,  1.38s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  41%|████      | 236/582 [05:27<07:59,  1.39s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  41%|████      | 236/582 [05:28<07:59,  1.39s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  41%|████      | 237/582 [05:28<07:58,  1.39s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  41%|████      | 237/582 [05:29<07:58,  1.39s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  41%|████      | 238/582 [05:29<07:57,  1.39s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  41%|████      | 238/582 [05:31<07:57,  1.39s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  41%|████      | 239/582 [05:31<07:55,  1.39s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  41%|████      | 239/582 [05:32<07:55,  1.39s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  41%|████      | 240/582 [05:32<07:53,  1.38s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  41%|████      | 240/582 [05:34<07:53,  1.38s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 241/582 [05:34<07:51,  1.38s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 241/582 [05:35<07:51,  1.38s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 242/582 [05:35<07:50,  1.38s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 242/582 [05:36<07:50,  1.38s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 243/582 [05:36<07:47,  1.38s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 243/582 [05:38<07:47,  1.38s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 244/582 [05:38<07:46,  1.38s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 244/582 [05:39<07:46,  1.38s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 245/582 [05:39<07:44,  1.38s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 245/582 [05:40<07:44,  1.38s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 246/582 [05:40<07:44,  1.38s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 246/582 [05:42<07:44,  1.38s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 247/582 [05:42<07:42,  1.38s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 247/582 [05:43<07:42,  1.38s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 248/582 [05:43<07:42,  1.39s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 248/582 [05:45<07:42,  1.39s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 249/582 [05:45<07:42,  1.39s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 249/582 [05:46<07:42,  1.39s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 250/582 [05:46<07:41,  1.39s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 250/582 [05:47<07:41,  1.39s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 251/582 [05:47<07:38,  1.39s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 251/582 [05:49<07:38,  1.39s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 252/582 [05:49<07:37,  1.39s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 252/582 [05:50<07:37,  1.39s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 253/582 [05:50<07:35,  1.38s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 253/582 [05:52<07:35,  1.38s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 254/582 [05:52<07:34,  1.39s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 254/582 [05:53<07:34,  1.39s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 255/582 [05:53<07:34,  1.39s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 255/582 [05:54<07:34,  1.39s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 256/582 [05:54<07:31,  1.39s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 256/582 [05:56<07:31,  1.39s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 257/582 [05:56<07:30,  1.39s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 257/582 [05:57<07:30,  1.39s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 258/582 [05:57<07:28,  1.38s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 258/582 [05:59<07:28,  1.38s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 259/582 [05:59<07:27,  1.39s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 259/582 [06:00<07:27,  1.39s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 260/582 [06:00<07:25,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 260/582 [06:01<07:25,  1.38s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 261/582 [06:01<07:24,  1.39s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 261/582 [06:03<07:24,  1.39s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 262/582 [06:03<07:24,  1.39s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 262/582 [06:04<07:24,  1.39s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 263/582 [06:04<07:23,  1.39s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 263/582 [06:05<07:23,  1.39s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 264/582 [06:05<07:21,  1.39s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 264/582 [06:07<07:21,  1.39s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 265/582 [06:07<07:19,  1.39s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 265/582 [06:08<07:19,  1.39s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 266/582 [06:08<07:18,  1.39s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 266/582 [06:10<07:18,  1.39s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 267/582 [06:10<07:18,  1.39s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 267/582 [06:11<07:18,  1.39s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 268/582 [06:11<07:16,  1.39s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 268/582 [06:12<07:16,  1.39s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 269/582 [06:12<07:14,  1.39s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 269/582 [06:14<07:14,  1.39s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 270/582 [06:14<07:11,  1.38s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 270/582 [06:15<07:11,  1.38s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 271/582 [06:15<07:10,  1.38s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 271/582 [06:17<07:10,  1.38s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 272/582 [06:17<07:08,  1.38s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 272/582 [06:18<07:08,  1.38s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 273/582 [06:18<07:06,  1.38s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 273/582 [06:19<07:06,  1.38s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 274/582 [06:19<07:05,  1.38s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 274/582 [06:21<07:05,  1.38s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 275/582 [06:21<07:03,  1.38s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 275/582 [06:22<07:03,  1.38s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 276/582 [06:22<07:02,  1.38s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 276/582 [06:23<07:02,  1.38s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 277/582 [06:23<07:01,  1.38s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 277/582 [06:25<07:01,  1.38s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 278/582 [06:25<06:59,  1.38s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 278/582 [06:26<06:59,  1.38s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 279/582 [06:26<06:58,  1.38s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 279/582 [06:28<06:58,  1.38s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 280/582 [06:28<06:56,  1.38s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 280/582 [06:29<06:56,  1.38s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 281/582 [06:29<06:55,  1.38s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 281/582 [06:30<06:55,  1.38s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 282/582 [06:30<06:55,  1.38s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 282/582 [06:32<06:55,  1.38s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 283/582 [06:32<06:54,  1.39s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 283/582 [06:33<06:54,  1.39s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 284/582 [06:33<06:52,  1.39s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 284/582 [06:35<06:52,  1.39s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 285/582 [06:35<06:51,  1.38s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 285/582 [06:36<06:51,  1.38s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 286/582 [06:36<06:49,  1.38s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 286/582 [06:37<06:49,  1.38s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 287/582 [06:37<06:48,  1.38s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 287/582 [06:39<06:48,  1.38s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 288/582 [06:39<06:47,  1.39s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 288/582 [06:40<06:47,  1.39s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 289/582 [06:40<06:46,  1.39s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 289/582 [06:41<06:46,  1.39s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 290/582 [06:41<06:44,  1.39s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 290/582 [06:43<06:44,  1.39s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  50%|█████     | 291/582 [06:43<06:44,  1.39s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  50%|█████     | 291/582 [06:44<06:44,  1.39s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  50%|█████     | 292/582 [06:44<06:43,  1.39s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  50%|█████     | 292/582 [06:46<06:43,  1.39s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  50%|█████     | 293/582 [06:46<06:42,  1.39s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  50%|█████     | 293/582 [06:47<06:42,  1.39s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  51%|█████     | 294/582 [06:47<06:40,  1.39s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  51%|█████     | 294/582 [06:48<06:40,  1.39s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  51%|█████     | 295/582 [06:48<06:38,  1.39s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  51%|█████     | 295/582 [06:50<06:38,  1.39s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  51%|█████     | 296/582 [06:50<06:36,  1.39s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  51%|█████     | 296/582 [06:51<06:36,  1.39s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  51%|█████     | 297/582 [06:51<06:34,  1.39s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  51%|█████     | 297/582 [06:53<06:34,  1.39s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  51%|█████     | 298/582 [06:53<06:34,  1.39s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  51%|█████     | 298/582 [06:54<06:34,  1.39s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 299/582 [06:54<06:32,  1.39s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 299/582 [06:55<06:32,  1.39s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 300/582 [06:55<06:30,  1.38s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 300/582 [06:57<06:30,  1.38s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 301/582 [06:57<06:29,  1.39s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 301/582 [06:58<06:29,  1.39s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 302/582 [06:58<06:27,  1.38s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 302/582 [06:59<06:27,  1.38s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 303/582 [06:59<06:25,  1.38s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 303/582 [07:01<06:25,  1.38s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 304/582 [07:01<06:24,  1.38s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 304/582 [07:02<06:24,  1.38s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 305/582 [07:02<06:23,  1.38s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 305/582 [07:04<06:23,  1.38s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 306/582 [07:04<06:22,  1.39s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 306/582 [07:05<06:22,  1.39s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 307/582 [07:05<06:22,  1.39s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 307/582 [07:06<06:22,  1.39s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 308/582 [07:06<06:19,  1.39s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 308/582 [07:08<06:19,  1.39s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 309/582 [07:08<06:17,  1.38s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 309/582 [07:09<06:17,  1.38s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 310/582 [07:09<06:16,  1.38s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 310/582 [07:11<06:16,  1.38s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 311/582 [07:11<06:15,  1.39s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 311/582 [07:12<06:15,  1.39s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 312/582 [07:12<06:13,  1.38s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 312/582 [07:13<06:13,  1.38s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 313/582 [07:13<06:12,  1.38s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 313/582 [07:15<06:12,  1.38s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 314/582 [07:15<06:11,  1.38s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 314/582 [07:16<06:11,  1.38s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 315/582 [07:16<06:09,  1.38s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 315/582 [07:17<06:09,  1.38s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 316/582 [07:17<06:08,  1.39s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 316/582 [07:19<06:08,  1.39s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 317/582 [07:19<06:07,  1.39s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 317/582 [07:20<06:07,  1.39s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 318/582 [07:20<06:05,  1.39s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 318/582 [07:22<06:05,  1.39s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 319/582 [07:22<06:04,  1.39s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 319/582 [07:23<06:04,  1.39s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 320/582 [07:23<06:03,  1.39s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 320/582 [07:24<06:03,  1.39s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 321/582 [07:24<06:01,  1.38s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 321/582 [07:26<06:01,  1.38s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 322/582 [07:26<06:00,  1.39s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 322/582 [07:27<06:00,  1.39s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 323/582 [07:27<05:57,  1.38s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 323/582 [07:29<05:57,  1.38s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 324/582 [07:29<05:56,  1.38s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 324/582 [07:30<05:56,  1.38s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 325/582 [07:30<05:56,  1.39s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 325/582 [07:31<05:56,  1.39s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 326/582 [07:31<05:55,  1.39s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 326/582 [07:33<05:55,  1.39s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 327/582 [07:33<05:53,  1.39s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 327/582 [07:34<05:53,  1.39s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 328/582 [07:34<05:51,  1.38s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 328/582 [07:35<05:51,  1.38s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 329/582 [07:35<05:50,  1.39s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 329/582 [07:37<05:50,  1.39s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 330/582 [07:37<05:48,  1.38s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 330/582 [07:38<05:48,  1.38s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 331/582 [07:38<05:46,  1.38s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 331/582 [07:40<05:46,  1.38s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 332/582 [07:40<05:44,  1.38s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 332/582 [07:41<05:44,  1.38s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 333/582 [07:41<05:44,  1.38s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 333/582 [07:42<05:44,  1.38s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 334/582 [07:42<05:42,  1.38s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 334/582 [07:44<05:42,  1.38s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 335/582 [07:44<05:40,  1.38s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 335/582 [07:45<05:40,  1.38s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 336/582 [07:45<05:39,  1.38s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 336/582 [07:47<05:39,  1.38s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 337/582 [07:47<05:39,  1.38s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 337/582 [07:48<05:39,  1.38s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 338/582 [07:48<05:37,  1.38s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 338/582 [07:49<05:37,  1.38s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 339/582 [07:49<05:35,  1.38s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 339/582 [07:51<05:35,  1.38s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 340/582 [07:51<05:34,  1.38s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 340/582 [07:52<05:34,  1.38s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 341/582 [07:52<05:32,  1.38s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 341/582 [07:53<05:32,  1.38s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 342/582 [07:53<05:31,  1.38s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 342/582 [07:55<05:31,  1.38s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 343/582 [07:55<05:30,  1.38s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 343/582 [07:56<05:30,  1.38s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 344/582 [07:56<05:29,  1.38s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 344/582 [07:58<05:29,  1.38s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 345/582 [07:58<05:28,  1.39s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 345/582 [07:59<05:28,  1.39s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 346/582 [07:59<05:27,  1.39s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 346/582 [08:00<05:27,  1.39s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 347/582 [08:00<05:26,  1.39s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 347/582 [08:02<05:26,  1.39s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 348/582 [08:02<05:25,  1.39s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 348/582 [08:03<05:25,  1.39s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 349/582 [08:03<05:23,  1.39s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 349/582 [08:05<05:23,  1.39s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  60%|██████    | 350/582 [08:05<05:22,  1.39s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  60%|██████    | 350/582 [08:06<05:22,  1.39s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  60%|██████    | 351/582 [08:06<05:21,  1.39s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  60%|██████    | 351/582 [08:07<05:21,  1.39s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  60%|██████    | 352/582 [08:07<05:19,  1.39s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  60%|██████    | 352/582 [08:09<05:19,  1.39s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  61%|██████    | 353/582 [08:09<05:17,  1.39s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  61%|██████    | 353/582 [08:10<05:17,  1.39s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  61%|██████    | 354/582 [08:10<05:15,  1.38s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  61%|██████    | 354/582 [08:11<05:15,  1.38s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  61%|██████    | 355/582 [08:11<05:13,  1.38s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  61%|██████    | 355/582 [08:13<05:13,  1.38s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  61%|██████    | 356/582 [08:13<05:12,  1.38s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  61%|██████    | 356/582 [08:14<05:12,  1.38s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 357/582 [08:14<05:11,  1.38s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 357/582 [08:16<05:11,  1.38s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 358/582 [08:16<05:10,  1.39s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 358/582 [08:17<05:10,  1.39s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 359/582 [08:17<05:09,  1.39s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 359/582 [08:18<05:09,  1.39s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 360/582 [08:18<05:08,  1.39s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 360/582 [08:20<05:08,  1.39s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 361/582 [08:20<05:06,  1.39s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 361/582 [08:21<05:06,  1.39s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 362/582 [08:21<05:05,  1.39s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 362/582 [08:23<05:05,  1.39s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 363/582 [08:23<05:04,  1.39s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 363/582 [08:24<05:04,  1.39s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 364/582 [08:24<05:03,  1.39s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 364/582 [08:25<05:03,  1.39s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 365/582 [08:25<05:01,  1.39s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 365/582 [08:27<05:01,  1.39s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 366/582 [08:27<05:00,  1.39s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 366/582 [08:28<05:00,  1.39s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 367/582 [08:28<04:58,  1.39s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 367/582 [08:30<04:58,  1.39s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 368/582 [08:30<04:57,  1.39s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 368/582 [08:31<04:57,  1.39s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 369/582 [08:31<04:55,  1.39s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 369/582 [08:32<04:55,  1.39s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 370/582 [08:32<04:54,  1.39s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 370/582 [08:34<04:54,  1.39s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 371/582 [08:34<04:52,  1.39s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 371/582 [08:35<04:52,  1.39s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 372/582 [08:35<04:51,  1.39s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 372/582 [08:36<04:51,  1.39s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 373/582 [08:36<04:49,  1.39s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 373/582 [08:38<04:49,  1.39s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 374/582 [08:38<04:48,  1.39s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 374/582 [08:39<04:48,  1.39s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 375/582 [08:39<04:47,  1.39s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 375/582 [08:41<04:47,  1.39s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 376/582 [08:41<04:45,  1.39s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 376/582 [08:42<04:45,  1.39s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 377/582 [08:42<04:44,  1.39s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 377/582 [08:43<04:44,  1.39s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 378/582 [08:43<04:42,  1.39s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 378/582 [08:45<04:42,  1.39s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 379/582 [08:45<04:41,  1.38s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 379/582 [08:46<04:41,  1.38s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 380/582 [08:46<04:39,  1.38s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 380/582 [08:48<04:39,  1.38s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 381/582 [08:48<04:38,  1.39s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 381/582 [08:49<04:38,  1.39s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 382/582 [08:49<04:38,  1.39s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 382/582 [08:50<04:38,  1.39s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 383/582 [08:50<04:36,  1.39s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 383/582 [08:52<04:36,  1.39s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 384/582 [08:52<04:35,  1.39s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 384/582 [08:53<04:35,  1.39s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 385/582 [08:53<04:33,  1.39s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 385/582 [08:54<04:33,  1.39s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 386/582 [08:54<04:31,  1.39s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 386/582 [08:56<04:31,  1.39s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 387/582 [08:56<04:28,  1.38s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 387/582 [08:57<04:28,  1.38s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 388/582 [08:57<04:27,  1.38s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 388/582 [08:59<04:27,  1.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 389/582 [08:59<04:25,  1.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 389/582 [09:00<04:25,  1.38s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 390/582 [09:00<04:24,  1.38s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 390/582 [09:01<04:24,  1.38s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 391/582 [09:01<04:23,  1.38s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 391/582 [09:03<04:23,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 392/582 [09:03<04:22,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 392/582 [09:04<04:22,  1.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 393/582 [09:04<04:20,  1.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 393/582 [09:05<04:20,  1.38s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 394/582 [09:05<04:18,  1.38s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 394/582 [09:07<04:18,  1.38s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 395/582 [09:07<04:17,  1.38s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 395/582 [09:08<04:17,  1.38s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 396/582 [09:08<04:16,  1.38s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 396/582 [09:10<04:16,  1.38s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 397/582 [09:10<04:15,  1.38s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 397/582 [09:11<04:15,  1.38s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 398/582 [09:11<04:14,  1.38s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 398/582 [09:12<04:14,  1.38s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 399/582 [09:12<04:13,  1.38s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 399/582 [09:14<04:13,  1.38s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 400/582 [09:14<04:11,  1.38s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 400/582 [09:15<04:11,  1.38s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 401/582 [09:15<04:10,  1.38s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 401/582 [09:17<04:10,  1.38s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 402/582 [09:17<04:08,  1.38s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 402/582 [09:18<04:08,  1.38s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 403/582 [09:18<04:07,  1.38s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 403/582 [09:19<04:07,  1.38s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 404/582 [09:19<04:06,  1.38s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 404/582 [09:21<04:06,  1.38s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 405/582 [09:21<04:05,  1.38s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 405/582 [09:22<04:05,  1.38s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 406/582 [09:22<04:03,  1.39s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 406/582 [09:24<04:03,  1.39s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 407/582 [09:24<04:03,  1.39s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 407/582 [09:25<04:03,  1.39s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 2:  70%|███████   | 408/582 [09:25<04:01,  1.39s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 2:  70%|███████   | 408/582 [09:26<04:01,  1.39s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  70%|███████   | 409/582 [09:26<04:00,  1.39s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  70%|███████   | 409/582 [09:28<04:00,  1.39s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  70%|███████   | 410/582 [09:28<03:58,  1.39s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  70%|███████   | 410/582 [09:29<03:58,  1.39s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  71%|███████   | 411/582 [09:29<03:57,  1.39s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  71%|███████   | 411/582 [09:30<03:57,  1.39s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  71%|███████   | 412/582 [09:30<03:55,  1.39s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  71%|███████   | 412/582 [09:32<03:55,  1.39s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  71%|███████   | 413/582 [09:32<03:54,  1.38s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  71%|███████   | 413/582 [09:33<03:54,  1.38s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  71%|███████   | 414/582 [09:33<03:53,  1.39s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  71%|███████   | 414/582 [09:35<03:53,  1.39s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 415/582 [09:35<03:52,  1.39s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 415/582 [09:36<03:52,  1.39s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 416/582 [09:36<03:50,  1.39s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 416/582 [09:37<03:50,  1.39s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 417/582 [09:37<03:47,  1.38s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 417/582 [09:39<03:47,  1.38s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 418/582 [09:39<03:46,  1.38s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 418/582 [09:40<03:46,  1.38s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 419/582 [09:40<03:45,  1.38s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 419/582 [09:42<03:45,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 420/582 [09:42<03:44,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 420/582 [09:43<03:44,  1.38s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 421/582 [09:43<03:43,  1.39s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 421/582 [09:44<03:43,  1.39s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 422/582 [09:44<03:41,  1.39s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 422/582 [09:46<03:41,  1.39s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 423/582 [09:46<03:40,  1.39s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 423/582 [09:47<03:40,  1.39s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 424/582 [09:47<03:39,  1.39s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 424/582 [09:48<03:39,  1.39s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 425/582 [09:48<03:37,  1.39s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 425/582 [09:50<03:37,  1.39s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 426/582 [09:50<03:35,  1.38s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 426/582 [09:51<03:35,  1.38s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 427/582 [09:51<03:34,  1.38s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 427/582 [09:53<03:34,  1.38s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 428/582 [09:53<03:32,  1.38s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 428/582 [09:54<03:32,  1.38s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 429/582 [09:54<03:31,  1.38s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 429/582 [09:55<03:31,  1.38s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 430/582 [09:55<03:29,  1.38s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 430/582 [09:57<03:29,  1.38s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 431/582 [09:57<03:28,  1.38s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 431/582 [09:58<03:28,  1.38s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 432/582 [09:58<03:27,  1.39s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 432/582 [10:00<03:27,  1.39s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 433/582 [10:00<03:26,  1.38s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 433/582 [10:01<03:26,  1.38s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 434/582 [10:01<03:24,  1.38s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 434/582 [10:02<03:24,  1.38s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 435/582 [10:02<03:23,  1.38s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 435/582 [10:04<03:23,  1.38s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 436/582 [10:04<03:22,  1.38s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 436/582 [10:05<03:22,  1.38s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 437/582 [10:05<03:21,  1.39s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 437/582 [10:06<03:21,  1.39s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 438/582 [10:06<03:20,  1.39s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 438/582 [10:08<03:20,  1.39s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 439/582 [10:08<03:18,  1.39s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 439/582 [10:09<03:18,  1.39s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 440/582 [10:09<03:16,  1.38s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 440/582 [10:11<03:16,  1.38s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 441/582 [10:11<03:15,  1.39s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 441/582 [10:12<03:15,  1.39s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 442/582 [10:12<03:14,  1.39s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 442/582 [10:13<03:14,  1.39s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 443/582 [10:13<03:12,  1.39s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 443/582 [10:15<03:12,  1.39s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 444/582 [10:15<03:10,  1.38s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 444/582 [10:16<03:10,  1.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 445/582 [10:16<03:09,  1.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 445/582 [10:18<03:09,  1.38s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 446/582 [10:18<03:08,  1.39s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 446/582 [10:19<03:08,  1.39s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 447/582 [10:19<03:07,  1.39s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 447/582 [10:20<03:07,  1.39s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 448/582 [10:20<03:06,  1.39s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 448/582 [10:22<03:06,  1.39s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 449/582 [10:22<03:04,  1.39s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 449/582 [10:23<03:04,  1.39s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 450/582 [10:23<03:03,  1.39s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 450/582 [10:24<03:03,  1.39s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 451/582 [10:24<03:01,  1.39s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 451/582 [10:26<03:01,  1.39s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 452/582 [10:26<03:00,  1.39s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 452/582 [10:27<03:00,  1.39s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 453/582 [10:27<02:58,  1.38s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 453/582 [10:29<02:58,  1.38s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 454/582 [10:29<02:56,  1.38s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 454/582 [10:30<02:56,  1.38s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 455/582 [10:30<02:55,  1.38s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 455/582 [10:31<02:55,  1.38s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 456/582 [10:31<02:54,  1.38s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 456/582 [10:33<02:54,  1.38s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 457/582 [10:33<02:52,  1.38s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 457/582 [10:34<02:52,  1.38s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 458/582 [10:34<02:51,  1.38s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 458/582 [10:36<02:51,  1.38s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 459/582 [10:36<02:49,  1.38s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 459/582 [10:37<02:49,  1.38s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 460/582 [10:37<02:48,  1.38s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 460/582 [10:38<02:48,  1.38s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 461/582 [10:38<02:47,  1.39s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 461/582 [10:40<02:47,  1.39s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 462/582 [10:40<02:46,  1.38s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 462/582 [10:41<02:46,  1.38s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 463/582 [10:41<02:45,  1.39s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 463/582 [10:42<02:45,  1.39s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 464/582 [10:42<02:43,  1.38s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 464/582 [10:44<02:43,  1.38s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 465/582 [10:44<02:41,  1.38s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 465/582 [10:45<02:41,  1.38s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  80%|████████  | 466/582 [10:45<02:40,  1.39s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  80%|████████  | 466/582 [10:47<02:40,  1.39s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  80%|████████  | 467/582 [10:47<02:39,  1.39s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  80%|████████  | 467/582 [10:48<02:39,  1.39s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  80%|████████  | 468/582 [10:48<02:37,  1.38s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  80%|████████  | 468/582 [10:49<02:37,  1.38s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  81%|████████  | 469/582 [10:49<02:36,  1.38s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  81%|████████  | 469/582 [10:51<02:36,  1.38s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  81%|████████  | 470/582 [10:51<02:35,  1.38s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  81%|████████  | 470/582 [10:52<02:35,  1.38s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  81%|████████  | 471/582 [10:52<02:33,  1.38s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  81%|████████  | 471/582 [10:53<02:33,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  81%|████████  | 472/582 [10:54<02:31,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  81%|████████  | 472/582 [10:55<02:31,  1.38s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 473/582 [10:55<02:30,  1.38s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 473/582 [10:56<02:30,  1.38s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 474/582 [10:56<02:29,  1.38s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 474/582 [10:58<02:29,  1.38s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 475/582 [10:58<02:27,  1.38s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 475/582 [10:59<02:27,  1.38s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 476/582 [10:59<02:26,  1.38s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 476/582 [11:00<02:26,  1.38s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 477/582 [11:00<02:25,  1.39s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 477/582 [11:02<02:25,  1.39s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 478/582 [11:02<02:23,  1.38s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 478/582 [11:03<02:23,  1.38s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 479/582 [11:03<02:22,  1.38s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 479/582 [11:05<02:22,  1.38s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 480/582 [11:05<02:20,  1.38s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 480/582 [11:06<02:20,  1.38s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 481/582 [11:06<02:19,  1.38s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 481/582 [11:07<02:19,  1.38s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 482/582 [11:07<02:18,  1.38s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 482/582 [11:09<02:18,  1.38s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 483/582 [11:09<02:17,  1.38s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 483/582 [11:10<02:17,  1.38s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 484/582 [11:10<02:15,  1.38s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 484/582 [11:11<02:15,  1.38s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 485/582 [11:11<02:14,  1.38s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 485/582 [11:13<02:14,  1.38s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 486/582 [11:13<02:12,  1.38s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 486/582 [11:14<02:12,  1.38s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 487/582 [11:14<02:11,  1.38s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 487/582 [11:16<02:11,  1.38s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 488/582 [11:16<02:10,  1.38s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 488/582 [11:17<02:10,  1.38s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 489/582 [11:17<02:08,  1.39s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 489/582 [11:18<02:08,  1.39s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 490/582 [11:18<02:07,  1.38s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 490/582 [11:20<02:07,  1.38s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 491/582 [11:20<02:05,  1.38s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 491/582 [11:21<02:05,  1.38s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 492/582 [11:21<02:04,  1.38s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 492/582 [11:23<02:04,  1.38s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 493/582 [11:23<02:02,  1.38s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 493/582 [11:24<02:02,  1.38s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 494/582 [11:24<02:01,  1.38s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 494/582 [11:25<02:01,  1.38s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 495/582 [11:25<02:00,  1.38s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 495/582 [11:27<02:00,  1.38s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 496/582 [11:27<01:59,  1.38s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 496/582 [11:28<01:59,  1.38s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 497/582 [11:28<01:57,  1.38s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 497/582 [11:29<01:57,  1.38s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 498/582 [11:29<01:56,  1.38s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 498/582 [11:31<01:56,  1.38s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 499/582 [11:31<01:54,  1.38s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 499/582 [11:32<01:54,  1.38s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 500/582 [11:32<01:53,  1.38s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 500/582 [11:34<01:53,  1.38s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 501/582 [11:34<01:52,  1.39s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 501/582 [11:35<01:52,  1.39s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 502/582 [11:35<01:51,  1.39s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 502/582 [11:36<01:51,  1.39s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 503/582 [11:36<01:49,  1.39s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 503/582 [11:38<01:49,  1.39s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 504/582 [11:38<01:47,  1.38s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 504/582 [11:39<01:47,  1.38s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 505/582 [11:39<01:46,  1.39s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 505/582 [11:41<01:46,  1.39s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 506/582 [11:41<01:45,  1.39s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 506/582 [11:42<01:45,  1.39s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 507/582 [11:42<01:43,  1.38s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 507/582 [11:43<01:43,  1.38s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 508/582 [11:43<01:42,  1.38s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 508/582 [11:45<01:42,  1.38s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 509/582 [11:45<01:41,  1.38s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 509/582 [11:46<01:41,  1.38s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 510/582 [11:46<01:39,  1.39s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 510/582 [11:47<01:39,  1.39s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 511/582 [11:47<01:38,  1.39s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 511/582 [11:49<01:38,  1.39s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 512/582 [11:49<01:36,  1.38s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 512/582 [11:50<01:36,  1.38s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 513/582 [11:50<01:35,  1.38s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 513/582 [11:52<01:35,  1.38s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 514/582 [11:52<01:34,  1.38s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 514/582 [11:53<01:34,  1.38s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 515/582 [11:53<01:32,  1.38s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 515/582 [11:54<01:32,  1.38s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 516/582 [11:54<01:31,  1.38s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 516/582 [11:56<01:31,  1.38s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 517/582 [11:56<01:29,  1.38s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 517/582 [11:57<01:29,  1.38s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 518/582 [11:57<01:28,  1.38s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 518/582 [11:59<01:28,  1.38s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 519/582 [11:59<01:26,  1.38s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 519/582 [12:00<01:26,  1.38s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 520/582 [12:00<01:25,  1.38s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 520/582 [12:01<01:25,  1.38s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 521/582 [12:01<01:24,  1.38s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 521/582 [12:03<01:24,  1.38s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 522/582 [12:03<01:22,  1.38s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 522/582 [12:04<01:22,  1.38s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 523/582 [12:04<01:21,  1.38s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 523/582 [12:05<01:21,  1.38s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 524/582 [12:05<01:20,  1.38s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 524/582 [12:07<01:20,  1.38s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 525/582 [12:07<01:18,  1.38s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 525/582 [12:08<01:18,  1.38s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 526/582 [12:08<01:17,  1.38s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 526/582 [12:10<01:17,  1.38s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 527/582 [12:10<01:15,  1.38s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 527/582 [12:11<01:15,  1.38s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 528/582 [12:11<01:14,  1.38s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 528/582 [12:12<01:14,  1.38s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 529/582 [12:12<01:13,  1.38s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 529/582 [12:14<01:13,  1.38s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 530/582 [12:14<01:12,  1.39s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 530/582 [12:15<01:12,  1.39s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 531/582 [12:15<01:10,  1.39s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 531/582 [12:17<01:10,  1.39s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 532/582 [12:17<01:09,  1.38s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 532/582 [12:18<01:09,  1.38s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 533/582 [12:18<01:07,  1.38s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 533/582 [12:19<01:07,  1.38s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 534/582 [12:19<01:06,  1.39s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 534/582 [12:21<01:06,  1.39s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 535/582 [12:21<01:05,  1.39s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 535/582 [12:22<01:05,  1.39s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 536/582 [12:22<01:03,  1.39s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 536/582 [12:23<01:03,  1.39s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 537/582 [12:23<01:02,  1.39s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 537/582 [12:25<01:02,  1.39s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 538/582 [12:25<01:00,  1.38s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 538/582 [12:26<01:00,  1.38s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 539/582 [12:26<00:59,  1.38s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 539/582 [12:28<00:59,  1.38s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 540/582 [12:28<00:57,  1.38s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 540/582 [12:29<00:57,  1.38s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 541/582 [12:29<00:56,  1.38s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 541/582 [12:30<00:56,  1.38s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 542/582 [12:30<00:55,  1.38s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 542/582 [12:32<00:55,  1.38s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 543/582 [12:32<00:53,  1.38s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 543/582 [12:33<00:53,  1.38s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 544/582 [12:33<00:52,  1.38s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 544/582 [12:35<00:52,  1.38s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 545/582 [12:35<00:51,  1.38s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 545/582 [12:36<00:51,  1.38s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 546/582 [12:36<00:49,  1.39s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 546/582 [12:37<00:49,  1.39s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 547/582 [12:37<00:48,  1.38s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 547/582 [12:39<00:48,  1.38s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 548/582 [12:39<00:47,  1.39s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 548/582 [12:40<00:47,  1.39s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 549/582 [12:40<00:45,  1.38s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 549/582 [12:41<00:45,  1.38s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 550/582 [12:41<00:44,  1.38s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 550/582 [12:43<00:44,  1.38s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 551/582 [12:43<00:42,  1.38s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 551/582 [12:44<00:42,  1.38s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 552/582 [12:44<00:41,  1.38s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 552/582 [12:46<00:41,  1.38s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 553/582 [12:46<00:40,  1.38s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 553/582 [12:47<00:40,  1.38s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 554/582 [12:47<00:38,  1.38s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 554/582 [12:48<00:38,  1.38s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 555/582 [12:48<00:37,  1.38s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 555/582 [12:50<00:37,  1.38s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 556/582 [12:50<00:36,  1.39s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 556/582 [12:51<00:36,  1.39s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 557/582 [12:51<00:34,  1.39s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 557/582 [12:52<00:34,  1.39s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 558/582 [12:52<00:33,  1.38s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 558/582 [12:54<00:33,  1.38s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 559/582 [12:54<00:31,  1.38s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 559/582 [12:55<00:31,  1.38s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 560/582 [12:55<00:30,  1.38s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 560/582 [12:57<00:30,  1.38s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 561/582 [12:57<00:28,  1.38s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 561/582 [12:58<00:28,  1.38s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 562/582 [12:58<00:27,  1.38s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 562/582 [12:59<00:27,  1.38s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 563/582 [12:59<00:26,  1.39s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 563/582 [13:01<00:26,  1.39s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 564/582 [13:01<00:24,  1.39s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 564/582 [13:02<00:24,  1.39s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 565/582 [13:02<00:23,  1.38s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 565/582 [13:04<00:23,  1.38s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 566/582 [13:04<00:22,  1.39s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 566/582 [13:05<00:22,  1.39s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 567/582 [13:05<00:20,  1.38s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 567/582 [13:06<00:20,  1.38s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 568/582 [13:06<00:19,  1.38s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 568/582 [13:08<00:19,  1.38s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 569/582 [13:08<00:17,  1.38s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 569/582 [13:09<00:17,  1.38s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 570/582 [13:09<00:16,  1.38s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 570/582 [13:10<00:16,  1.38s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 571/582 [13:10<00:15,  1.38s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 571/582 [13:12<00:15,  1.38s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 572/582 [13:12<00:13,  1.38s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 572/582 [13:13<00:13,  1.38s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 573/582 [13:13<00:12,  1.38s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 573/582 [13:15<00:12,  1.38s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 574/582 [13:15<00:11,  1.38s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 574/582 [13:16<00:11,  1.38s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 575/582 [13:16<00:09,  1.38s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 575/582 [13:17<00:09,  1.38s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 576/582 [13:17<00:08,  1.38s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 576/582 [13:19<00:08,  1.38s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 577/582 [13:19<00:06,  1.38s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 577/582 [13:20<00:06,  1.38s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 578/582 [13:20<00:05,  1.39s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 578/582 [13:22<00:05,  1.39s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 579/582 [13:22<00:04,  1.38s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 579/582 [13:23<00:04,  1.38s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 580/582 [13:23<00:02,  1.38s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 580/582 [13:24<00:02,  1.38s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 581/582 [13:24<00:01,  1.38s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 581/582 [13:25<00:01,  1.38s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2: 100%|██████████| 582/582 [13:25<00:00,  1.23s/it, training_loss=0.151]\u001b[A\n",
            " 33%|███▎      | 1/3 [28:35<30:04, 902.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2\n",
            "Training loss: 0.5204353871726498\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 2/3 [30:13<15:04, 904.96s/it]\n",
            "Epoch 3:   0%|          | 0/582 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.6060280970384165\n",
            "F1 Score (Weighted): 0.7892480509405266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3:   0%|          | 0/582 [00:01<?, ?it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 3:   0%|          | 1/582 [00:01<13:16,  1.37s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:   0%|          | 1/582 [00:02<13:16,  1.37s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:   0%|          | 2/582 [00:02<13:14,  1.37s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:   0%|          | 2/582 [00:04<13:14,  1.37s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:   1%|          | 3/582 [00:04<13:14,  1.37s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:   1%|          | 3/582 [00:05<13:14,  1.37s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:   1%|          | 4/582 [00:05<13:13,  1.37s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:   1%|          | 4/582 [00:06<13:13,  1.37s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:   1%|          | 5/582 [00:06<13:12,  1.37s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:   1%|          | 5/582 [00:08<13:12,  1.37s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 3:   1%|          | 6/582 [00:08<13:14,  1.38s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 3:   1%|          | 6/582 [00:09<13:14,  1.38s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:   1%|          | 7/582 [00:09<13:13,  1.38s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:   1%|          | 7/582 [00:11<13:13,  1.38s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:   1%|▏         | 8/582 [00:11<13:13,  1.38s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:   1%|▏         | 8/582 [00:12<13:13,  1.38s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 3:   2%|▏         | 9/582 [00:12<13:11,  1.38s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 3:   2%|▏         | 9/582 [00:13<13:11,  1.38s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:   2%|▏         | 10/582 [00:13<13:10,  1.38s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:   2%|▏         | 10/582 [00:15<13:10,  1.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:   2%|▏         | 11/582 [00:15<13:10,  1.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:   2%|▏         | 11/582 [00:16<13:10,  1.38s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:   2%|▏         | 12/582 [00:16<13:11,  1.39s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:   2%|▏         | 12/582 [00:17<13:11,  1.39s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 3:   2%|▏         | 13/582 [00:17<13:09,  1.39s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 3:   2%|▏         | 13/582 [00:19<13:09,  1.39s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:   2%|▏         | 14/582 [00:19<13:10,  1.39s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:   2%|▏         | 14/582 [00:20<13:10,  1.39s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:   3%|▎         | 15/582 [00:20<13:08,  1.39s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:   3%|▎         | 15/582 [00:22<13:08,  1.39s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 3:   3%|▎         | 16/582 [00:22<13:06,  1.39s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 3:   3%|▎         | 16/582 [00:23<13:06,  1.39s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:   3%|▎         | 17/582 [00:23<13:05,  1.39s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:   3%|▎         | 17/582 [00:24<13:05,  1.39s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:   3%|▎         | 18/582 [00:24<13:04,  1.39s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:   3%|▎         | 18/582 [00:26<13:04,  1.39s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:   3%|▎         | 19/582 [00:26<13:02,  1.39s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:   3%|▎         | 19/582 [00:27<13:02,  1.39s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:   3%|▎         | 20/582 [00:27<13:01,  1.39s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:   3%|▎         | 20/582 [00:29<13:01,  1.39s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:   4%|▎         | 21/582 [00:29<12:59,  1.39s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:   4%|▎         | 21/582 [00:30<12:59,  1.39s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:   4%|▍         | 22/582 [00:30<12:58,  1.39s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:   4%|▍         | 22/582 [00:31<12:58,  1.39s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:   4%|▍         | 23/582 [00:31<12:57,  1.39s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:   4%|▍         | 23/582 [00:33<12:57,  1.39s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:   4%|▍         | 24/582 [00:33<12:55,  1.39s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:   4%|▍         | 24/582 [00:34<12:55,  1.39s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3:   4%|▍         | 25/582 [00:34<12:53,  1.39s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3:   4%|▍         | 25/582 [00:36<12:53,  1.39s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:   4%|▍         | 26/582 [00:36<12:52,  1.39s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:   4%|▍         | 26/582 [00:37<12:52,  1.39s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:   5%|▍         | 27/582 [00:37<12:49,  1.39s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:   5%|▍         | 27/582 [00:38<12:49,  1.39s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:   5%|▍         | 28/582 [00:38<12:48,  1.39s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:   5%|▍         | 28/582 [00:40<12:48,  1.39s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 3:   5%|▍         | 29/582 [00:40<12:48,  1.39s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 3:   5%|▍         | 29/582 [00:41<12:48,  1.39s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:   5%|▌         | 30/582 [00:41<12:48,  1.39s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:   5%|▌         | 30/582 [00:42<12:48,  1.39s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:   5%|▌         | 31/582 [00:42<12:45,  1.39s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:   5%|▌         | 31/582 [00:44<12:45,  1.39s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:   5%|▌         | 32/582 [00:44<12:44,  1.39s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:   5%|▌         | 32/582 [00:45<12:44,  1.39s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:   6%|▌         | 33/582 [00:45<12:43,  1.39s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:   6%|▌         | 33/582 [00:47<12:43,  1.39s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:   6%|▌         | 34/582 [00:47<12:42,  1.39s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:   6%|▌         | 34/582 [00:48<12:42,  1.39s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:   6%|▌         | 35/582 [00:48<12:40,  1.39s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:   6%|▌         | 35/582 [00:49<12:40,  1.39s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:   6%|▌         | 36/582 [00:49<12:38,  1.39s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:   6%|▌         | 36/582 [00:51<12:38,  1.39s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:   6%|▋         | 37/582 [00:51<12:36,  1.39s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:   6%|▋         | 37/582 [00:52<12:36,  1.39s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:   7%|▋         | 38/582 [00:52<12:36,  1.39s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:   7%|▋         | 38/582 [00:54<12:36,  1.39s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:   7%|▋         | 39/582 [00:54<12:33,  1.39s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:   7%|▋         | 39/582 [00:55<12:33,  1.39s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:   7%|▋         | 40/582 [00:55<12:31,  1.39s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:   7%|▋         | 40/582 [00:56<12:31,  1.39s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:   7%|▋         | 41/582 [00:56<12:31,  1.39s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:   7%|▋         | 41/582 [00:58<12:31,  1.39s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:   7%|▋         | 42/582 [00:58<12:31,  1.39s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:   7%|▋         | 42/582 [00:59<12:31,  1.39s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:   7%|▋         | 43/582 [00:59<12:29,  1.39s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:   7%|▋         | 43/582 [01:01<12:29,  1.39s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:   8%|▊         | 44/582 [01:01<12:28,  1.39s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:   8%|▊         | 44/582 [01:02<12:28,  1.39s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:   8%|▊         | 45/582 [01:02<12:27,  1.39s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:   8%|▊         | 45/582 [01:03<12:27,  1.39s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:   8%|▊         | 46/582 [01:03<12:24,  1.39s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:   8%|▊         | 46/582 [01:05<12:24,  1.39s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:   8%|▊         | 47/582 [01:05<12:23,  1.39s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:   8%|▊         | 47/582 [01:06<12:23,  1.39s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:   8%|▊         | 48/582 [01:06<12:22,  1.39s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:   8%|▊         | 48/582 [01:08<12:22,  1.39s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:   8%|▊         | 49/582 [01:08<12:22,  1.39s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:   8%|▊         | 49/582 [01:09<12:22,  1.39s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:   9%|▊         | 50/582 [01:09<12:23,  1.40s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:   9%|▊         | 50/582 [01:10<12:23,  1.40s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:   9%|▉         | 51/582 [01:10<12:19,  1.39s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:   9%|▉         | 51/582 [01:12<12:19,  1.39s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 3:   9%|▉         | 52/582 [01:12<12:17,  1.39s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 3:   9%|▉         | 52/582 [01:13<12:17,  1.39s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:   9%|▉         | 53/582 [01:13<12:16,  1.39s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:   9%|▉         | 53/582 [01:14<12:16,  1.39s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:   9%|▉         | 54/582 [01:14<12:14,  1.39s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:   9%|▉         | 54/582 [01:16<12:14,  1.39s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:   9%|▉         | 55/582 [01:16<12:13,  1.39s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:   9%|▉         | 55/582 [01:17<12:13,  1.39s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  10%|▉         | 56/582 [01:17<12:11,  1.39s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  10%|▉         | 56/582 [01:19<12:11,  1.39s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  10%|▉         | 57/582 [01:19<12:09,  1.39s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  10%|▉         | 57/582 [01:20<12:09,  1.39s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  10%|▉         | 58/582 [01:20<12:06,  1.39s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  10%|▉         | 58/582 [01:21<12:06,  1.39s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  10%|█         | 59/582 [01:21<12:04,  1.39s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  10%|█         | 59/582 [01:23<12:04,  1.39s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  10%|█         | 60/582 [01:23<12:03,  1.39s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  10%|█         | 60/582 [01:24<12:03,  1.39s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 3:  10%|█         | 61/582 [01:24<12:02,  1.39s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 3:  10%|█         | 61/582 [01:26<12:02,  1.39s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  11%|█         | 62/582 [01:26<11:59,  1.38s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  11%|█         | 62/582 [01:27<11:59,  1.38s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  11%|█         | 63/582 [01:27<11:58,  1.38s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  11%|█         | 63/582 [01:28<11:58,  1.38s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  11%|█         | 64/582 [01:28<11:57,  1.39s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  11%|█         | 64/582 [01:30<11:57,  1.39s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  11%|█         | 65/582 [01:30<11:56,  1.39s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  11%|█         | 65/582 [01:31<11:56,  1.39s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 66/582 [01:31<11:54,  1.38s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 66/582 [01:32<11:54,  1.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 67/582 [01:32<11:53,  1.39s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 67/582 [01:34<11:53,  1.39s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 68/582 [01:34<11:52,  1.39s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 68/582 [01:35<11:52,  1.39s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 69/582 [01:35<11:49,  1.38s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 69/582 [01:37<11:49,  1.38s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 70/582 [01:37<11:46,  1.38s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 70/582 [01:38<11:46,  1.38s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 71/582 [01:38<11:45,  1.38s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 71/582 [01:39<11:45,  1.38s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 72/582 [01:39<11:44,  1.38s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 72/582 [01:41<11:44,  1.38s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 73/582 [01:41<11:43,  1.38s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 73/582 [01:42<11:43,  1.38s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 74/582 [01:42<11:42,  1.38s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 74/582 [01:44<11:42,  1.38s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 75/582 [01:44<11:42,  1.38s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 75/582 [01:45<11:42,  1.38s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 76/582 [01:45<11:40,  1.38s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 76/582 [01:46<11:40,  1.38s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 77/582 [01:46<11:37,  1.38s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 77/582 [01:48<11:37,  1.38s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 78/582 [01:48<11:36,  1.38s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 78/582 [01:49<11:36,  1.38s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 79/582 [01:49<11:36,  1.39s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 79/582 [01:50<11:36,  1.39s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 80/582 [01:50<11:34,  1.38s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 80/582 [01:52<11:34,  1.38s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 81/582 [01:52<11:32,  1.38s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 81/582 [01:53<11:32,  1.38s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 82/582 [01:53<11:31,  1.38s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 82/582 [01:55<11:31,  1.38s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 83/582 [01:55<11:29,  1.38s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 83/582 [01:56<11:29,  1.38s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 84/582 [01:56<11:27,  1.38s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 84/582 [01:57<11:27,  1.38s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 85/582 [01:57<11:28,  1.39s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 85/582 [01:59<11:28,  1.39s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 86/582 [01:59<11:26,  1.38s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 86/582 [02:00<11:26,  1.38s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 87/582 [02:00<11:24,  1.38s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 87/582 [02:02<11:24,  1.38s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 88/582 [02:02<11:23,  1.38s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 88/582 [02:03<11:23,  1.38s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 89/582 [02:03<11:22,  1.38s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 89/582 [02:04<11:22,  1.38s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 90/582 [02:04<11:20,  1.38s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 90/582 [02:06<11:20,  1.38s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 91/582 [02:06<11:19,  1.38s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 91/582 [02:07<11:19,  1.38s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 92/582 [02:07<11:19,  1.39s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 92/582 [02:08<11:19,  1.39s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 93/582 [02:08<11:20,  1.39s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 93/582 [02:10<11:20,  1.39s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 94/582 [02:10<11:18,  1.39s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 94/582 [02:11<11:18,  1.39s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 95/582 [02:11<11:15,  1.39s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 95/582 [02:13<11:15,  1.39s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 96/582 [02:13<11:13,  1.38s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 96/582 [02:14<11:13,  1.38s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 97/582 [02:14<11:12,  1.39s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 97/582 [02:15<11:12,  1.39s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 98/582 [02:15<11:10,  1.38s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 98/582 [02:17<11:10,  1.38s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 99/582 [02:17<11:08,  1.38s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 99/582 [02:18<11:08,  1.38s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 100/582 [02:18<11:07,  1.38s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 100/582 [02:20<11:07,  1.38s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 101/582 [02:20<11:07,  1.39s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 101/582 [02:21<11:07,  1.39s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 102/582 [02:21<11:05,  1.39s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 102/582 [02:22<11:05,  1.39s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 103/582 [02:22<11:02,  1.38s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 103/582 [02:24<11:02,  1.38s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 104/582 [02:24<11:01,  1.38s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 104/582 [02:25<11:01,  1.38s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 105/582 [02:25<11:00,  1.38s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 105/582 [02:26<11:00,  1.38s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 106/582 [02:26<10:58,  1.38s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 106/582 [02:28<10:58,  1.38s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 107/582 [02:28<10:57,  1.38s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 107/582 [02:29<10:57,  1.38s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 108/582 [02:29<10:55,  1.38s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 108/582 [02:31<10:55,  1.38s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 109/582 [02:31<10:53,  1.38s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 109/582 [02:32<10:53,  1.38s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 110/582 [02:32<10:52,  1.38s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 110/582 [02:33<10:52,  1.38s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 111/582 [02:33<10:54,  1.39s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 111/582 [02:35<10:54,  1.39s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 112/582 [02:35<10:53,  1.39s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 112/582 [02:36<10:53,  1.39s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 113/582 [02:36<10:50,  1.39s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 113/582 [02:38<10:50,  1.39s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 114/582 [02:38<10:49,  1.39s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 114/582 [02:39<10:49,  1.39s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 115/582 [02:39<10:45,  1.38s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 115/582 [02:40<10:45,  1.38s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 116/582 [02:40<10:45,  1.39s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 116/582 [02:42<10:45,  1.39s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  20%|██        | 117/582 [02:42<10:43,  1.38s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  20%|██        | 117/582 [02:43<10:43,  1.38s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  20%|██        | 118/582 [02:43<10:41,  1.38s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  20%|██        | 118/582 [02:44<10:41,  1.38s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  20%|██        | 119/582 [02:44<10:40,  1.38s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  20%|██        | 119/582 [02:46<10:40,  1.38s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 3:  21%|██        | 120/582 [02:46<10:39,  1.38s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 3:  21%|██        | 120/582 [02:47<10:39,  1.38s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  21%|██        | 121/582 [02:47<10:39,  1.39s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  21%|██        | 121/582 [02:49<10:39,  1.39s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  21%|██        | 122/582 [02:49<10:39,  1.39s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  21%|██        | 122/582 [02:50<10:39,  1.39s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  21%|██        | 123/582 [02:50<10:37,  1.39s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  21%|██        | 123/582 [02:51<10:37,  1.39s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 124/582 [02:51<10:35,  1.39s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 124/582 [02:53<10:35,  1.39s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 125/582 [02:53<10:32,  1.38s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 125/582 [02:54<10:32,  1.38s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 126/582 [02:54<10:30,  1.38s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 126/582 [02:56<10:30,  1.38s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 127/582 [02:56<10:30,  1.39s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 127/582 [02:57<10:30,  1.39s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 128/582 [02:57<10:29,  1.39s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 128/582 [02:58<10:29,  1.39s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 129/582 [02:58<10:28,  1.39s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 129/582 [03:00<10:28,  1.39s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 130/582 [03:00<10:26,  1.39s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 130/582 [03:01<10:26,  1.39s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 131/582 [03:01<10:24,  1.39s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 131/582 [03:02<10:24,  1.39s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 132/582 [03:03<10:24,  1.39s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 132/582 [03:04<10:24,  1.39s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 133/582 [03:04<10:21,  1.39s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 133/582 [03:05<10:21,  1.39s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 134/582 [03:05<10:19,  1.38s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 134/582 [03:07<10:19,  1.38s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 135/582 [03:07<10:19,  1.39s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 135/582 [03:08<10:19,  1.39s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 136/582 [03:08<10:17,  1.39s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 136/582 [03:09<10:17,  1.39s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 137/582 [03:09<10:16,  1.39s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 137/582 [03:11<10:16,  1.39s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 138/582 [03:11<10:14,  1.39s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 138/582 [03:12<10:14,  1.39s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 139/582 [03:12<10:13,  1.39s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 139/582 [03:14<10:13,  1.39s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 140/582 [03:14<10:13,  1.39s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 140/582 [03:15<10:13,  1.39s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 141/582 [03:15<10:11,  1.39s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 141/582 [03:16<10:11,  1.39s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 142/582 [03:16<10:10,  1.39s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 142/582 [03:18<10:10,  1.39s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 143/582 [03:18<10:09,  1.39s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 143/582 [03:19<10:09,  1.39s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 144/582 [03:19<10:06,  1.38s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 144/582 [03:20<10:06,  1.38s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 145/582 [03:21<10:05,  1.39s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 145/582 [03:22<10:05,  1.39s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 146/582 [03:22<10:05,  1.39s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 146/582 [03:23<10:05,  1.39s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 147/582 [03:23<10:03,  1.39s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 147/582 [03:25<10:03,  1.39s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 148/582 [03:25<10:01,  1.38s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 148/582 [03:26<10:01,  1.38s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 149/582 [03:26<09:58,  1.38s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 149/582 [03:27<09:58,  1.38s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 150/582 [03:27<09:57,  1.38s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 150/582 [03:29<09:57,  1.38s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 151/582 [03:29<09:55,  1.38s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 151/582 [03:30<09:55,  1.38s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 152/582 [03:30<09:56,  1.39s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 152/582 [03:32<09:56,  1.39s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 153/582 [03:32<09:53,  1.38s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 153/582 [03:33<09:53,  1.38s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 154/582 [03:33<09:54,  1.39s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 154/582 [03:34<09:54,  1.39s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 155/582 [03:34<09:53,  1.39s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 155/582 [03:36<09:53,  1.39s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 156/582 [03:36<09:52,  1.39s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 156/582 [03:37<09:52,  1.39s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 157/582 [03:37<09:51,  1.39s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 157/582 [03:39<09:51,  1.39s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 158/582 [03:39<09:48,  1.39s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 158/582 [03:40<09:48,  1.39s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 159/582 [03:40<09:45,  1.39s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 159/582 [03:41<09:45,  1.39s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 160/582 [03:41<09:46,  1.39s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 160/582 [03:43<09:46,  1.39s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 161/582 [03:43<09:45,  1.39s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 161/582 [03:44<09:45,  1.39s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 162/582 [03:44<09:44,  1.39s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 162/582 [03:45<09:44,  1.39s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 163/582 [03:45<09:40,  1.39s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 163/582 [03:47<09:40,  1.39s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 164/582 [03:47<09:38,  1.38s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 164/582 [03:48<09:38,  1.38s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 165/582 [03:48<09:37,  1.38s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 165/582 [03:50<09:37,  1.38s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 166/582 [03:50<09:37,  1.39s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 166/582 [03:51<09:37,  1.39s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 167/582 [03:51<09:36,  1.39s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 167/582 [03:52<09:36,  1.39s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 168/582 [03:52<09:33,  1.39s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 168/582 [03:54<09:33,  1.39s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 169/582 [03:54<09:32,  1.39s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 169/582 [03:55<09:32,  1.39s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 170/582 [03:55<09:29,  1.38s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 170/582 [03:57<09:29,  1.38s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 171/582 [03:57<09:27,  1.38s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 171/582 [03:58<09:27,  1.38s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 172/582 [03:58<09:26,  1.38s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 172/582 [03:59<09:26,  1.38s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 173/582 [03:59<09:26,  1.38s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 173/582 [04:01<09:26,  1.38s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 174/582 [04:01<09:24,  1.38s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 174/582 [04:02<09:24,  1.38s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  30%|███       | 175/582 [04:02<09:23,  1.38s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  30%|███       | 175/582 [04:03<09:23,  1.38s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 3:  30%|███       | 176/582 [04:03<09:22,  1.39s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 3:  30%|███       | 176/582 [04:05<09:22,  1.39s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  30%|███       | 177/582 [04:05<09:21,  1.39s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  30%|███       | 177/582 [04:06<09:21,  1.39s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 3:  31%|███       | 178/582 [04:06<09:19,  1.38s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 3:  31%|███       | 178/582 [04:08<09:19,  1.38s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  31%|███       | 179/582 [04:08<09:18,  1.38s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  31%|███       | 179/582 [04:09<09:18,  1.38s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  31%|███       | 180/582 [04:09<09:17,  1.39s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  31%|███       | 180/582 [04:10<09:17,  1.39s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 3:  31%|███       | 181/582 [04:10<09:17,  1.39s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 3:  31%|███       | 181/582 [04:12<09:17,  1.39s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 182/582 [04:12<09:13,  1.38s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 182/582 [04:13<09:13,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 183/582 [04:13<09:11,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 183/582 [04:15<09:11,  1.38s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 184/582 [04:15<09:11,  1.39s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 184/582 [04:16<09:11,  1.39s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 185/582 [04:16<09:08,  1.38s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 185/582 [04:17<09:08,  1.38s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 186/582 [04:17<09:07,  1.38s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 186/582 [04:19<09:07,  1.38s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 187/582 [04:19<09:06,  1.38s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 187/582 [04:20<09:06,  1.38s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 188/582 [04:20<09:05,  1.39s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 188/582 [04:21<09:05,  1.39s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 189/582 [04:21<09:05,  1.39s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 189/582 [04:23<09:05,  1.39s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 190/582 [04:23<09:03,  1.39s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 190/582 [04:24<09:03,  1.39s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 191/582 [04:24<09:02,  1.39s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 191/582 [04:26<09:02,  1.39s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 192/582 [04:26<09:00,  1.39s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 192/582 [04:27<09:00,  1.39s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 193/582 [04:27<08:59,  1.39s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 193/582 [04:28<08:59,  1.39s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 194/582 [04:28<08:55,  1.38s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 194/582 [04:30<08:55,  1.38s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 195/582 [04:30<08:55,  1.38s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 195/582 [04:31<08:55,  1.38s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 196/582 [04:31<08:53,  1.38s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 196/582 [04:33<08:53,  1.38s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 197/582 [04:33<08:52,  1.38s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 197/582 [04:34<08:52,  1.38s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 198/582 [04:34<08:51,  1.38s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 198/582 [04:35<08:51,  1.38s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 199/582 [04:35<08:50,  1.39s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 199/582 [04:37<08:50,  1.39s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 200/582 [04:37<08:51,  1.39s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 200/582 [04:38<08:51,  1.39s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 201/582 [04:38<08:49,  1.39s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 201/582 [04:40<08:49,  1.39s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 202/582 [04:40<08:49,  1.39s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 202/582 [04:41<08:49,  1.39s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 203/582 [04:41<08:46,  1.39s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 203/582 [04:42<08:46,  1.39s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 204/582 [04:42<08:43,  1.39s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 204/582 [04:44<08:43,  1.39s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 205/582 [04:44<08:43,  1.39s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 205/582 [04:45<08:43,  1.39s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 206/582 [04:45<08:41,  1.39s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 206/582 [04:46<08:41,  1.39s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 207/582 [04:46<08:39,  1.38s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 207/582 [04:48<08:39,  1.38s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 208/582 [04:48<08:37,  1.38s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 208/582 [04:49<08:37,  1.38s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 209/582 [04:49<08:35,  1.38s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 209/582 [04:51<08:35,  1.38s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 210/582 [04:51<08:34,  1.38s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 210/582 [04:52<08:34,  1.38s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 211/582 [04:52<08:33,  1.38s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 211/582 [04:53<08:33,  1.38s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 212/582 [04:53<08:31,  1.38s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 212/582 [04:55<08:31,  1.38s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 213/582 [04:55<08:28,  1.38s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 213/582 [04:56<08:28,  1.38s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 214/582 [04:56<08:27,  1.38s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 214/582 [04:57<08:27,  1.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 215/582 [04:57<08:25,  1.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 215/582 [04:59<08:25,  1.38s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 216/582 [04:59<08:25,  1.38s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 216/582 [05:00<08:25,  1.38s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 217/582 [05:00<08:23,  1.38s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 217/582 [05:02<08:23,  1.38s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 218/582 [05:02<08:22,  1.38s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 218/582 [05:03<08:22,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 219/582 [05:03<08:21,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 219/582 [05:04<08:21,  1.38s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 220/582 [05:04<08:20,  1.38s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 220/582 [05:06<08:20,  1.38s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 221/582 [05:06<08:19,  1.38s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 221/582 [05:07<08:19,  1.38s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 222/582 [05:07<08:18,  1.39s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 222/582 [05:09<08:18,  1.39s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 223/582 [05:09<08:18,  1.39s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 223/582 [05:10<08:18,  1.39s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 224/582 [05:10<08:16,  1.39s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 224/582 [05:11<08:16,  1.39s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 225/582 [05:11<08:14,  1.39s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 225/582 [05:13<08:14,  1.39s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 226/582 [05:13<08:13,  1.39s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 226/582 [05:14<08:13,  1.39s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 227/582 [05:14<08:12,  1.39s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 227/582 [05:15<08:12,  1.39s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 228/582 [05:16<08:11,  1.39s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 228/582 [05:17<08:11,  1.39s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 229/582 [05:17<08:10,  1.39s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 229/582 [05:18<08:10,  1.39s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 230/582 [05:18<08:09,  1.39s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 230/582 [05:20<08:09,  1.39s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 231/582 [05:20<08:05,  1.38s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 231/582 [05:21<08:05,  1.38s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 232/582 [05:21<08:05,  1.39s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 232/582 [05:22<08:05,  1.39s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  40%|████      | 233/582 [05:22<08:03,  1.39s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  40%|████      | 233/582 [05:24<08:03,  1.39s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 3:  40%|████      | 234/582 [05:24<08:02,  1.39s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 3:  40%|████      | 234/582 [05:25<08:02,  1.39s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 3:  40%|████      | 235/582 [05:25<08:00,  1.39s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 3:  40%|████      | 235/582 [05:27<08:00,  1.39s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  41%|████      | 236/582 [05:27<07:59,  1.39s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  41%|████      | 236/582 [05:28<07:59,  1.39s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  41%|████      | 237/582 [05:28<07:58,  1.39s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  41%|████      | 237/582 [05:29<07:58,  1.39s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  41%|████      | 238/582 [05:29<07:56,  1.39s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  41%|████      | 238/582 [05:31<07:56,  1.39s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  41%|████      | 239/582 [05:31<07:54,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  41%|████      | 239/582 [05:32<07:54,  1.38s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  41%|████      | 240/582 [05:32<07:52,  1.38s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  41%|████      | 240/582 [05:33<07:52,  1.38s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 241/582 [05:34<07:51,  1.38s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 241/582 [05:35<07:51,  1.38s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 242/582 [05:35<07:50,  1.38s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 242/582 [05:36<07:50,  1.38s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 243/582 [05:36<07:49,  1.38s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 243/582 [05:38<07:49,  1.38s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 244/582 [05:38<07:47,  1.38s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 244/582 [05:39<07:47,  1.38s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 245/582 [05:39<07:46,  1.38s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 245/582 [05:40<07:46,  1.38s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 246/582 [05:40<07:44,  1.38s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 246/582 [05:42<07:44,  1.38s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 247/582 [05:42<07:42,  1.38s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 247/582 [05:43<07:42,  1.38s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 248/582 [05:43<07:41,  1.38s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 248/582 [05:45<07:41,  1.38s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 249/582 [05:45<07:40,  1.38s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 249/582 [05:46<07:40,  1.38s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 250/582 [05:46<07:38,  1.38s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 250/582 [05:47<07:38,  1.38s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 251/582 [05:47<07:36,  1.38s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 251/582 [05:49<07:36,  1.38s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 252/582 [05:49<07:34,  1.38s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 252/582 [05:50<07:34,  1.38s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 253/582 [05:50<07:33,  1.38s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 253/582 [05:51<07:33,  1.38s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 254/582 [05:51<07:32,  1.38s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 254/582 [05:53<07:32,  1.38s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 255/582 [05:53<07:30,  1.38s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 255/582 [05:54<07:30,  1.38s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 256/582 [05:54<07:29,  1.38s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 256/582 [05:56<07:29,  1.38s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 257/582 [05:56<07:28,  1.38s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 257/582 [05:57<07:28,  1.38s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 258/582 [05:57<07:26,  1.38s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 258/582 [05:58<07:26,  1.38s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 259/582 [05:58<07:26,  1.38s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 259/582 [06:00<07:26,  1.38s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 260/582 [06:00<07:25,  1.38s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 260/582 [06:01<07:25,  1.38s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 261/582 [06:01<07:25,  1.39s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 261/582 [06:03<07:25,  1.39s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 262/582 [06:03<07:24,  1.39s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 262/582 [06:04<07:24,  1.39s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 263/582 [06:04<07:22,  1.39s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 263/582 [06:05<07:22,  1.39s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 264/582 [06:05<07:22,  1.39s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 264/582 [06:07<07:22,  1.39s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 265/582 [06:07<07:21,  1.39s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 265/582 [06:08<07:21,  1.39s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 266/582 [06:08<07:19,  1.39s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 266/582 [06:09<07:19,  1.39s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 267/582 [06:09<07:17,  1.39s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 267/582 [06:11<07:17,  1.39s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 268/582 [06:11<07:15,  1.39s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 268/582 [06:12<07:15,  1.39s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 269/582 [06:12<07:13,  1.39s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 269/582 [06:14<07:13,  1.39s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 270/582 [06:14<07:12,  1.39s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 270/582 [06:15<07:12,  1.39s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 271/582 [06:15<07:11,  1.39s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 271/582 [06:16<07:11,  1.39s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 272/582 [06:16<07:11,  1.39s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 272/582 [06:18<07:11,  1.39s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 273/582 [06:18<07:09,  1.39s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 273/582 [06:19<07:09,  1.39s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 274/582 [06:19<07:08,  1.39s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 274/582 [06:21<07:08,  1.39s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 275/582 [06:21<07:06,  1.39s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 275/582 [06:22<07:06,  1.39s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 276/582 [06:22<07:04,  1.39s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 276/582 [06:23<07:04,  1.39s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 277/582 [06:23<07:04,  1.39s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 277/582 [06:25<07:04,  1.39s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 278/582 [06:25<07:02,  1.39s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 278/582 [06:26<07:02,  1.39s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 279/582 [06:26<07:00,  1.39s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 279/582 [06:28<07:00,  1.39s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 280/582 [06:28<06:59,  1.39s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 280/582 [06:29<06:59,  1.39s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 281/582 [06:29<06:58,  1.39s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 281/582 [06:30<06:58,  1.39s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 282/582 [06:30<06:57,  1.39s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 282/582 [06:32<06:57,  1.39s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 283/582 [06:32<06:56,  1.39s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 283/582 [06:33<06:56,  1.39s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 284/582 [06:33<06:53,  1.39s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 284/582 [06:34<06:53,  1.39s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 285/582 [06:34<06:52,  1.39s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 285/582 [06:36<06:52,  1.39s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 286/582 [06:36<06:50,  1.39s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 286/582 [06:37<06:50,  1.39s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 287/582 [06:37<06:47,  1.38s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 287/582 [06:39<06:47,  1.38s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 288/582 [06:39<06:46,  1.38s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 288/582 [06:40<06:46,  1.38s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 289/582 [06:40<06:44,  1.38s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 289/582 [06:41<06:44,  1.38s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 290/582 [06:41<06:45,  1.39s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 290/582 [06:43<06:45,  1.39s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  50%|█████     | 291/582 [06:43<06:43,  1.39s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  50%|█████     | 291/582 [06:44<06:43,  1.39s/it, training_loss=0.318]\u001b[A\n",
            "Epoch 3:  50%|█████     | 292/582 [06:44<06:42,  1.39s/it, training_loss=0.318]\u001b[A\n",
            "Epoch 3:  50%|█████     | 292/582 [06:46<06:42,  1.39s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  50%|█████     | 293/582 [06:46<06:40,  1.39s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  50%|█████     | 293/582 [06:47<06:40,  1.39s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:  51%|█████     | 294/582 [06:47<06:38,  1.38s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:  51%|█████     | 294/582 [06:48<06:38,  1.38s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  51%|█████     | 295/582 [06:48<06:38,  1.39s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  51%|█████     | 295/582 [06:50<06:38,  1.39s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  51%|█████     | 296/582 [06:50<06:36,  1.39s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  51%|█████     | 296/582 [06:51<06:36,  1.39s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  51%|█████     | 297/582 [06:51<06:34,  1.38s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  51%|█████     | 297/582 [06:52<06:34,  1.38s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  51%|█████     | 298/582 [06:52<06:32,  1.38s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  51%|█████     | 298/582 [06:54<06:32,  1.38s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 299/582 [06:54<06:31,  1.38s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 299/582 [06:55<06:31,  1.38s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 300/582 [06:55<06:30,  1.38s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 300/582 [06:57<06:30,  1.38s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 301/582 [06:57<06:28,  1.38s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 301/582 [06:58<06:28,  1.38s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 302/582 [06:58<06:27,  1.38s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 302/582 [06:59<06:27,  1.38s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 303/582 [06:59<06:26,  1.38s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 303/582 [07:01<06:26,  1.38s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 304/582 [07:01<06:24,  1.38s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 304/582 [07:02<06:24,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 305/582 [07:02<06:22,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 305/582 [07:04<06:22,  1.38s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 306/582 [07:04<06:21,  1.38s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 306/582 [07:05<06:21,  1.38s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 307/582 [07:05<06:20,  1.38s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 307/582 [07:06<06:20,  1.38s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 308/582 [07:06<06:19,  1.38s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 308/582 [07:08<06:19,  1.38s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 309/582 [07:08<06:17,  1.38s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 309/582 [07:09<06:17,  1.38s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 310/582 [07:09<06:16,  1.38s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 310/582 [07:10<06:16,  1.38s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 311/582 [07:10<06:15,  1.38s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 311/582 [07:12<06:15,  1.38s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 312/582 [07:12<06:15,  1.39s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 312/582 [07:13<06:15,  1.39s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 313/582 [07:13<06:13,  1.39s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 313/582 [07:15<06:13,  1.39s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 314/582 [07:15<06:12,  1.39s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 314/582 [07:16<06:12,  1.39s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 315/582 [07:16<06:11,  1.39s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 315/582 [07:17<06:11,  1.39s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 316/582 [07:17<06:09,  1.39s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 316/582 [07:19<06:09,  1.39s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 317/582 [07:19<06:08,  1.39s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 317/582 [07:20<06:08,  1.39s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 318/582 [07:20<06:07,  1.39s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 318/582 [07:22<06:07,  1.39s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 319/582 [07:22<06:05,  1.39s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 319/582 [07:23<06:05,  1.39s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 320/582 [07:23<06:03,  1.39s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 320/582 [07:24<06:03,  1.39s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 321/582 [07:24<06:02,  1.39s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 321/582 [07:26<06:02,  1.39s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 322/582 [07:26<06:00,  1.39s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 322/582 [07:27<06:00,  1.39s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 323/582 [07:27<05:58,  1.39s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 323/582 [07:29<05:58,  1.39s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 324/582 [07:29<05:57,  1.39s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 324/582 [07:30<05:57,  1.39s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 325/582 [07:30<05:55,  1.38s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 325/582 [07:31<05:55,  1.38s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 326/582 [07:31<05:54,  1.39s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 326/582 [07:33<05:54,  1.39s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 327/582 [07:33<05:53,  1.39s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 327/582 [07:34<05:53,  1.39s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 328/582 [07:34<05:53,  1.39s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 328/582 [07:35<05:53,  1.39s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 329/582 [07:35<05:51,  1.39s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 329/582 [07:37<05:51,  1.39s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 330/582 [07:37<05:50,  1.39s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 330/582 [07:38<05:50,  1.39s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 331/582 [07:38<05:48,  1.39s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 331/582 [07:40<05:48,  1.39s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 332/582 [07:40<05:46,  1.39s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 332/582 [07:41<05:46,  1.39s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 333/582 [07:41<05:44,  1.39s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 333/582 [07:42<05:44,  1.39s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 334/582 [07:42<05:43,  1.39s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 334/582 [07:44<05:43,  1.39s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 335/582 [07:44<05:41,  1.38s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 335/582 [07:45<05:41,  1.38s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 336/582 [07:45<05:40,  1.38s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 336/582 [07:47<05:40,  1.38s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 337/582 [07:47<05:38,  1.38s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 337/582 [07:48<05:38,  1.38s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 338/582 [07:48<05:36,  1.38s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 338/582 [07:49<05:36,  1.38s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 339/582 [07:49<05:35,  1.38s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 339/582 [07:51<05:35,  1.38s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 340/582 [07:51<05:33,  1.38s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 340/582 [07:52<05:33,  1.38s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 341/582 [07:52<05:33,  1.38s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 341/582 [07:53<05:33,  1.38s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 342/582 [07:53<05:33,  1.39s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 342/582 [07:55<05:33,  1.39s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 343/582 [07:55<05:31,  1.39s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 343/582 [07:56<05:31,  1.39s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 344/582 [07:56<05:30,  1.39s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 344/582 [07:58<05:30,  1.39s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 345/582 [07:58<05:29,  1.39s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 345/582 [07:59<05:29,  1.39s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 346/582 [07:59<05:27,  1.39s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 346/582 [08:00<05:27,  1.39s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 347/582 [08:00<05:26,  1.39s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 347/582 [08:02<05:26,  1.39s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 348/582 [08:02<05:25,  1.39s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 348/582 [08:03<05:25,  1.39s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 349/582 [08:03<05:24,  1.39s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 349/582 [08:05<05:24,  1.39s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  60%|██████    | 350/582 [08:05<05:21,  1.39s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  60%|██████    | 350/582 [08:06<05:21,  1.39s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  60%|██████    | 351/582 [08:06<05:19,  1.38s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  60%|██████    | 351/582 [08:07<05:19,  1.38s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  60%|██████    | 352/582 [08:07<05:17,  1.38s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  60%|██████    | 352/582 [08:09<05:17,  1.38s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  61%|██████    | 353/582 [08:09<05:17,  1.38s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  61%|██████    | 353/582 [08:10<05:17,  1.38s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  61%|██████    | 354/582 [08:10<05:15,  1.38s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  61%|██████    | 354/582 [08:11<05:15,  1.38s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  61%|██████    | 355/582 [08:11<05:13,  1.38s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  61%|██████    | 355/582 [08:13<05:13,  1.38s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 3:  61%|██████    | 356/582 [08:13<05:12,  1.38s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 3:  61%|██████    | 356/582 [08:14<05:12,  1.38s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 357/582 [08:14<05:10,  1.38s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 357/582 [08:16<05:10,  1.38s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 358/582 [08:16<05:10,  1.38s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 358/582 [08:17<05:10,  1.38s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 359/582 [08:17<05:08,  1.38s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 359/582 [08:18<05:08,  1.38s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 360/582 [08:18<05:06,  1.38s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 360/582 [08:20<05:06,  1.38s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 361/582 [08:20<05:04,  1.38s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 361/582 [08:21<05:04,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 362/582 [08:21<05:03,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 362/582 [08:23<05:03,  1.38s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 363/582 [08:23<05:02,  1.38s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 363/582 [08:24<05:02,  1.38s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 364/582 [08:24<05:00,  1.38s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 364/582 [08:25<05:00,  1.38s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 365/582 [08:25<05:00,  1.38s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 365/582 [08:27<05:00,  1.38s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 366/582 [08:27<04:58,  1.38s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 366/582 [08:28<04:58,  1.38s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 367/582 [08:28<04:57,  1.38s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 367/582 [08:29<04:57,  1.38s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 368/582 [08:29<04:55,  1.38s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 368/582 [08:31<04:55,  1.38s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 369/582 [08:31<04:54,  1.38s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 369/582 [08:32<04:54,  1.38s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 370/582 [08:32<04:52,  1.38s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 370/582 [08:34<04:52,  1.38s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 371/582 [08:34<04:52,  1.38s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 371/582 [08:35<04:52,  1.38s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 372/582 [08:35<04:50,  1.38s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 372/582 [08:36<04:50,  1.38s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 373/582 [08:36<04:49,  1.39s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 373/582 [08:38<04:49,  1.39s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 374/582 [08:38<04:47,  1.38s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 374/582 [08:39<04:47,  1.38s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 375/582 [08:39<04:46,  1.38s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 375/582 [08:41<04:46,  1.38s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 376/582 [08:41<04:44,  1.38s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 376/582 [08:42<04:44,  1.38s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 377/582 [08:42<04:43,  1.38s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 377/582 [08:43<04:43,  1.38s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 378/582 [08:43<04:42,  1.38s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 378/582 [08:45<04:42,  1.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 379/582 [08:45<04:40,  1.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 379/582 [08:46<04:40,  1.38s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 380/582 [08:46<04:38,  1.38s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 380/582 [08:47<04:38,  1.38s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 381/582 [08:47<04:37,  1.38s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 381/582 [08:49<04:37,  1.38s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 382/582 [08:49<04:36,  1.38s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 382/582 [08:50<04:36,  1.38s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 383/582 [08:50<04:34,  1.38s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 383/582 [08:52<04:34,  1.38s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 384/582 [08:52<04:33,  1.38s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 384/582 [08:53<04:33,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 385/582 [08:53<04:32,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 385/582 [08:54<04:32,  1.38s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 386/582 [08:54<04:30,  1.38s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 386/582 [08:56<04:30,  1.38s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 387/582 [08:56<04:29,  1.38s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 387/582 [08:57<04:29,  1.38s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 388/582 [08:57<04:28,  1.38s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 388/582 [08:58<04:28,  1.38s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 389/582 [08:58<04:27,  1.38s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 389/582 [09:00<04:27,  1.38s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 390/582 [09:00<04:26,  1.39s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 390/582 [09:01<04:26,  1.39s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 391/582 [09:01<04:24,  1.38s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 391/582 [09:03<04:24,  1.38s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 392/582 [09:03<04:23,  1.39s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 392/582 [09:04<04:23,  1.39s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 393/582 [09:04<04:21,  1.38s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 393/582 [09:05<04:21,  1.38s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 394/582 [09:05<04:21,  1.39s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 394/582 [09:07<04:21,  1.39s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 395/582 [09:07<04:18,  1.38s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 395/582 [09:08<04:18,  1.38s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 396/582 [09:08<04:17,  1.38s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 396/582 [09:10<04:17,  1.38s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 397/582 [09:10<04:15,  1.38s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 397/582 [09:11<04:15,  1.38s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 398/582 [09:11<04:14,  1.38s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 398/582 [09:12<04:14,  1.38s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 399/582 [09:12<04:13,  1.38s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 399/582 [09:14<04:13,  1.38s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 400/582 [09:14<04:11,  1.38s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 400/582 [09:15<04:11,  1.38s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 401/582 [09:15<04:09,  1.38s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 401/582 [09:16<04:09,  1.38s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 402/582 [09:16<04:08,  1.38s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 402/582 [09:18<04:08,  1.38s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 403/582 [09:18<04:07,  1.38s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 403/582 [09:19<04:07,  1.38s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 404/582 [09:19<04:05,  1.38s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 404/582 [09:21<04:05,  1.38s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 405/582 [09:21<04:04,  1.38s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 405/582 [09:22<04:04,  1.38s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 406/582 [09:22<04:03,  1.38s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 406/582 [09:23<04:03,  1.38s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 407/582 [09:23<04:01,  1.38s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 407/582 [09:25<04:01,  1.38s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  70%|███████   | 408/582 [09:25<04:00,  1.38s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  70%|███████   | 408/582 [09:26<04:00,  1.38s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 3:  70%|███████   | 409/582 [09:26<03:59,  1.38s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 3:  70%|███████   | 409/582 [09:28<03:59,  1.38s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  70%|███████   | 410/582 [09:28<03:57,  1.38s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  70%|███████   | 410/582 [09:29<03:57,  1.38s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  71%|███████   | 411/582 [09:29<03:56,  1.38s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  71%|███████   | 411/582 [09:30<03:56,  1.38s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  71%|███████   | 412/582 [09:30<03:55,  1.38s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  71%|███████   | 412/582 [09:32<03:55,  1.38s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  71%|███████   | 413/582 [09:32<03:53,  1.38s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  71%|███████   | 413/582 [09:33<03:53,  1.38s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  71%|███████   | 414/582 [09:33<03:52,  1.38s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  71%|███████   | 414/582 [09:34<03:52,  1.38s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 415/582 [09:34<03:51,  1.39s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 415/582 [09:36<03:51,  1.39s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 416/582 [09:36<03:49,  1.38s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 416/582 [09:37<03:49,  1.38s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 417/582 [09:37<03:47,  1.38s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 417/582 [09:39<03:47,  1.38s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 418/582 [09:39<03:46,  1.38s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 418/582 [09:40<03:46,  1.38s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 419/582 [09:40<03:45,  1.38s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 419/582 [09:41<03:45,  1.38s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 420/582 [09:41<03:44,  1.38s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 420/582 [09:43<03:44,  1.38s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 421/582 [09:43<03:42,  1.38s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 421/582 [09:44<03:42,  1.38s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 422/582 [09:44<03:40,  1.38s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 422/582 [09:45<03:40,  1.38s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 423/582 [09:45<03:39,  1.38s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 423/582 [09:47<03:39,  1.38s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 424/582 [09:47<03:39,  1.39s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 424/582 [09:48<03:39,  1.39s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 425/582 [09:48<03:37,  1.39s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 425/582 [09:50<03:37,  1.39s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 426/582 [09:50<03:35,  1.38s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 426/582 [09:51<03:35,  1.38s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 427/582 [09:51<03:34,  1.38s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 427/582 [09:52<03:34,  1.38s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 428/582 [09:52<03:33,  1.38s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 428/582 [09:54<03:33,  1.38s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 429/582 [09:54<03:31,  1.38s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 429/582 [09:55<03:31,  1.38s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 430/582 [09:55<03:30,  1.39s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 430/582 [09:57<03:30,  1.39s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 431/582 [09:57<03:29,  1.38s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 431/582 [09:58<03:29,  1.38s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 432/582 [09:58<03:28,  1.39s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 432/582 [09:59<03:28,  1.39s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 433/582 [09:59<03:26,  1.39s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 433/582 [10:01<03:26,  1.39s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 434/582 [10:01<03:25,  1.39s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 434/582 [10:02<03:25,  1.39s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 435/582 [10:02<03:24,  1.39s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 435/582 [10:04<03:24,  1.39s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 436/582 [10:04<03:23,  1.39s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 436/582 [10:05<03:23,  1.39s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 437/582 [10:05<03:21,  1.39s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 437/582 [10:06<03:21,  1.39s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 438/582 [10:06<03:20,  1.39s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 438/582 [10:08<03:20,  1.39s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 439/582 [10:08<03:18,  1.39s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 439/582 [10:09<03:18,  1.39s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 440/582 [10:09<03:16,  1.39s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 440/582 [10:10<03:16,  1.39s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 441/582 [10:10<03:15,  1.39s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 441/582 [10:12<03:15,  1.39s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 442/582 [10:12<03:13,  1.38s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 442/582 [10:13<03:13,  1.38s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 443/582 [10:13<03:12,  1.38s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 443/582 [10:15<03:12,  1.38s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 444/582 [10:15<03:10,  1.38s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 444/582 [10:16<03:10,  1.38s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 445/582 [10:16<03:09,  1.38s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 445/582 [10:17<03:09,  1.38s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 446/582 [10:17<03:07,  1.38s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 446/582 [10:19<03:07,  1.38s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 447/582 [10:19<03:06,  1.38s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 447/582 [10:20<03:06,  1.38s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 448/582 [10:20<03:04,  1.38s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 448/582 [10:21<03:04,  1.38s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 449/582 [10:21<03:03,  1.38s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 449/582 [10:23<03:03,  1.38s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 450/582 [10:23<03:01,  1.38s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 450/582 [10:24<03:01,  1.38s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 451/582 [10:24<03:00,  1.38s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 451/582 [10:26<03:00,  1.38s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 452/582 [10:26<02:59,  1.38s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 452/582 [10:27<02:59,  1.38s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 453/582 [10:27<02:58,  1.38s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 453/582 [10:28<02:58,  1.38s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 454/582 [10:28<02:57,  1.38s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 454/582 [10:30<02:57,  1.38s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 455/582 [10:30<02:55,  1.38s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 455/582 [10:31<02:55,  1.38s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 456/582 [10:31<02:53,  1.38s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 456/582 [10:33<02:53,  1.38s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 457/582 [10:33<02:52,  1.38s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 457/582 [10:34<02:52,  1.38s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 458/582 [10:34<02:51,  1.38s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 458/582 [10:35<02:51,  1.38s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 459/582 [10:35<02:49,  1.38s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 459/582 [10:37<02:49,  1.38s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 460/582 [10:37<02:48,  1.38s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 460/582 [10:38<02:48,  1.38s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 461/582 [10:38<02:47,  1.38s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 461/582 [10:39<02:47,  1.38s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 462/582 [10:39<02:45,  1.38s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 462/582 [10:41<02:45,  1.38s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 463/582 [10:41<02:44,  1.38s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 463/582 [10:42<02:44,  1.38s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 464/582 [10:42<02:42,  1.38s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 464/582 [10:44<02:42,  1.38s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 465/582 [10:44<02:41,  1.38s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 465/582 [10:45<02:41,  1.38s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  80%|████████  | 466/582 [10:45<02:40,  1.38s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  80%|████████  | 466/582 [10:46<02:40,  1.38s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 3:  80%|████████  | 467/582 [10:46<02:39,  1.39s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 3:  80%|████████  | 467/582 [10:48<02:39,  1.39s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  80%|████████  | 468/582 [10:48<02:37,  1.38s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  80%|████████  | 468/582 [10:49<02:37,  1.38s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  81%|████████  | 469/582 [10:49<02:36,  1.38s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  81%|████████  | 469/582 [10:50<02:36,  1.38s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 3:  81%|████████  | 470/582 [10:50<02:34,  1.38s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 3:  81%|████████  | 470/582 [10:52<02:34,  1.38s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  81%|████████  | 471/582 [10:52<02:33,  1.38s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  81%|████████  | 471/582 [10:53<02:33,  1.38s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  81%|████████  | 472/582 [10:53<02:31,  1.38s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  81%|████████  | 472/582 [10:55<02:31,  1.38s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 473/582 [10:55<02:30,  1.38s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 473/582 [10:56<02:30,  1.38s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 474/582 [10:56<02:29,  1.38s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 474/582 [10:57<02:29,  1.38s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 475/582 [10:57<02:27,  1.38s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 475/582 [10:59<02:27,  1.38s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 476/582 [10:59<02:26,  1.38s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 476/582 [11:00<02:26,  1.38s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 477/582 [11:00<02:24,  1.38s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 477/582 [11:02<02:24,  1.38s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 478/582 [11:02<02:23,  1.38s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 478/582 [11:03<02:23,  1.38s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 479/582 [11:03<02:22,  1.38s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 479/582 [11:04<02:22,  1.38s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 480/582 [11:04<02:20,  1.38s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 480/582 [11:06<02:20,  1.38s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 481/582 [11:06<02:19,  1.38s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 481/582 [11:07<02:19,  1.38s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 482/582 [11:07<02:18,  1.38s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 482/582 [11:08<02:18,  1.38s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 483/582 [11:08<02:16,  1.38s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 483/582 [11:10<02:16,  1.38s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 484/582 [11:10<02:15,  1.38s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 484/582 [11:11<02:15,  1.38s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 485/582 [11:11<02:14,  1.38s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 485/582 [11:13<02:14,  1.38s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 486/582 [11:13<02:12,  1.38s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 486/582 [11:14<02:12,  1.38s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 487/582 [11:14<02:11,  1.39s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 487/582 [11:15<02:11,  1.39s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 488/582 [11:15<02:10,  1.39s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 488/582 [11:17<02:10,  1.39s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 489/582 [11:17<02:08,  1.39s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 489/582 [11:18<02:08,  1.39s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 490/582 [11:18<02:07,  1.38s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 490/582 [11:20<02:07,  1.38s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 491/582 [11:20<02:05,  1.38s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 491/582 [11:21<02:05,  1.38s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 492/582 [11:21<02:04,  1.38s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 492/582 [11:22<02:04,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 493/582 [11:22<02:02,  1.38s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 493/582 [11:24<02:02,  1.38s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 494/582 [11:24<02:01,  1.38s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 494/582 [11:25<02:01,  1.38s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 495/582 [11:25<02:00,  1.38s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 495/582 [11:26<02:00,  1.38s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 496/582 [11:26<01:58,  1.38s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 496/582 [11:28<01:58,  1.38s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 497/582 [11:28<01:57,  1.39s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 497/582 [11:29<01:57,  1.39s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 498/582 [11:29<01:56,  1.38s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 498/582 [11:31<01:56,  1.38s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 499/582 [11:31<01:55,  1.39s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 499/582 [11:32<01:55,  1.39s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 500/582 [11:32<01:53,  1.39s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 500/582 [11:33<01:53,  1.39s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 501/582 [11:33<01:52,  1.38s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 501/582 [11:35<01:52,  1.38s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 502/582 [11:35<01:50,  1.39s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 502/582 [11:36<01:50,  1.39s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 503/582 [11:36<01:49,  1.39s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 503/582 [11:38<01:49,  1.39s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 504/582 [11:38<01:48,  1.39s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 504/582 [11:39<01:48,  1.39s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 505/582 [11:39<01:46,  1.39s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 505/582 [11:40<01:46,  1.39s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 506/582 [11:40<01:45,  1.39s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 506/582 [11:42<01:45,  1.39s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 507/582 [11:42<01:44,  1.39s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 507/582 [11:43<01:44,  1.39s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 508/582 [11:43<01:42,  1.39s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 508/582 [11:44<01:42,  1.39s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 509/582 [11:44<01:41,  1.39s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 509/582 [11:46<01:41,  1.39s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 510/582 [11:46<01:39,  1.39s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 510/582 [11:47<01:39,  1.39s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 511/582 [11:47<01:38,  1.39s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 511/582 [11:49<01:38,  1.39s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 512/582 [11:49<01:37,  1.39s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 512/582 [11:50<01:37,  1.39s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 513/582 [11:50<01:35,  1.39s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 513/582 [11:51<01:35,  1.39s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 514/582 [11:51<01:34,  1.39s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 514/582 [11:53<01:34,  1.39s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 515/582 [11:53<01:32,  1.38s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 515/582 [11:54<01:32,  1.38s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 516/582 [11:54<01:31,  1.38s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 516/582 [11:56<01:31,  1.38s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 517/582 [11:56<01:29,  1.38s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 517/582 [11:57<01:29,  1.38s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 518/582 [11:57<01:28,  1.38s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 518/582 [11:58<01:28,  1.38s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 519/582 [11:58<01:27,  1.38s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 519/582 [12:00<01:27,  1.38s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 520/582 [12:00<01:25,  1.38s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 520/582 [12:01<01:25,  1.38s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 521/582 [12:01<01:24,  1.38s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 521/582 [12:02<01:24,  1.38s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 522/582 [12:02<01:22,  1.38s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 522/582 [12:04<01:22,  1.38s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 523/582 [12:04<01:21,  1.38s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 523/582 [12:05<01:21,  1.38s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 524/582 [12:05<01:20,  1.39s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 524/582 [12:07<01:20,  1.39s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 525/582 [12:07<01:19,  1.39s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 525/582 [12:08<01:19,  1.39s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 526/582 [12:08<01:17,  1.38s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 526/582 [12:09<01:17,  1.38s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 527/582 [12:09<01:15,  1.38s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 527/582 [12:11<01:15,  1.38s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 528/582 [12:11<01:14,  1.38s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 528/582 [12:12<01:14,  1.38s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 529/582 [12:12<01:13,  1.38s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 529/582 [12:14<01:13,  1.38s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 530/582 [12:14<01:11,  1.38s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 530/582 [12:15<01:11,  1.38s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 531/582 [12:15<01:10,  1.38s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 531/582 [12:16<01:10,  1.38s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 532/582 [12:16<01:09,  1.38s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 532/582 [12:18<01:09,  1.38s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 533/582 [12:18<01:07,  1.39s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 533/582 [12:19<01:07,  1.39s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 534/582 [12:19<01:06,  1.39s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 534/582 [12:20<01:06,  1.39s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 535/582 [12:20<01:05,  1.38s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 535/582 [12:22<01:05,  1.38s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 536/582 [12:22<01:03,  1.39s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 536/582 [12:23<01:03,  1.39s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 537/582 [12:23<01:02,  1.38s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 537/582 [12:25<01:02,  1.38s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 538/582 [12:25<01:00,  1.38s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 538/582 [12:26<01:00,  1.38s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 539/582 [12:26<00:59,  1.38s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 539/582 [12:27<00:59,  1.38s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 540/582 [12:27<00:58,  1.38s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 540/582 [12:29<00:58,  1.38s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 541/582 [12:29<00:56,  1.38s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 541/582 [12:30<00:56,  1.38s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 542/582 [12:30<00:55,  1.39s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 542/582 [12:32<00:55,  1.39s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 543/582 [12:32<00:54,  1.39s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 543/582 [12:33<00:54,  1.39s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 544/582 [12:33<00:52,  1.39s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 544/582 [12:34<00:52,  1.39s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 545/582 [12:34<00:51,  1.39s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 545/582 [12:36<00:51,  1.39s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 546/582 [12:36<00:50,  1.39s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 546/582 [12:37<00:50,  1.39s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 547/582 [12:37<00:48,  1.39s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 547/582 [12:38<00:48,  1.39s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 548/582 [12:38<00:47,  1.38s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 548/582 [12:40<00:47,  1.38s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 549/582 [12:40<00:45,  1.38s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 549/582 [12:41<00:45,  1.38s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 550/582 [12:41<00:44,  1.38s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 550/582 [12:43<00:44,  1.38s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 551/582 [12:43<00:42,  1.38s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 551/582 [12:44<00:42,  1.38s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 552/582 [12:44<00:41,  1.38s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 552/582 [12:45<00:41,  1.38s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 553/582 [12:45<00:40,  1.38s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 553/582 [12:47<00:40,  1.38s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 554/582 [12:47<00:38,  1.38s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 554/582 [12:48<00:38,  1.38s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 555/582 [12:48<00:37,  1.38s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 555/582 [12:49<00:37,  1.38s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 556/582 [12:49<00:35,  1.38s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 556/582 [12:51<00:35,  1.38s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 557/582 [12:51<00:34,  1.38s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 557/582 [12:52<00:34,  1.38s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 558/582 [12:52<00:33,  1.38s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 558/582 [12:54<00:33,  1.38s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 559/582 [12:54<00:31,  1.38s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 559/582 [12:55<00:31,  1.38s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 560/582 [12:55<00:30,  1.38s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 560/582 [12:56<00:30,  1.38s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 561/582 [12:56<00:29,  1.38s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 561/582 [12:58<00:29,  1.38s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 562/582 [12:58<00:27,  1.38s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 562/582 [12:59<00:27,  1.38s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 563/582 [12:59<00:26,  1.38s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 563/582 [13:01<00:26,  1.38s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 564/582 [13:01<00:24,  1.38s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 564/582 [13:02<00:24,  1.38s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 565/582 [13:02<00:23,  1.38s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 565/582 [13:03<00:23,  1.38s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 566/582 [13:03<00:22,  1.38s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 566/582 [13:05<00:22,  1.38s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 567/582 [13:05<00:20,  1.38s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 567/582 [13:06<00:20,  1.38s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 568/582 [13:06<00:19,  1.38s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 568/582 [13:07<00:19,  1.38s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 569/582 [13:07<00:17,  1.38s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 569/582 [13:09<00:17,  1.38s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 570/582 [13:09<00:16,  1.38s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 570/582 [13:10<00:16,  1.38s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 571/582 [13:10<00:15,  1.38s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 571/582 [13:12<00:15,  1.38s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 572/582 [13:12<00:13,  1.38s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 572/582 [13:13<00:13,  1.38s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 573/582 [13:13<00:12,  1.38s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 573/582 [13:14<00:12,  1.38s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 574/582 [13:14<00:11,  1.38s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 574/582 [13:16<00:11,  1.38s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 575/582 [13:16<00:09,  1.38s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 575/582 [13:17<00:09,  1.38s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 576/582 [13:17<00:08,  1.38s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 576/582 [13:18<00:08,  1.38s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 577/582 [13:18<00:06,  1.38s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 577/582 [13:20<00:06,  1.38s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 578/582 [13:20<00:05,  1.38s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 578/582 [13:21<00:05,  1.38s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 579/582 [13:21<00:04,  1.38s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 579/582 [13:23<00:04,  1.38s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 580/582 [13:23<00:02,  1.39s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 580/582 [13:24<00:02,  1.39s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 581/582 [13:24<00:01,  1.39s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 581/582 [13:25<00:01,  1.39s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3: 100%|██████████| 582/582 [13:25<00:00,  1.23s/it, training_loss=0.199]\u001b[A\n",
            " 67%|██████▋   | 2/3 [43:46<15:04, 904.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3\n",
            "Training loss: 0.3560123329412487\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [45:24<00:00, 908.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.6711228408457077\n",
            "F1 Score (Weighted): 0.799392932238563\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w3LIWQKqF9c",
        "outputId": "ac76eced-467f-4f6e-f993-eefa770a2695"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: Yes\n",
            "Accuracy: 2462/2901 = 0.848672871423647\n",
            "\n",
            "Class: No\n",
            "Accuracy: 1920/2166 = 0.8864265927977839\n",
            "\n",
            "Class: In the middle, neither yes nor no\n",
            "Accuracy: 55/128 = 0.4296875\n",
            "\n",
            "Class: Probably yes / sometimes yes\n",
            "Accuracy: 91/249 = 0.3654618473895582\n",
            "\n",
            "Class: Probably no\n",
            "Accuracy: 39/232 = 0.16810344827586207\n",
            "\n",
            "Class: Yes, subject to some conditions\n",
            "Accuracy: 464/517 = 0.8974854932301741\n",
            "\n",
            "Class: I am not sure how X will interpret Y’s answer\n",
            "Accuracy: 0/12 = 0.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rjF9G7VqFPW",
        "outputId": "2c46caef-732b-40a6-84a1-47c375dca71a"
      },
      "source": [
        "print('Dev Accuracy:', end = ' ')\n",
        "flat_accuracy(predictions, true_vals)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dev Accuracy: "
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8107977437550362"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_bCLLiLqFDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9ece1b-3626-49f1-d3b7-c54ec0d5cbfd"
      },
      "source": [
        "encoded_data_test = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='test'].YN_s.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=256, \n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_test = encoded_data_test['input_ids']\n",
        "attention_masks_test = encoded_data_test['attention_mask']\n",
        "labels_test = torch.tensor(df[df.data_type=='test'].strict.values)\n",
        "\n",
        "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "\n",
        "dataloader_test = DataLoader(dataset_test, \n",
        "                                   sampler=SequentialSampler(dataset_test), \n",
        "                                   batch_size=batch_size)\n",
        "\n",
        "test_loss, test_predictions, test_true_vals = evaluate(dataloader_test)\n",
        "test_f1 = f1_score_func(test_predictions, test_true_vals)\n",
        "print(test_f1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8108468193210941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AegQA5eE-KqM",
        "outputId": "5e9b5d66-1eb4-4f54-89b9-5c90aee2689d"
      },
      "source": [
        "accuracy_per_class(test_predictions, test_true_vals)\n",
        "print('Test Accuracy:', end = ' ')\n",
        "flat_accuracy(test_predictions, test_true_vals)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: Yes\n",
            "Accuracy: 2495/2901 = 0.8600482592209583\n",
            "\n",
            "Class: No\n",
            "Accuracy: 1934/2166 = 0.8928901200369345\n",
            "\n",
            "Class: In the middle, neither yes nor no\n",
            "Accuracy: 58/127 = 0.4566929133858268\n",
            "\n",
            "Class: Probably yes / sometimes yes\n",
            "Accuracy: 103/249 = 0.41365461847389556\n",
            "\n",
            "Class: Probably no\n",
            "Accuracy: 39/232 = 0.16810344827586207\n",
            "\n",
            "Class: Yes, subject to some conditions\n",
            "Accuracy: 466/516 = 0.9031007751937985\n",
            "\n",
            "Class: I am not sure how X will interpret Y’s answer\n",
            "Accuracy: 0/13 = 0.0\n",
            "\n",
            "Test Accuracy: "
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.821244358478401"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S91mcLzu94KP"
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": []
    }
  ]
}